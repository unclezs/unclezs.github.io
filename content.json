{"meta":{"title":"Unclezs","subtitle":"what do you want for me?","description":"学习与总结","author":"Uncle","url":"https://blog.unclezs.com","root":"/"},"pages":[{"title":"","date":"2076-11-29T08:54:34.955Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"google068e28eb55243bcb.html","permalink":"https://blog.unclezs.com/google068e28eb55243bcb.html","excerpt":"","text":"google-site-verification: google068e28eb55243bcb.html"},{"title":"文档及分类","date":"2020-03-04T08:52:48.000Z","updated":"2021-01-02T08:43:30.000Z","comments":false,"path":"categories/index.html","permalink":"https://blog.unclezs.com/categories/index.html","excerpt":"","text":""},{"title":"留言","date":"2020-07-18T06:33:48.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"comment/index.html","permalink":"https://blog.unclezs.com/comment/index.html","excerpt":"","text":"欢迎大家给我留言，一起交流！"},{"title":"关于","date":"2020-03-04T08:45:54.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"about/index.html","permalink":"https://blog.unclezs.com/about/index.html","excerpt":"","text":"一切都不是那么的完美。 个人博客https://blog.unclezs.com Unclezs's Githubhttps://github.com/unclezs 重庆理工大学https://www.cqut.edu.cn Uncle小说官网https://app.unclezs.com 小说下载网http://novel.unclezs.com"},{"title":"标签","date":"2020-03-04T08:45:54.000Z","updated":"2021-01-02T08:43:30.000Z","comments":false,"path":"tags/index.html","permalink":"https://blog.unclezs.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"打造好用的PowerShell媲美oh-my-zsh","slug":"玩机/效率工具/打造好用的PowerShell媲美oh-my-zsh","date":"2021-01-02T03:57:37.000Z","updated":"2021-01-02T03:57:37.000Z","comments":true,"path":"玩机/效率工具/打造好用的PowerShell媲美oh-my-zsh.html","link":"","permalink":"https://blog.unclezs.com/%E7%8E%A9%E6%9C%BA/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/%E6%89%93%E9%80%A0%E5%A5%BD%E7%94%A8%E7%9A%84PowerShell%E5%AA%B2%E7%BE%8Eoh-my-zsh.html","excerpt":"简介windows下面的CMD控制台很难用，也很丑，但是wndows后面出了个powershell，用着还是不错，但是还是丑，并且有些功能高效功能不具备，比如git分支显示，历史命令提示。 在windows下用了oh-my-zsh后，用着十分的舒服。所以在windows上寻找了一样的结局方案。利用powershell7打造属于windows的强劲终端 先上个效果图： Git分支显示 历史命令提示 终端选择 Fluent Terminate(我的选择) Terminus Windows Terminal (微软应用商店) … 其实windows自带的也是可以的，不过用着总是不算那么舒服","text":"简介windows下面的CMD控制台很难用，也很丑，但是wndows后面出了个powershell，用着还是不错，但是还是丑，并且有些功能高效功能不具备，比如git分支显示，历史命令提示。 在windows下用了oh-my-zsh后，用着十分的舒服。所以在windows上寻找了一样的结局方案。利用powershell7打造属于windows的强劲终端 先上个效果图： Git分支显示 历史命令提示 终端选择 Fluent Terminate(我的选择) Terminus Windows Terminal (微软应用商店) … 其实windows自带的也是可以的，不过用着总是不算那么舒服 下载Powershell7去 PowerShell Release Page 下载安装即可 美化本节就来改造下 PowerShell（以下简称 Posh）。 字体安装需要配置PowerLine字体来显示一些特殊字符 # clone git clone https://github.com/powerline/fonts.git --depth=1 # install cd fonts ./install.sh # clean-up a bit cd .. rm -rf fonts 再将终端字体设置为 Meslo LG S DZ for PowerLine oh-my-poshzsh 下有 oh-my-zsh，Posh 下也有 oh-my-posh 可以做到和 oh-my-zsh 一样的外观。 Install-Module posh-git -Scope CurrentUser Install-Module oh-my-posh -Scope CurrentUser Install-Module posh-docker -Scope CurrentUser 安装完后，我们还需要配置下 Posh 才能使其变成 oh-my-zsh 的样子。 首先在 Posh 中输入 $profile 并回车，Posh 会输出你当前使用的 Profile 文件地址，打开该文件（若没有就需要新建），在该文件中写入以下内容。 或者直接使用： notepad $profile 编辑保存 写入： Import-Module posh-git Import-Module oh-my-posh Set-Theme Paradox # 单行显示，但是在我的IDEA下显示有问题 自测 #Set-Theme Agnoster 保存之后重启posh即可看到效果 命令提示通过PSReadLine实现zsh-autosuggestions插件的功能。 安装： Install-Module -Name PowerShellGet -Force 在主题配置文件后加入 Set-PSReadLineOption -PredictionSource History # 设置预测文本来源为历史记录 Set-PSReadlineKeyHandler -Key Tab -Function Complete # 设置 Tab 键补全 Set-PSReadLineKeyHandler -Key &quot;Ctrl+d&quot; -Function MenuComplete # 设置 Ctrl+d 为菜单补全和 Intellisense Set-PSReadLineKeyHandler -Key &quot;Ctrl+z&quot; -Function Undo # 设置 Ctrl+z 为撤销 Set-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward # 设置向上键为后向搜索历史记录 Set-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward # 设置向下键为前向搜索历史纪录 即可看到最开始简介时候的效果 配置Vim 下载vim: https://www.vim.org/download.php#pc 记住安装路径 编辑配置文件设置vim别名 执行： notepad $profile 加入一行： set-alias vim &quot;D:\\Program Files\\Vim\\vim82\\vim.exe&quot; 也可以把notepad++配置一下更加方便的编辑 set-alias open &quot;C:\\Program Files\\Notepad++\\notepad++.exe&quot; 然后就可以通过open xx文件名打开文件了 配置代理$http_proxy = &quot;http://127.0.0.1:1080&quot; $socks5_proxy = &quot;socks5://127.0.0.1:1080&quot; $env:http_proxy=&quot;$socks5_proxy&quot; $env:https_proxy=&quot;$socks5_proxy&quot; sudo具体查看：https://github.com/gerardog/gsudo 通过scoop安装： scoop install gsudo 安装之后就可以使用sudo了 在Idea中配置 填写自己PowerShell路径，加上nologo则不会打印开头的字体。 在VsCode中配置 选择默认终端为powershell7 配置字体无logo文字 &#123; &quot;terminal.integrated.shell.windows&quot;: &quot;C:\\\\Program Files\\\\PowerShell\\\\7\\\\pwsh.exe&quot;, &quot;terminal.integrated.fontFamily&quot;: &quot;Meslo LG S DZ for PowerLine&quot;, &quot;terminal.integrated.shellArgs.windows&quot;: &quot; -nologo&quot;, &#125; 其他其实windows下还有wsl2，可以直接使用oh-my-zsh，但是我体验了一阵，发现如果在wsl2中编译windows下的文件十分缓慢，IO性能太差，不能日常，如果把项目放到wsl2中确实可以解决项目编译慢的问题，但是又会有其他一些问题，比如idea读取不到maven的子模块。坑就很多所以还是放弃了，也就偶尔用来使用windows环境了。 参考 告别 Windows 终端的难看难用，打造好用的 PowerShell","categories":[{"name":"玩机","slug":"玩机","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/"},{"name":"效率工具","slug":"玩机/效率工具","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"powershell","slug":"powershell","permalink":"https://blog.unclezs.com/tags/powershell/"}],"author":"Unclezs"},{"title":"利用PhantomJs抓取动态网页","slug":"爬虫/利用PhantomJs抓取动态网页","date":"2020-12-25T09:11:01.000Z","updated":"2020-12-25T09:11:01.000Z","comments":true,"path":"爬虫/利用PhantomJs抓取动态网页.html","link":"","permalink":"https://blog.unclezs.com/%E7%88%AC%E8%99%AB/%E5%88%A9%E7%94%A8PhantomJs%E6%8A%93%E5%8F%96%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5.html","excerpt":"简介PhantomJS是可使用JavaScript编写脚本的无头WebKit，我们可以用来做一些爬虫工作，网页截图等，不过目前项目已经被挂起。 基本使用下载执行文件对应自己的操作系统，目前最新的是v2.11 下载地址 语法 phantomjs [options] script.js [arg1 [arg2 [...]]] 编写脚本 hello.js console.log(&quot;hello phantomJS!&quot;) phantom.exit(0) 执行脚本 phantom hello.js","text":"简介PhantomJS是可使用JavaScript编写脚本的无头WebKit，我们可以用来做一些爬虫工作，网页截图等，不过目前项目已经被挂起。 基本使用下载执行文件对应自己的操作系统，目前最新的是v2.11 下载地址 语法 phantomjs [options] script.js [arg1 [arg2 [...]]] 编写脚本 hello.js console.log(&quot;hello phantomJS!&quot;) phantom.exit(0) 执行脚本 phantom hello.js 输出 hello phantomJS! 抓取网页脚本var page = require(&#x27;webpage&#x27;).create(); page.open(&#x27;http://blog.unclezs.com&#x27;, function (status) &#123; if (status !== &#x27;success&#x27;) &#123; console.log(&#x27;failed&#x27;); &#125; else &#123; console.log(page.content); &#125; phantom.exit(); &#125;); 执行即可看到抓取到的html 自定义请求头可以通过 http://httpbin.org/get 这个网站测试自己的请求内容 page.customHeaders=&#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27; &#125; 忽略SSL错误通过参数 –proxy=address:port 设置 比如 phantom –proxy=127.0.0.1:80 script.js 代理通过参数 –ignore-ssl-errors=[true|false|yes|no] 默认为false 比如 phantom –proxy=127.0.0.1:80 script.js 优化取消图片加载 –load-images=[true|false|yes|no] 默认true Java示例Js脚本/** * phantomjs 解析动态网页 * 支持传入referer、cookie、useragent * * @author blog.unclezs.com * @date 2020-12-24 * @see https://phantomjs.org/api/ */ var page = require(&#x27;webpage&#x27;).create(); var system = require(&#x27;system&#x27;); // 只传入脚本名称 不传入参数不执行 if (system.args.length === 1) &#123; phantom.exit(); &#125; // 为了提升加载速度，不加载图片 page.settings.loadImages = false; // 超过10秒放弃加载 page.settings.resourceTimeout = 10000; // 忽略SSL错误 // 参数 需要按照顺序 var url = system.args[1]; var referer = system.args[2]; var cookie = system.args[3]; var userAgent = system.args[4]; var customHeaders = &#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&#x27;, &#x27;Referer&#x27;: url &#125;; if (referer) &#123; customHeaders[&#x27;Referer&#x27;] = referer; &#125; if (cookie) &#123; customHeaders[&#x27;Cookie&#x27;] = cookie; &#125; if (userAgent) &#123; customHeaders[&#x27;User-Agent&#x27;] = userAgent; &#125; page.customHeaders = customHeaders; page.open(url, function (status) &#123; if (status === &#x27;success&#x27;) &#123; console.log(page.content); &#125; phantom.exit(); &#125;); Java工具/** * https://phantomjs.org/api/ * &lt;p&gt; * 首先 添加system properties PHANTOMJS_PATH、PHANTOMJS_SCRIPT * &lt;p&gt; * 不然会使用默认位置去读取 * * @author blog.unclezs.com * @since 2020/12/24 17:30 */ @Slf4j public class PhantomJsClient implements HttpProvider &#123; /** * PhantomJs执行文件的位置 */ public static final String PHANTOMJS_PATH = &quot;PHANTOMJS_PATH&quot;; /** * 脚本位置 */ public static final String PHANTOMJS_SCRIPT = &quot;PHANTOMJS_SCRIPT_PATH&quot;; public static final String DEFAULT_PHANTOMJS_SCRIPT = FileUtil.USER_DIR + &quot;/script/spider.js&quot;; public static final String DEFAULT_PHANTOMJS_PATH = FileUtil.USER_DIR + &quot;/script/phantomjs&quot; + SystemUtil.getExecuteSuffix(); /** * 获取网页内容 * * @param data 请求数据 * @return / * @throws IOException / */ @Override public String content(RequestData data) throws IOException &#123; return executePhantomJs(PhantomJsRequestData.from(data)); &#125; @Override public InputStream stream(RequestData requestData) throws IOException &#123; throw new UnsupportedEncodingException(&quot;PhantomJs动态网页HTTP客户端不支持获取流&quot;); &#125; @Override public boolean isDynamic() &#123; return true; &#125; public String content(String url) throws IOException &#123; return content(RequestData.defaultRequestData(url)); &#125; /** * 执行PhantomJs脚本抓取动态网页 * phantomjs [options] script.js [arg1 [arg2 [...]]] * @param data 请求数据 * @return / */ public String executePhantomJs(PhantomJsRequestData data) throws IOException &#123; if (StringUtil.isEmpty(data.getUrl())) &#123; log.warn(&quot;phantomJS request url 不能为空&quot;); return StringUtil.EMPTY; &#125; StringBuilder command = new StringBuilder(); // phantomJs command.append(System.getProperty(PHANTOMJS_PATH, DEFAULT_PHANTOMJS_PATH)); // 忽略SSL错误 command.append(StringUtil.BLANK).append(&quot;--ignore-ssl-errors=&quot;).append(data.isIgnoreSslError()); // 不加载图片 command.append(StringUtil.BLANK).append(&quot;--load-images=&quot;).append(data.isLoadImg()); // HTTP代理 if (StringUtil.isNotEmpty(data.getProxy())) &#123; command.append(StringUtil.BLANK).append(&quot;--proxy=&quot;).append(data.getProxy()); &#125; // script command.append(StringUtil.BLANK).append(System.getProperty(PHANTOMJS_SCRIPT, DEFAULT_PHANTOMJS_SCRIPT)); // args command.append(StringUtil.BLANK).append(data.getUrl()); command.append(StringUtil.BLANK).append(data.getReferer()); command.append(StringUtil.BLANK).append(data.getCookie()); command.append(StringUtil.BLANK).append(data.getUserAgent()); return CommandUtil.execute(command.toString()); &#125; &#125; /** * 执行CMD命令工具 * * @author zhanghongguo@sensorsdata.cn * @since 2020/12/25 11:09 */ @Slf4j @UtilityClass public class CommandUtil &#123; /** * 执行CMD命令 * * @param command 命令 * @return 控制台数据 */ public static String execute(String command) throws IOException &#123; StringBuilder buffer = new StringBuilder(); log.trace(&quot;执行Command - 命令：&#123;&#125;&quot;, command); Process process = Runtime.getRuntime().exec(command); InputStream is = process.getInputStream(); BufferedReader br = new BufferedReader(new InputStreamReader(is)); String tmp; while ((tmp = br.readLine()) != null) &#123; buffer.append(tmp).append(StringUtil.NEW_LINE); &#125; return buffer.toString(); &#125; &#125; 参考官方文档","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://blog.unclezs.com/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://blog.unclezs.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"PhantomJs","slug":"PhantomJs","permalink":"https://blog.unclezs.com/tags/PhantomJs/"}],"author":"Unclezs"},{"title":"Java中的摘要算法MessageDigest","slug":"Java/基础/Java中的摘要算法MessageDigest","date":"2020-12-19T07:43:40.000Z","updated":"2020-12-19T07:43:40.000Z","comments":true,"path":"Java/基础/Java中的摘要算法MessageDigest.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E4%B8%AD%E7%9A%84%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95MessageDigest.html","excerpt":"MessageDigestJava的摘要算法在java.security包下MessageDigest，通过SPI加载更多的摘要算法，这个包还提供了一些Java的权限检查，这里提一下摘要算法，用可以配合Base64或者Hex转化组合进行加密。可以有MD2、MD5、SHA-224、SHA-256、SHA-384、SHA-512等等 例子/** * Java的摘要算法 * * @author unclezs * @since 2020/12/19 14:48 */ @Slf4j public class MessageDigestSample &#123; /** * 常用的摘要算法 */ public static final String DIGEST_MD2 = &quot;MD2&quot;; public static final String DIGEST_MD5 = &quot;MD5&quot;; public static final String DIGEST_SHA = &quot;SHA&quot;; public static final String DIGEST_SHA_224 = &quot;SHA-224&quot;; public static final String DIGEST_SHA_256 = &quot;SHA-256&quot;; public static final String DIGEST_SHA_384 = &quot;SHA-384&quot;; public static final String DIGEST_SHA_512 = &quot;SHA-512&quot;; public static void main(String[] args) &#123; String[] algorithms = &#123;DIGEST_MD2, DIGEST_MD5, DIGEST_SHA, DIGEST_SHA_224, DIGEST_SHA_256, DIGEST_SHA_384, DIGEST_SHA_512&#125;; for (String algorithm : algorithms) &#123; try &#123; String original = &quot;original&quot;; String salt = &quot;salt&quot;; MessageDigest digest = MessageDigest.getInstance(algorithm); digest.reset(); digest.update(salt.getBytes(StandardCharsets.UTF_8)); byte[] hashed = digest.digest(original.getBytes()); log.info(&quot;&#123;&#125;生成的摘要：&#123;&#125;&quot;, algorithm, Arrays.toString(hashed)); &#125; catch (NoSuchAlgorithmException e) &#123; log.error(&quot;摘要算法不存在:&#123;&#125;&quot;, algorithm, e); &#125; &#125; &#125; &#125; 输出 HMacHMAC（Hash-based Message Authentication Code，散列消息认证码）是一种使用密码散列函数，同时结合一个加密密钥，通过特别计算方式之后产生的消息认证码（MAC）。它可以用来保证数据的完整性，同时可以用来作某个消息的身份验证。HMAC算法 是一种基于密钥的报文完整性的验证方法。HMAC算法利用哈希运算，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。其安全性是建立在Hash加密算法基础上的。它要求通信双方共享密钥、约定算法、对报文进行Hash运算，形成固定长度的认证码。通信双方通过认证码的校验来确定报文的合法性。HMAC算法可以用来作加密、数字签名、报文验证等。 在javax.crypto包下提供了实现 示例","text":"MessageDigestJava的摘要算法在java.security包下MessageDigest，通过SPI加载更多的摘要算法，这个包还提供了一些Java的权限检查，这里提一下摘要算法，用可以配合Base64或者Hex转化组合进行加密。可以有MD2、MD5、SHA-224、SHA-256、SHA-384、SHA-512等等 例子/** * Java的摘要算法 * * @author unclezs * @since 2020/12/19 14:48 */ @Slf4j public class MessageDigestSample &#123; /** * 常用的摘要算法 */ public static final String DIGEST_MD2 = &quot;MD2&quot;; public static final String DIGEST_MD5 = &quot;MD5&quot;; public static final String DIGEST_SHA = &quot;SHA&quot;; public static final String DIGEST_SHA_224 = &quot;SHA-224&quot;; public static final String DIGEST_SHA_256 = &quot;SHA-256&quot;; public static final String DIGEST_SHA_384 = &quot;SHA-384&quot;; public static final String DIGEST_SHA_512 = &quot;SHA-512&quot;; public static void main(String[] args) &#123; String[] algorithms = &#123;DIGEST_MD2, DIGEST_MD5, DIGEST_SHA, DIGEST_SHA_224, DIGEST_SHA_256, DIGEST_SHA_384, DIGEST_SHA_512&#125;; for (String algorithm : algorithms) &#123; try &#123; String original = &quot;original&quot;; String salt = &quot;salt&quot;; MessageDigest digest = MessageDigest.getInstance(algorithm); digest.reset(); digest.update(salt.getBytes(StandardCharsets.UTF_8)); byte[] hashed = digest.digest(original.getBytes()); log.info(&quot;&#123;&#125;生成的摘要：&#123;&#125;&quot;, algorithm, Arrays.toString(hashed)); &#125; catch (NoSuchAlgorithmException e) &#123; log.error(&quot;摘要算法不存在:&#123;&#125;&quot;, algorithm, e); &#125; &#125; &#125; &#125; 输出 HMacHMAC（Hash-based Message Authentication Code，散列消息认证码）是一种使用密码散列函数，同时结合一个加密密钥，通过特别计算方式之后产生的消息认证码（MAC）。它可以用来保证数据的完整性，同时可以用来作某个消息的身份验证。HMAC算法 是一种基于密钥的报文完整性的验证方法。HMAC算法利用哈希运算，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。其安全性是建立在Hash加密算法基础上的。它要求通信双方共享密钥、约定算法、对报文进行Hash运算，形成固定长度的认证码。通信双方通过认证码的校验来确定报文的合法性。HMAC算法可以用来作加密、数字签名、报文验证等。 在javax.crypto包下提供了实现 示例/** * HmacSha256算法加密 * https://blog.csdn.net/sdnyqfyqf/article/details/105534376 * * @author unclezs * @since 2020/12/19 16:33 */ @Slf4j public class HmacSample &#123; public static void main(String[] args) &#123; log.info(&quot;HmacSHA256 加密后：&#123;&#125;&quot;,byHmacSha256(&quot;salt&quot;, &quot;unclezs&quot;)); &#125; private static byte[] byHmacSha256(String salt, String original) &#123; String hmacSha256 = &quot;HmacSHA256&quot;; try &#123; Mac mac = Mac.getInstance(hmacSha256); SecretKey key = new SecretKeySpec(salt.getBytes(StandardCharsets.UTF_8), hmacSha256); mac.init(key); return mac.doFinal(original.getBytes(StandardCharsets.UTF_8)); &#125; catch (NoSuchAlgorithmException e) &#123; log.error(&quot;加密算法不存在：&#123;&#125;&quot;, hmacSha256, e); &#125; catch (InvalidKeyException e) &#123; log.error(&quot;非法私有key：&#123;&#125;&quot;, hmacSha256, e); &#125; return new byte[0]; &#125; &#125; 2020-12-19 16:45:20 [main] INFO com.unclezs.samples.java.encryption.HmacSample #main:23 - HmacSHA256 加密后：[3, 40, -93, -87, 70, 63, 79, 86, 31, 59, -1, -67, 115, -26, 76, -46, 31, 4, 35, -119, -112, -82, 43, -27, 97, -12, 76, 63, 115, -113, 41, 109]","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://blog.unclezs.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[],"author":"Unclezs"},{"title":"Java中的四种引用类型详解","slug":"Java/基础/Java中的四种引用类型详解","date":"2020-12-17T05:43:33.000Z","updated":"2020-12-17T05:43:33.000Z","comments":true,"path":"Java/基础/Java中的四种引用类型详解.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E4%B8%AD%E7%9A%84%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3.html","excerpt":"概念及应用场景 强引用：Java中的引用，默认都是强引用。比如new一个对象，对它的引用就是强引用。对于被强引用指向的对象，就算JVM内存不足OOM，也不会去回收它们。 软引用：若一个对象只被软引用所引用，那么它将在JVM内存不足的时候被回收，即如果JVM内存足够，则软引用所指向的对象不会被垃圾回收(其实这个说法也不够准确，具体原因后面再说)。根据这个性质，软引用很适合做内存缓存：既能提高查询效率，也不会造成内存泄漏。 弱引用：若一个对象只被弱引用所引用，那么它将在下一次GC中被回收掉。如ThreadLocal和WeakHashMap中都使用了弱引用，防止内存泄漏。 虚引用：虚引用是四种引用中最弱的一种引用。我们永远无法从虚引用中拿到对象，被虚引用引用的对象就跟不存在一样。虚引用一般用来跟踪垃圾回收情况，或者可以完成垃圾收集器之外的一些定制化操作。Java NIO中的堆外内存(DirectByteBuffer)因为不受GC的管理，这些内存的清理就是通过虚引用来完成的。 终结器引用：无需手动编码，但其内部配合引用队列使用，在垃圾回收时，终结器引用入队（被引用对象 暂时没有被回收），再由 Finalizer 线程通过终结器引用找到被引用对象并调用它的 finalize 方法，第二次 GC 时才能回收被引用对象 引用队列引用队列(Reference Queue)是一个链表，顾名思义，存放的是引用对象(Reference对象)的队列。软引用与弱引用可以和一个引用队列(Reference Queue)配合使用，当引用所指向的对象被垃圾回收之后，该引用对象本身会被添加到与之关联的引用队列中，从而方便后续一些跟踪或者额外的清理操作。因为无法从虚引用中拿到目标对象，虚引用必须和一个引用队列(Reference Queue)配合使用。 简单测试package com.unclezs.samples.java.reference; import lombok.extern.slf4j.Slf4j; import java.lang.ref.PhantomReference; import java.lang.ref.Reference; import java.lang.ref.ReferenceQueue; import java.lang.ref.SoftReference; import java.lang.ref.WeakReference; import java.util.Arrays; /** * 几种引用类型测试 * &lt;p&gt; * 指定VM参数 -Xms20m -Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author zhanghongguo@sensorsdata.cn * @since 2020/12/17 13:56 */ @Slf4j public class ReferenceSamples &#123; private static final int SIZE1MB = 1024 * 1024; private static final int SIZE1KB = 1024; public static void main(String[] args) throws InterruptedException &#123; // 引用队列，存放Reference对象 ReferenceQueue&lt;Byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); // 定义四种引用对象，强/弱/虚引用为1kb，软引用为1mb Byte[] strong = new Byte[SIZE1KB]; SoftReference&lt;Byte[]&gt; soft = new SoftReference&lt;&gt;(new Byte[SIZE1MB * 10], queue); WeakReference&lt;Byte[]&gt; weak = new WeakReference&lt;&gt;(new Byte[SIZE1KB], queue); PhantomReference&lt;Byte[]&gt; phantom = new PhantomReference&lt;&gt;(new Byte[SIZE1KB], queue); Reference&lt;? extends Byte[]&gt; collectedReference; // 初始状态 log.info(&quot;初始值 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;初始值 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;初始值 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;初始值 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;初始值 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); log.info(&quot;********************&quot;); // 第一次手动触发GC System.gc(); // 停100ms保证垃圾回收已经执行 Thread.sleep(100); log.info(&quot;GC后 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;GC后 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;GC后 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;GC后 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;GC后 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); log.info(&quot;********************&quot;); // 再分配1M的内存，以模拟OOM的情况 Byte[] newByte = new Byte[SIZE1MB * 15]; log.info(&quot;Full GC后 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;Full GC后 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;Full GC后 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;Full GC失败后 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;Full GC失败后 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); &#125; &#125; 注意设置VM参数，每个机器不一样，你可以试着调试到合适自己的。 初始状态下，虚引用用就返回null，其他三个引用都有值。 当触发GC之后，弱引用指向的对象也被回收了，而且可以看到弱引用和虚引用两个引用对象被加到了它们相关联的引用队列中了；强引用和软引用还是可以取到值。 当JVM内存不足之后，软引用也被内存回收了（可以看到软引用，第一次gc后还是内存不足，第二次gc时候，回收了软引用对象），同时该软引用也被加到了与之关联的引用队列中了。而强引用依然能取到值。 源码解析","text":"概念及应用场景 强引用：Java中的引用，默认都是强引用。比如new一个对象，对它的引用就是强引用。对于被强引用指向的对象，就算JVM内存不足OOM，也不会去回收它们。 软引用：若一个对象只被软引用所引用，那么它将在JVM内存不足的时候被回收，即如果JVM内存足够，则软引用所指向的对象不会被垃圾回收(其实这个说法也不够准确，具体原因后面再说)。根据这个性质，软引用很适合做内存缓存：既能提高查询效率，也不会造成内存泄漏。 弱引用：若一个对象只被弱引用所引用，那么它将在下一次GC中被回收掉。如ThreadLocal和WeakHashMap中都使用了弱引用，防止内存泄漏。 虚引用：虚引用是四种引用中最弱的一种引用。我们永远无法从虚引用中拿到对象，被虚引用引用的对象就跟不存在一样。虚引用一般用来跟踪垃圾回收情况，或者可以完成垃圾收集器之外的一些定制化操作。Java NIO中的堆外内存(DirectByteBuffer)因为不受GC的管理，这些内存的清理就是通过虚引用来完成的。 终结器引用：无需手动编码，但其内部配合引用队列使用，在垃圾回收时，终结器引用入队（被引用对象 暂时没有被回收），再由 Finalizer 线程通过终结器引用找到被引用对象并调用它的 finalize 方法，第二次 GC 时才能回收被引用对象 引用队列引用队列(Reference Queue)是一个链表，顾名思义，存放的是引用对象(Reference对象)的队列。软引用与弱引用可以和一个引用队列(Reference Queue)配合使用，当引用所指向的对象被垃圾回收之后，该引用对象本身会被添加到与之关联的引用队列中，从而方便后续一些跟踪或者额外的清理操作。因为无法从虚引用中拿到目标对象，虚引用必须和一个引用队列(Reference Queue)配合使用。 简单测试package com.unclezs.samples.java.reference; import lombok.extern.slf4j.Slf4j; import java.lang.ref.PhantomReference; import java.lang.ref.Reference; import java.lang.ref.ReferenceQueue; import java.lang.ref.SoftReference; import java.lang.ref.WeakReference; import java.util.Arrays; /** * 几种引用类型测试 * &lt;p&gt; * 指定VM参数 -Xms20m -Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author zhanghongguo@sensorsdata.cn * @since 2020/12/17 13:56 */ @Slf4j public class ReferenceSamples &#123; private static final int SIZE1MB = 1024 * 1024; private static final int SIZE1KB = 1024; public static void main(String[] args) throws InterruptedException &#123; // 引用队列，存放Reference对象 ReferenceQueue&lt;Byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); // 定义四种引用对象，强/弱/虚引用为1kb，软引用为1mb Byte[] strong = new Byte[SIZE1KB]; SoftReference&lt;Byte[]&gt; soft = new SoftReference&lt;&gt;(new Byte[SIZE1MB * 10], queue); WeakReference&lt;Byte[]&gt; weak = new WeakReference&lt;&gt;(new Byte[SIZE1KB], queue); PhantomReference&lt;Byte[]&gt; phantom = new PhantomReference&lt;&gt;(new Byte[SIZE1KB], queue); Reference&lt;? extends Byte[]&gt; collectedReference; // 初始状态 log.info(&quot;初始值 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;初始值 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;初始值 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;初始值 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;初始值 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); log.info(&quot;********************&quot;); // 第一次手动触发GC System.gc(); // 停100ms保证垃圾回收已经执行 Thread.sleep(100); log.info(&quot;GC后 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;GC后 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;GC后 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;GC后 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;GC后 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); log.info(&quot;********************&quot;); // 再分配1M的内存，以模拟OOM的情况 Byte[] newByte = new Byte[SIZE1MB * 15]; log.info(&quot;Full GC后 强引用： &#123;&#125;&quot;, Arrays.hashCode(strong)); log.info(&quot;Full GC后 软引用： &#123;&#125;&quot;, Arrays.hashCode(soft.get())); log.info(&quot;Full GC后 弱引用： &#123;&#125;&quot;, Arrays.hashCode(weak.get())); log.info(&quot;Full GC失败后 虚引用： &#123;&#125;&quot;, Arrays.hashCode(phantom.get())); do &#123; collectedReference = queue.poll(); log.info(&quot;Full GC失败后 引用队列： &quot; + collectedReference); &#125; while (collectedReference != null); &#125; &#125; 注意设置VM参数，每个机器不一样，你可以试着调试到合适自己的。 初始状态下，虚引用用就返回null，其他三个引用都有值。 当触发GC之后，弱引用指向的对象也被回收了，而且可以看到弱引用和虚引用两个引用对象被加到了它们相关联的引用队列中了；强引用和软引用还是可以取到值。 当JVM内存不足之后，软引用也被内存回收了（可以看到软引用，第一次gc后还是内存不足，第二次gc时候，回收了软引用对象），同时该软引用也被加到了与之关联的引用队列中了。而强引用依然能取到值。 源码解析Reference类弱引用，软引用和虚引用都继承自Reference类，我们从Reference类看起 // 此Reference对象可能会有四种状态：active, pending, enqueued, inactive // avtive: 新创建的对象状态是active // pending: 当Reference所指向的对象不可达，并且Reference与一个引用队列关联，那么垃圾收集器 // 会将Reference标记为pending，并且会将之加到pending队列里面 // enqueued: 当Reference从pending队列中，移到引用队列中之后，就是enqueued状态 // inactive: 如果Reference所指向的对象不可达，并且Reference没有与引用队列关联，Reference // 从引用队列移除之后，变为inactive状态。inactive就是最终状态 public abstract class Reference&lt;T&gt; &#123; // 该对象就是Reference所指向的对象，垃圾收集器会对此对象做特殊处理。 private T referent; /* Treated specially by GC */ // Reference相关联的引用队列 volatile ReferenceQueue&lt;? super T&gt; queue; // 当Reference是active时，next为null // 当该Reference处于引用队列中时，next指向队列中的下一个Reference // 其他情况next指向this，即自己 // 垃圾收集器只需判断next是不是为null，来看是否需要对此Reference做特殊处理 volatile Reference next; // 当Reference在pending队列中时，该值指向下一个队列中Reference对象 // 另外垃圾收集器在GC过程中，也会用此对象做标记 transient private Reference&lt;T&gt; discovered; /* used by VM */ // 锁对象 static private class Lock &#123; &#125; private static Lock lock = new Lock(); // pending队列，这里的pending是pending链表的队首元素，一般与上面的discovered变量一起使用 private static Reference&lt;Object&gt; pending = null; // 获取Reference指向的对象。默认返回referent对象 public T get() &#123; return this.referent; &#125; &#125; Reference类跟垃圾收集器紧密关联，其状态变化如下图所示： 上述步骤大多数都是由GC线程来完成，其中Pending到Enqueued是用户线程来做的。Reference类中定义了一个子类ReferenceHandler，专门用来处理Pending状态的Reference。我们来看看它具体做了什么。 ReferenceHandler类public abstract class Reference&lt;T&gt; &#123; // 静态块，主要逻辑是启动ReferenceHandler线程 static &#123; // 创建ReferenceHandler线程 ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread handler = new ReferenceHandler(tg, &quot;Reference Handler&quot;); // 设置成守护线程，最高优先级，并启动 handler.setPriority(Thread.MAX_PRIORITY); handler.setDaemon(true); handler.start(); // 访问控制 SharedSecrets.setJavaLangRefAccess(new JavaLangRefAccess() &#123; @Override public boolean tryHandlePendingReference() &#123; return tryHandlePending(false); &#125; &#125;); &#125; // 内部类ReferenceHandler，用来处理Pending状态的Reference private static class ReferenceHandler extends Thread &#123; private static void ensureClassInitialized(Class&lt;?&gt; clazz) &#123; try &#123; Class.forName(clazz.getName(), true, clazz.getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw (Error) new NoClassDefFoundError(e.getMessage()).initCause(e); &#125; &#125; // 静态块，确保InterruptedException和Cleaner已经被ClassLoader加载 // 因为后面会用到这两个类 static &#123; ensureClassInitialized(InterruptedException.class); ensureClassInitialized(Cleaner.class); &#125; ReferenceHandler(ThreadGroup g, String name) &#123; super(g, name); &#125; public void run() &#123; // 死循环调用tryHandlePending方法 while (true) &#123; tryHandlePending(true); &#125; &#125; &#125; &#125; Reference类在加载进JVM的时候，会启动ReferenceHandler线程，并将它设成最高优先级的守护线程，不断循环调用tryHandlePending方法。接下来看tryHandlePending方法： // waitForNotify默认是true。 static boolean tryHandlePending(boolean waitForNotify) &#123; Reference&lt;Object&gt; r; Cleaner c; try &#123; // 需要在同步块中进行 synchronized (lock) &#123; // 判断pending队列是否为空，pending是队首元素 if (pending != null) &#123; // 取到pending队列队首元素，赋值给r r = pending; // Cleaner类是Java NIO中专门用来清理堆外内存(DirectByteBufer)的类，这里对它做了特殊处理 // 当没有其他引用指向堆外内存时，与之关联的Cleaner会被加到pending队列中 // 如果该Reference是Cleaner实例，那么取到该Cleaner，后续可以做一些清理操作。 c = r instanceof Cleaner ? (Cleaner) r : null; // r.discovered就是下一个元素 // 以下操作即为将队首元素从pending队列移除 pending = r.discovered; r.discovered = null; &#125; else &#123; // 如果pending队列为空，则释放锁等待 // 当有Reference添加到pending队列中时，ReferenceHandler线程会从此处被唤醒 if (waitForNotify) &#123; lock.wait(); &#125; return waitForNotify; &#125; &#125; &#125; catch (OutOfMemoryError x) &#123; // OOM时，让出cpu Thread.yield(); return true; &#125; catch (InterruptedException x) &#123; return true; &#125; // 给Cleaner的特殊处理，调用clean()方法，以释放与之关联的堆外内存 if (c != null) &#123; c.clean(); return true; &#125; // 此处，将此Reference加入到与之关联的引用队列 ReferenceQueue&lt;? super Object&gt; q = r.queue; if (q != ReferenceQueue.NULL) q.enqueue(r); return true; &#125; 看到这里，豁然开朗。ReferenceHandler线程专门用来处理pending状态的Reference，跟GC线程组成类似生产者消费者的关系。当pending队列为空，则等待；当Reference关联的对象被回收，Reference被加入到pending队列中之后，ReferenceHandler线程会被唤醒来处理pending的Reference，主要做三件事： 将该Reference从pending队列移除 如果该Reference是Cleaner的实例，那么调用clean方法，释放堆外内存 将Reference加入到与之关联的引用队列 软引用SoftReference// 相比WeakReference，它增加了两个时间戳，clock和timestamp // 这两个参数是实现他们内存回收上区别的关键 public class SoftReference&lt;T&gt; extends Reference&lt;T&gt; &#123; // 每次GC之后，若该引用指向的对象没有被回收，则垃圾收集器会将clock更新成当前时间 static private long clock; // 每次调用get方法的时候，会更新该时间戳为clock值 // 所以该值保存的是上一次(最近一次)GC的时间戳 private long timestamp; public SoftReference(T referent) &#123; super(referent); this.timestamp = clock; &#125; public SoftReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); this.timestamp = clock; &#125; // 每次调用，更新timestamp的值，使之等于clock的值，即最近一次gc的时间 public T get() &#123; T o = super.get(); if (o != null &amp;&amp; this.timestamp != clock) this.timestamp = clock; return o; &#125; &#125; SoftReference除了多了两个时间戳之外，跟WeakReference几乎没有区别，它是如何做到在内存不足时被回收这件事的呢？其实这是垃圾收集器干的活。垃圾收集器回收SoftReference所指向的对象，会看两个维度： SoftReference.timestamp有多老(距上一次GC过了多久) JVM的堆空闲空间有多大 而具体什么时候回收SoftReference所指向的对象呢，可以参考如下公式： interval &lt;&#x3D; free_heap * ms_per_mb 其中interval为上一次GC与当前时间的差值，以毫秒为单位；free_heap为当前JVM中剩余的堆空间大小，以MB为单位；ms_per_mb可以理解为一个常数，即每兆空闲空间可维持的SoftReference的对象生存的时长，默认为1000，可以通过JVM参数-XX:SoftRefLRUPolicyMSPerMB设置。如果上述表达式返回false，则清理SoftReference所指向的对象，并将该SoftReference加入到pending队列中；否则不做处理。所以说在JVM内存不足的时候回收软引用这个说法不是非常准确，只是个经验说法，软引用的回收，还跟它存活的时间有关，甚至跟JVM参数设置(-XX:SoftRefLRUPolicyMSPerMB)都有关系！ 弱引用(WeakReference)// 更加简单，只重写了两个构造方法 public class WeakReference&lt;T&gt; extends Reference&lt;T&gt; &#123; public WeakReference(T referent) &#123; super(referent); &#125; public WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125; &#125; 虚引用(PhantomReference)一般用于获取被回收的时候的通知，比如NIO的直接内存属于JVM之外的，就用了这个实现的 具体可以看Cleaner类 // 灰常简单，只重写了一个构造方法，一个get方法 public class PhantomReference&lt;T&gt; extends Reference&lt;T&gt; &#123; // get方法永远返回null public T get() &#123; return null; &#125; // 只提供了一个包含ReferenceQueue的构造方法，说明它必须和引用队列一起使用 public PhantomReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125; &#125; 终结器引用（FinalReference 与 Finalizer）因为jvm只能管理jvm内存空间，但是对于应用运行时需要的其它native资源(jvm通过jni暴漏出来的功能)：例如直接内存DirectByteBuffer，网络连接SocksSocketImpl，文件流FileInputStream等与操作系统有交互的资源，jvm就无能为力了，需要我们自己来调用释放这些资源方法来释放，为了避免对象死了之后，程序员忘记手动释放这些资源，导致这些对象有的外部资源泄露，java提供了finalizer机制通过重写对象的finalizer方法，在这个方法里面执行释放对象占用的外部资源的操作，这样使用这些资源的程序员即使忘记手动释放，jvm也可以在回收对象之前帮助释放掉这些外部资源，帮助我们调用这个方法回收资源的线程就是我们在导出jvm线程栈时看到的名为Finalizer的守护线程； /** * Final references, used to implement finalization */ class FinalReference&lt;T&gt; extends Reference&lt;T&gt; &#123; public FinalReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125; &#125; 相关链接How Hotspot Clear SoftreferenceFinalReference类的功能FinalReference和Finalizer的源码分析","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"引用类型","slug":"引用类型","permalink":"https://blog.unclezs.com/tags/%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"},{"name":"虚引用","slug":"虚引用","permalink":"https://blog.unclezs.com/tags/%E8%99%9A%E5%BC%95%E7%94%A8/"},{"name":"弱引用","slug":"弱引用","permalink":"https://blog.unclezs.com/tags/%E5%BC%B1%E5%BC%95%E7%94%A8/"}],"author":"Unclezs"},{"title":"ThreadLocal与FastThreadLocal","slug":"Java/并发编程/ThreadLocal与FastThreadLocal","date":"2020-12-17T03:54:01.000Z","updated":"2020-12-17T03:54:01.000Z","comments":true,"path":"Java/并发编程/ThreadLocal与FastThreadLocal.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal%E4%B8%8EFastThreadLocal.html","excerpt":"ThreadLocal简介ThreadLocal使用场合主要解决多线程中数据数据因并发产生不一致问题。ThreadLocal为每个线程的中并发访问的数据提供一个副本，通过访问副本来运行业务，这样的结果是耗费了内存，单大大减少了线程同步所带来性能消耗，也减少了线程并发控制的复杂度。ThreadLocal不能使用基本数据类型，只能使用Object类型。 实现ThreadLocal就是绑定在线程上的，可以让每个线程可以存储隔离的线程安全的数据。 其实现就是在Thread类的本地变量中存储ThreadLocal.ThreadlocalMap一个成员变量。 public class Thread implements Runnable &#123; ......(其他源码) /* * 当前线程的ThreadLocalMap，主要存储该线程自身的ThreadLocal * 本文主要讨论的就是这个ThreadLocalMap */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal，自父线程集成而来的ThreadLocalMap， * 主要用于父子线程间ThreadLocal变量的传递 */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; &#125; 然后在设置的时候直接使用当前ThreadLocal变量为key到Thread中的ThreadLocalMap中取值，可以看到这里的ThreadlocalMap是一个hash结构。 public class ThreadLocal&#123; public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) //key为自己声明的threadLocal map.set(this, value); else //创建一个ThreadLocalmap createMap(t, value); &#125; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; //setInitialValue就是可以在没有设置当前线程的threadlocal的初始值，可以自己定义默认为null return setInitialValue(); &#125; &#125; InheritableThreadLocal子线程共享","text":"ThreadLocal简介ThreadLocal使用场合主要解决多线程中数据数据因并发产生不一致问题。ThreadLocal为每个线程的中并发访问的数据提供一个副本，通过访问副本来运行业务，这样的结果是耗费了内存，单大大减少了线程同步所带来性能消耗，也减少了线程并发控制的复杂度。ThreadLocal不能使用基本数据类型，只能使用Object类型。 实现ThreadLocal就是绑定在线程上的，可以让每个线程可以存储隔离的线程安全的数据。 其实现就是在Thread类的本地变量中存储ThreadLocal.ThreadlocalMap一个成员变量。 public class Thread implements Runnable &#123; ......(其他源码) /* * 当前线程的ThreadLocalMap，主要存储该线程自身的ThreadLocal * 本文主要讨论的就是这个ThreadLocalMap */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal，自父线程集成而来的ThreadLocalMap， * 主要用于父子线程间ThreadLocal变量的传递 */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; &#125; 然后在设置的时候直接使用当前ThreadLocal变量为key到Thread中的ThreadLocalMap中取值，可以看到这里的ThreadlocalMap是一个hash结构。 public class ThreadLocal&#123; public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) //key为自己声明的threadLocal map.set(this, value); else //创建一个ThreadLocalmap createMap(t, value); &#125; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; //setInitialValue就是可以在没有设置当前线程的threadlocal的初始值，可以自己定义默认为null return setInitialValue(); &#125; &#125; InheritableThreadLocal子线程共享InheritableThreadLocal主要用于子线程创建时，需要自动继承父线程的ThreadLocal变量，方便必要信息的进一步传递。 public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125; &#125; 在新建线程的init方法中如果inheritThreadLocals为true则会继承，默认是true.并且是使用InheritableThreadLocal的才能继承，判断条件就是thread.inheritableThreadLocals是不是为null，而InheritableThreadLocal.createMap就是将threadlocalMap重写为了inheritableThreadLocals 示例 @Slf4j public class InheritableThreadLocalSample &#123; private static InheritableThreadLocal&lt;String&gt; inheritableThreadLocal = new InheritableThreadLocal&lt;&gt;(); private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; Thread parent = new Thread(() -&gt; &#123; threadLocal.set(&quot;uncle&quot;); inheritableThreadLocal.set(&quot;uncle&quot;); log.info(&quot;父线程的值：threadLocal:&#123;&#125;,inheritableThreadLocal:&#123;&#125;&quot;, threadLocal.get(),inheritableThreadLocal.get()); Thread child = new Thread(() -&gt; &#123; log.info(&quot;父线程的值：threadLocal:&#123;&#125;,inheritableThreadLocal:&#123;&#125;&quot;, threadLocal.get(),inheritableThreadLocal.get()); &#125;,&quot;child thread&quot;); child.start(); &#125;,&quot;parent thread&quot;); parent.start(); &#125; &#125; 输出 2020-12-17 17:11:59 [parent thread] INFO com.unclezs.samples.java.thread.threadlocal.InheritableThreadLocalSample #lambda$main$1:18 - 父线程的值：threadLocal:uncle,inheritableThreadLocal:uncle 2020-12-17 17:11:59 [child thread] INFO com.unclezs.samples.java.thread.threadlocal.InheritableThreadLocalSample #lambda$null$0:20 - 父线程的值：threadLocal:null,inheritableThreadLocal:uncle 内存泄漏问题使用的时候注意ThreadLocal用完之后没用的要释放掉，以免造成内存泄漏。为什么不释放就可能照成内存泄漏呢？JVM不会回收吗？ 首先看看ThreadLocalMap的结构，也是哈希结构，不过是开放地址法解决冲突的 static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 开放地址法找到合适的位置 for (Entry e = tab[i] ;e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //已经存在直接设置value if (k == key) &#123; e.value = value; return; &#125; //entity存在，但是弱引用key threadlocal已经被回收了 获取到的key为null if (k == null) &#123; //直接覆盖这个已经被回收的key的位置 放入新的 replaceStaleEntry(key, value, i); return; &#125; &#125; //不存在冲突 tab[i] = new Entry(key, value); int sz = ++size; //先清理已经被回收了的，范围是keyindex-&gt;size 判断是否需要扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; &#125; 所以这里可以看出来，首先Entity是个弱引用对象，引用对象为ThreadLocal，所以ThreadLocal只要发生了GC了就会被回收，这个时候Entity中的样子就变成了： key=null,value=xx 虽然key threadlocal被回收了，但是value并没有被回收，而且entity也还是在table数组中强引用占用着内存。所以如果不处理这些数据就有可能造成内存泄漏 你可以想象，我们平时使用线程池，这个线程复用技术，因为ThreadLocal实现还是在Thread中放一个ThreadLocalMap，如果复用了Thread也代表会重复用这个ThreadLocalMap，如果一个线程在使用完ThreadLocal之后，另一个线程又拿过来用，导致ThreadLocalMap里面的一直没有正常释放，甚至越放越多。最终导致每个线程里面的ThreadLocalMap都有大量数据，导致内存泄漏 虽然ThreadLocalMap会在set，get以及resize等方法中对stale slots做自动删除（set以及get不保证所有过期slots会在操作中会被删除，而resize则会删除threadLocalMap中所有的过期slots）。但是最佳的实践还是用put就有对应的remove才行 比如用户登录进行put，用户注销进行remove。 FastThreadLocal这个为什么说快呢？难道Hash存取数据还不够快吗？还有更快的吗？那也只有数组了。 这个实现是在Netty中的，用数组代替了 Hash+开发地址法。因为ThreadLocalMap是放在线程的成员变量中的，所以Netty自己继承出来一个FastThread,里面就包含了个InternalThreadLocalMap，别看名字是map其实是数组实现的。 所以具体要使用FastThreadLocal需要使用FastThread才行。 更多了解去 Netty进阶：自顶向下解析FastThreadLocal","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://blog.unclezs.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"threadLocal","slug":"threadLocal","permalink":"https://blog.unclezs.com/tags/threadLocal/"}],"author":"Unclezs"},{"title":"Maven之自定义插件","slug":"Java/Maven/Maven之自定义插件","date":"2020-12-06T03:26:14.000Z","updated":"2020-12-06T03:26:14.000Z","comments":true,"path":"Java/Maven/Maven之自定义插件.html","link":"","permalink":"https://blog.unclezs.com/Java/Maven/Maven%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%92%E4%BB%B6.html","excerpt":"简介Mojo：Maven plain Old Java Object。每一个 Mojo 就是 Maven 中的一个执行目标（executable goal），而插件则是对单个或多个相关的 Mojo 做统一分发。 一个 Mojo 包含一个简单的 Java 类。插件中多个类似 Mojo 的通用之处可以使用抽象父类来封装。Maven插件项目的打包方式packaging必须为maven-plugin 第一个插件依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;samples-maven&lt;/artifactId&gt; &lt;groupId&gt;com.unclezs&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;packaging&gt;maven-plugin&lt;/packaging&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;hello-maven-plugin&lt;/artifactId&gt; &lt;name&gt;hello-maven-plugin&lt;/name&gt; &lt;description&gt;我的第一maven插件&lt;/description&gt; &lt;properties&gt; &lt;custom.plugin.version&gt;3.6.0&lt;/custom.plugin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-api&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;plexus-utils&lt;/artifactId&gt; &lt;groupId&gt;org.codehaus.plexus&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugin-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;!--自定义插件前缀 mvn xxx:mojoName，默认为xxx-maven-plugin的xxx--&gt; &lt;configuration&gt; &lt;goalPrefix&gt;hello&lt;/goalPrefix&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 编写mojo/** * @author blog.unclezs.com * @date 2020/12/6 2:51 上午 */ @Mojo(name = &quot;custom&quot;) public class CustomPlugin extends AbstractMojo &#123; @Override public void execute() throws MojoExecutionException, MojoFailureException &#123; getLog().info(&quot;hello maven plugin!!!&quot;); &#125; &#125; 安装到本地仓库maven clean install -U","text":"简介Mojo：Maven plain Old Java Object。每一个 Mojo 就是 Maven 中的一个执行目标（executable goal），而插件则是对单个或多个相关的 Mojo 做统一分发。 一个 Mojo 包含一个简单的 Java 类。插件中多个类似 Mojo 的通用之处可以使用抽象父类来封装。Maven插件项目的打包方式packaging必须为maven-plugin 第一个插件依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;samples-maven&lt;/artifactId&gt; &lt;groupId&gt;com.unclezs&lt;/groupId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/parent&gt; &lt;packaging&gt;maven-plugin&lt;/packaging&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;hello-maven-plugin&lt;/artifactId&gt; &lt;name&gt;hello-maven-plugin&lt;/name&gt; &lt;description&gt;我的第一maven插件&lt;/description&gt; &lt;properties&gt; &lt;custom.plugin.version&gt;3.6.0&lt;/custom.plugin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-api&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;plexus-utils&lt;/artifactId&gt; &lt;groupId&gt;org.codehaus.plexus&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugin-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;custom.plugin.version&#125;&lt;/version&gt; &lt;!--自定义插件前缀 mvn xxx:mojoName，默认为xxx-maven-plugin的xxx--&gt; &lt;configuration&gt; &lt;goalPrefix&gt;hello&lt;/goalPrefix&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 编写mojo/** * @author blog.unclezs.com * @date 2020/12/6 2:51 上午 */ @Mojo(name = &quot;custom&quot;) public class CustomPlugin extends AbstractMojo &#123; @Override public void execute() throws MojoExecutionException, MojoFailureException &#123; getLog().info(&quot;hello maven plugin!!!&quot;); &#125; &#125; 安装到本地仓库maven clean install -U 测试插件再另个一项目下引入 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.unclezs&lt;/groupId&gt; &lt;artifactId&gt;hello-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;!--这个如果加上mvn compile的时候自动执行--&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 然后执行 mvn hello:custom mvn com.unclezs:hello-maven-plugin:1.0:custom mvn groupId:artifactId:version:goal 参数传递package com.unclezs; import org.apache.maven.plugin.AbstractMojo; import org.apache.maven.plugin.MojoExecutionException; import org.apache.maven.plugin.MojoFailureException; import org.apache.maven.plugins.annotations.Mojo; import org.apache.maven.plugins.annotations.Parameter; import java.io.File; import java.net.URL; import java.util.*; /** * @author blog.unclezs.com * @date 2020/12/6 2:51 上午 */ @Mojo(name = &quot;param&quot;) public class ParameterPlugin extends AbstractMojo &#123; @Parameter(property = &quot;param.name&quot;, defaultValue = &quot;$&#123;project.artifactId&#125;&quot;) private String name; @Parameter private Integer number; @Parameter private Boolean bool; @Parameter private Double doubleValue; @Parameter private Date date; @Parameter private File file; @Parameter private URL url; @Parameter private Color color; @Parameter private String[] array; @Parameter private List&lt;String&gt; list; @Parameter private Map&lt;String, String&gt; map; @Parameter private Properties properties; @Parameter private User obj; @Override public void execute() throws MojoExecutionException, MojoFailureException &#123; getLog().info(&quot;String:&quot;+name); getLog().info(&quot;Integer:&quot; + number); getLog().info(&quot;Boolean:&quot; + bool); getLog().info(&quot;Double:&quot; + doubleValue); getLog().info(&quot;Date:&quot; + date); getLog().info(&quot;File:&quot; + file.getName()); getLog().info(&quot;URL:&quot; + url); getLog().info(&quot;enum:&quot; + color); getLog().info(&quot;array:&quot; + Arrays.toString(array)); getLog().info(&quot;List:&quot; + list); getLog().info(&quot;Map:&quot; + map); getLog().info(&quot;Properties:&quot; + properties); getLog().info(&quot;obj:&quot; + obj); &#125; public enum Color &#123; GREEN, RED, BLUE &#125; &#125; 对应的引用时候传值 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.unclezs&lt;&#x2F;groupId&gt; &lt;artifactId&gt;hello-maven-plugin&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0&lt;&#x2F;version&gt; &lt;configuration&gt; &lt;name&gt;unclezs&lt;&#x2F;name&gt; &lt;number&gt;123&lt;&#x2F;number&gt; &lt;bool&gt;true&lt;&#x2F;bool&gt; &lt;doubleValue&gt;1.0&lt;&#x2F;doubleValue&gt; &lt;date&gt;2005-10-06 2:22:55.1 PM&lt;&#x2F;date&gt; &lt;file&gt;$&#123;project.basedir&#125;&#x2F;pom.xml&lt;&#x2F;file&gt; &lt;url&gt;https:&#x2F;&#x2F;blog.unclezs.com&lt;&#x2F;url&gt; &lt;color&gt;GREEN&lt;&#x2F;color&gt; &lt;array&gt; &lt;param&gt;value1&lt;&#x2F;param&gt; &lt;param&gt;value2&lt;&#x2F;param&gt; &lt;&#x2F;array&gt; &lt;list&gt; &lt;param&gt;value1&lt;&#x2F;param&gt; &lt;param&gt;value2&lt;&#x2F;param&gt; &lt;&#x2F;list&gt; &lt;map&gt; &lt;key1&gt;value1&lt;&#x2F;key1&gt; &lt;key2&gt;value2&lt;&#x2F;key2&gt; &lt;&#x2F;map&gt; &lt;properties&gt; &lt;property&gt; &lt;name&gt;propertyName1&lt;&#x2F;name&gt; &lt;value&gt;propertyValue1&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;propertyName2&lt;&#x2F;name&gt; &lt;value&gt;propertyValue2&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;properties&gt; &lt;obj&gt; &lt;age&gt;12&lt;&#x2F;age&gt; &lt;name&gt;uncle&lt;&#x2F;name&gt; &lt;&#x2F;obj&gt; &lt;&#x2F;configuration&gt; &lt;!--这个如果加上mvn compile的时候自动执行--&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;&#x2F;phase&gt; &lt;goals&gt; &lt;goal&gt;custom&lt;&#x2F;goal&gt; &lt;&#x2F;goals&gt; &lt;&#x2F;execution&gt; &lt;&#x2F;executions&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt; 测试输出 更多细节查看plugin-parameters 相关链接 Plugin Developers Centre 示例代码","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://blog.unclezs.com/categories/Java/Maven/"}],"tags":[{"name":"插件","slug":"插件","permalink":"https://blog.unclezs.com/tags/%E6%8F%92%E4%BB%B6/"}],"author":"Unclezs"},{"title":"Model高效转换神器之MapStruct","slug":"Java/工具/Model高效转换神器之MapStruct","date":"2020-12-05T10:23:56.000Z","updated":"2020-12-05T10:23:56.000Z","comments":true,"path":"Java/工具/Model高效转换神器之MapStruct.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B7%A5%E5%85%B7/Model%E9%AB%98%E6%95%88%E8%BD%AC%E6%8D%A2%E7%A5%9E%E5%99%A8%E4%B9%8BMapStruct.html","excerpt":"简介MapStruct是一种注释处理器，用于生成类型安全，高性能和无依赖的Bean映射代码。解决了我们日常在各种Vo、Dto、Model之间的转换难题。 有人问不是有BeanUtil了吗，为什么还要这么累赘的写这样的转换器？ BeanUtil原理是利用反射，所以效率低，MapStruct是在编译时生成代码效率高 BeanUtil的只是名称类型相同的的转换比较方便 MapStruct支持各种复杂类型的转换。 配置依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;properties&gt; &lt;org.mapstruct.version&gt;1.4.1.Final&lt;/org.mapstruct.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;!--如果有用Lombok需要添加下面这个，注意顺序--&gt; &lt;path&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 入门案例用了lombok，不用也一样，自己写getter、setter 示例代码在samples-mapstruct @Data @AllArgsConstructor @NoArgsConstructor public class UserDto &#123; private String age; private String name; &#125; @Data @AllArgsConstructor @NoArgsConstructor public class User &#123; private String age; private String name; &#125;","text":"简介MapStruct是一种注释处理器，用于生成类型安全，高性能和无依赖的Bean映射代码。解决了我们日常在各种Vo、Dto、Model之间的转换难题。 有人问不是有BeanUtil了吗，为什么还要这么累赘的写这样的转换器？ BeanUtil原理是利用反射，所以效率低，MapStruct是在编译时生成代码效率高 BeanUtil的只是名称类型相同的的转换比较方便 MapStruct支持各种复杂类型的转换。 配置依赖&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;properties&gt; &lt;org.mapstruct.version&gt;1.4.1.Final&lt;/org.mapstruct.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;!--如果有用Lombok需要添加下面这个，注意顺序--&gt; &lt;path&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 入门案例用了lombok，不用也一样，自己写getter、setter 示例代码在samples-mapstruct @Data @AllArgsConstructor @NoArgsConstructor public class UserDto &#123; private String age; private String name; &#125; @Data @AllArgsConstructor @NoArgsConstructor public class User &#123; private String age; private String name; &#125; 编写Mapper @Mapper public interface UserMapper &#123; UserMapper INSTANCE = Mappers.getMapper(UserMapper.class); User userDto2User(UserDto userDto); UserDto userDto2User(User user); &#125; 测试代码 @Slf4j public class MapStructSample &#123; public static void main(String[] args) &#123; User user = new User(&quot;123&quot;, &quot;uncle&quot;); UserDto userDto = UserMapper.INSTANCE.userDto2User(user); log.info(&quot;&#123;&#125;&quot;,userDto); &#125; &#125; 输出 18:20:14.886 [main] INFO com.unclezs.samples.mapstruct.MapStructSample - UserDto(age&#x3D;123, name&#x3D;uncle) 可以看到生成了代码 不同的属性名@Data @AllArgsConstructor @NoArgsConstructor public class PersonDto &#123; private String cname; &#125; @Data @AllArgsConstructor @NoArgsConstructor public class Person &#123; private String name; &#125; @Mapper public interface PersonMapper &#123; PersonMapper INSTANCE = Mappers.getMapper(PersonMapper.class); @Mapping(source = &quot;name&quot;,target = &quot;cname&quot;) PersonDto personToPersonDto(Person user); &#125; 属性嵌套@Data @AllArgsConstructor @NoArgsConstructor public class PersonVo &#123; private String cname; private String userName; private String userAge; &#125; @Mapper public interface PersonMapper &#123; PersonMapper INSTANCE = Mappers.getMapper(PersonMapper.class); @Mapping(source = &quot;name&quot;, target = &quot;cname&quot;) PersonDto personToPersonDto(Person user); @Mapping(source = &quot;user&quot;,target = &quot;guest&quot;) @Mapping(source = &quot;name&quot;,target = &quot;cname&quot;) PersonDto personToPersonDtoNested(Person person); @Mapping(source = &quot;user.name&quot;,target = &quot;userName&quot;) @Mapping(source = &quot;user.age&quot;,target = &quot;userAge&quot;) @Mapping(source = &quot;name&quot;,target = &quot;cname&quot;) PersonVo personToPersonVoNestedProperty(Person person); &#125; 测试 @Test public void testNested() &#123; Person person = new Person(); person.setName(&quot;uncle&quot;); User user = new User(&quot;123&quot;, &quot;uncle&quot;); person.setUser(user); PersonDto personDto = PersonMapper.INSTANCE.personToPersonDtoNested(person); Assert.assertEquals(&quot;uncle&quot;, personDto.getCname()); Assert.assertEquals(&quot;uncle&quot;, personDto.getGuest().getName()); &#125; @Test public void testNestedToProperty() &#123; Person person = new Person(); person.setName(&quot;uncle&quot;); User user = new User(&quot;123&quot;, &quot;uncle&quot;); person.setUser(user); PersonVo personVo = PersonMapper.INSTANCE.personToPersonVoNestedProperty(person); Assert.assertEquals(&quot;uncle&quot;, personVo.getCname()); Assert.assertEquals(&quot;uncle&quot;, personVo.getUserName()); &#125; 相关链接官方文档github官方地址","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://blog.unclezs.com/categories/Java/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"高效工具","slug":"高效工具","permalink":"https://blog.unclezs.com/tags/%E9%AB%98%E6%95%88%E5%B7%A5%E5%85%B7/"},{"name":"mapper","slug":"mapper","permalink":"https://blog.unclezs.com/tags/mapper/"},{"name":"mapstruct","slug":"mapstruct","permalink":"https://blog.unclezs.com/tags/mapstruct/"},{"name":"属性转换","slug":"属性转换","permalink":"https://blog.unclezs.com/tags/%E5%B1%9E%E6%80%A7%E8%BD%AC%E6%8D%A2/"}],"author":"Unclezs"},{"title":"logback源码分析","slug":"Java/日志框架/12.logback源码分析","date":"2020-12-04T15:53:05.000Z","updated":"2020-12-04T15:53:05.000Z","comments":true,"path":"Java/日志框架/12.logback源码分析.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/12.logback%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html","excerpt":"从一个Logger获取说起 public static Logger getLogger(Class&lt;?&gt; clazz) &#123; //获取Logger Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format(&quot;Detected logger name mismatch. Given name: \\&quot;%s\\&quot;; computed name: \\&quot;%s\\&quot;.&quot;, logger.getName(), autoComputedCallingClass.getName())); Util.report(&quot;See &quot; + LOGGER_NAME_MISMATCH_URL + &quot; for an explanation&quot;); &#125; &#125; return logger; &#125; 在跟进Logger logger = getLogger(clazz.getName());方法 public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name); &#125; 这个方法就是初始化LoggerContext，如果没有初始化则调用performInitialization进行初始化，初始化了就直接返回 public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(&quot;Unreachable code&quot;); &#125; 再看看performInitialization()方法，里面就一个绑定和校验 private final static void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125; &#125; 比较核心的方法bind()： private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; //这里通过findPossibleStaticLoggerBinderPathSet查找类路径下的org/slf4j/impl/StaticLoggerBinder.class //如果有多个或者没有则记录错误信息 if (!isAndroid()) &#123; staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; //这个是直接引入StaticLoggerBinder方式进行加注，这个初始化的时候会在static代码块中执行init方式加载配置 //如果Jar包中没有这个类则会报错NoClassDefFoundError，多个的话Jvm优先选择先被加载的那个实现。 StaticLoggerBinder.getSingleton(); //初始化成功 INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; //显示真实选择的实现类 reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report(&quot;Failed to load class \\&quot;org.slf4j.impl.StaticLoggerBinder\\&quot;.&quot;); Util.report(&quot;Defaulting to no-operation (NOP) logger implementation&quot;); Util.report(&quot;See &quot; + NO_STATICLOGGERBINDER_URL + &quot; for further details.&quot;); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains(&quot;org.slf4j.impl.StaticLoggerBinder.getSingleton()&quot;)) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report(&quot;slf4j-api 1.6.x (or later) is incompatible with this binding.&quot;); Util.report(&quot;Your binding is version 1.5.5 or earlier.&quot;); Util.report(&quot;Upgrade your binding to version 1.6.x.&quot;); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException(&quot;Unexpected initialization failure&quot;, e); &#125; &#125;","text":"从一个Logger获取说起 public static Logger getLogger(Class&lt;?&gt; clazz) &#123; //获取Logger Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format(&quot;Detected logger name mismatch. Given name: \\&quot;%s\\&quot;; computed name: \\&quot;%s\\&quot;.&quot;, logger.getName(), autoComputedCallingClass.getName())); Util.report(&quot;See &quot; + LOGGER_NAME_MISMATCH_URL + &quot; for an explanation&quot;); &#125; &#125; return logger; &#125; 在跟进Logger logger = getLogger(clazz.getName());方法 public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name); &#125; 这个方法就是初始化LoggerContext，如果没有初始化则调用performInitialization进行初始化，初始化了就直接返回 public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(&quot;Unreachable code&quot;); &#125; 再看看performInitialization()方法，里面就一个绑定和校验 private final static void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125; &#125; 比较核心的方法bind()： private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; //这里通过findPossibleStaticLoggerBinderPathSet查找类路径下的org/slf4j/impl/StaticLoggerBinder.class //如果有多个或者没有则记录错误信息 if (!isAndroid()) &#123; staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; //这个是直接引入StaticLoggerBinder方式进行加注，这个初始化的时候会在static代码块中执行init方式加载配置 //如果Jar包中没有这个类则会报错NoClassDefFoundError，多个的话Jvm优先选择先被加载的那个实现。 StaticLoggerBinder.getSingleton(); //初始化成功 INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; //显示真实选择的实现类 reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report(&quot;Failed to load class \\&quot;org.slf4j.impl.StaticLoggerBinder\\&quot;.&quot;); Util.report(&quot;Defaulting to no-operation (NOP) logger implementation&quot;); Util.report(&quot;See &quot; + NO_STATICLOGGERBINDER_URL + &quot; for further details.&quot;); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains(&quot;org.slf4j.impl.StaticLoggerBinder.getSingleton()&quot;)) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report(&quot;slf4j-api 1.6.x (or later) is incompatible with this binding.&quot;); Util.report(&quot;Your binding is version 1.5.5 or earlier.&quot;); Util.report(&quot;Upgrade your binding to version 1.6.x.&quot;); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException(&quot;Unexpected initialization failure&quot;, e); &#125; &#125; StaticLoggerBinder.getSingleton();看看具体做了些什么 //静态代码块初始化 static &#123; SINGLETON.init(); &#125; void init() &#123; try &#123; try &#123; //执行真正的配置自动选择与加载 new ContextInitializer(defaultLoggerContext).autoConfig(); &#125; catch (JoranException je) &#123; Util.report(&quot;Failed to auto configure default logger context&quot;, je); &#125; //这里判断如果没有监听状态信息的话就 查看状态列表有没有warn以上的日志，有就打印到控制台 if (!StatusUtil.contextHasStatusListener(defaultLoggerContext)) &#123; StatusPrinter.printInCaseOfErrorsOrWarnings(defaultLoggerContext); &#125; contextSelectorBinder.init(defaultLoggerContext, KEY); initialized = true; &#125; catch (Exception t) &#123; // see LOGBACK-1159 Util.report(&quot;Failed to instantiate [&quot; + LoggerContext.class.getName() + &quot;]&quot;, t); &#125; &#125; 看看 new ContextInitializer(defaultLoggerContext).autoConfig();到底是怎么做的 public void autoConfig() throws JoranException &#123; StatusListenerConfigHelper.installIfAsked(loggerContext); //找到具体的配置文件 logback-test.xml&gt;logback.groovy&gt;logback.xml URL url = findURLOfDefaultConfigurationFile(true); if (url != null) &#123; //执行装载配置 configureByResource(url); &#125; else &#123; //如果没有上面的xml、groovy配置到执行则查询SPI,找Configurator的实现类 Configurator c = EnvUtil.loadFromServiceLoader(Configurator.class); if (c != null) &#123; try &#123; c.setContext(loggerContext); c.configure(loggerContext); &#125; catch (Exception e) &#123; throw new LogbackException(String.format(&quot;Failed to initialize Configurator: %s using ServiceLoader&quot;, c != null ? c.getClass() .getCanonicalName() : &quot;null&quot;), e); &#125; &#125; else &#123; //确实没有用户自定义配置，使用默认配置 BasicConfigurator basicConfigurator = new BasicConfigurator(); basicConfigurator.setContext(loggerContext); basicConfigurator.configure(loggerContext); &#125; &#125; &#125; 配置完成之后回到init方法，回去执行contextSelectorBinder.init(defaultLoggerContext, KEY); 这里面主要是解决日志分离问题，通过VM参数指定logback.ContextSelector来配置ContextSelector实现日志分离 public void init(LoggerContext defaultLoggerContext, Object key) throws ClassNotFoundException, NoSuchMethodException, InstantiationException, IllegalAccessException, InvocationTargetException &#123; if (this.key == null) &#123; this.key = key; &#125; else if (this.key != key) &#123; throw new IllegalAccessException(&quot;Only certain classes can access this method.&quot;); &#125; String contextSelectorStr = OptionHelper.getSystemProperty(ClassicConstants.LOGBACK_CONTEXT_SELECTOR); if (contextSelectorStr == null) &#123; contextSelector = new DefaultContextSelector(defaultLoggerContext); &#125; else if (contextSelectorStr.equals(&quot;JNDI&quot;)) &#123; // if jndi is specified, let&#x27;s use the appropriate class contextSelector = new ContextJNDISelector(defaultLoggerContext); &#125; else &#123; contextSelector = dynamicalContextSelector(defaultLoggerContext, contextSelectorStr); &#125; &#125; 到这里就初始化完成了。状态也变为了SUCCESSFUL_INITIALIZATION，performInitialization方法执行完成。返回了StaticLoggerBinder.getSingleton().getLoggerFactory(); public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(&quot;Unreachable code&quot;); &#125; 返回了指定的logback自定义ILoggerFactory的实现类LoggerContext public ILoggerFactory getLoggerFactory() &#123; if (!initialized) &#123; return defaultLoggerContext; &#125; if (contextSelectorBinder.getContextSelector() == null) &#123; throw new IllegalStateException(&quot;contextSelector cannot be null. See also &quot; + NULL_CS_URL); &#125; return contextSelectorBinder.getContextSelector().getLoggerContext(); &#125; 在执行了LoggerContext.getLogger()方法，可以看到他在创建Logger的时候会根据.分割的，从左到右依次查找，如果不存在就创建并保存，存在直接返回 @Override public final Logger getLogger(final String name) &#123; if (name == null) &#123; throw new IllegalArgumentException(&quot;name argument cannot be null&quot;); &#125; //名字为ROOT直接返回 根LOGGER if (Logger.ROOT_LOGGER_NAME.equalsIgnoreCase(name)) &#123; return root; &#125; int i = 0; Logger logger = root; //查询已经创建了的Logger Logger childLogger = (Logger) loggerCache.get(name); // 存在直接返回 if (childLogger != null) &#123; return childLogger; &#125; //不存在则按照规则创建，配置日志等级，继承祖先配置 String childName; while (true) &#123; //通过 . 分割Logger等级 划分父子节点 int h = LoggerNameUtil.getSeparatorIndexOf(name, i); if (h == -1) &#123; childName = name; &#125; else &#123; childName = name.substring(0, h); &#125; // 记录当前的分割位置（祖先节点到哪里了） i = h + 1; synchronized (logger) &#123; //这里是遍历子节点，拿到Logger，只找一级 childLogger = logger.getChildByName(childName); //没有子节点了，创建Logger if (childLogger == null) &#123; childLogger = logger.createChildByName(childName); //添加缓存 loggerCache.put(childName, childLogger); incSize(); &#125; &#125; //返回logger logger = childLogger; if (h == -1) &#123; return childLogger; &#125; &#125; &#125; 到这里就拿到了Logger进行了打印日志了，但是注意日志记录加载过程中，会经过turbofilter进行初步过滤，再经过RegularFilter进行过滤Appender，如果Appender都通过了再通过layout格式化日志，在经过Encoder把日志写入输出流显示。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback中使用MDC","slug":"Java/日志框架/11.logback中使用MDC","date":"2020-12-04T15:11:29.000Z","updated":"2020-12-04T15:11:29.000Z","comments":true,"path":"Java/日志框架/11.logback中使用MDC.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/11.logback%E4%B8%AD%E4%BD%BF%E7%94%A8MDC.html","excerpt":"简介logback 设计的目标之一是审计与调试复杂的分布式应用。大部分的分布式系统需要同时处理多个客户端。在一个系统典型的多线程实现中，不同的线程处理不同的客户端。一种可能但是不建议的方式是在每个客户端实例化一个新的且独立的 logger，来区分一个客户端与另一个客户端的日志输出。这种方式会导致 logger 急剧增加并且会增加维护成本。 一种轻量级的技术是给每个为客户端服务的 logger 打一个标记。Neil Harrison 在 Patterns for Logging Diagnostic Messages in Pattern Languages of Program Design 3, edited by R. Martin, D. Riehle, and F. Buschmann (Addison-Wesley, 1997) 这本书中描述了这种方法。logback 在 SLF4J API 利用了这种技术的变体：诊断上下文映射 (MDC)。 为了给每个请求打上唯一的标记，用户需要将上下文信息放到 MDC (Mapped Diagnostic Context 的缩写) 中。下面列出了 MDC 类中主要的部分。 package org.slf4j; public class MDC &#123; // 将上下文的值作为 MDC 的 key 放到ThreadContext的 map 中 public static void put(String key, String val); // 通过 key 获取上下文标识 public static String get(String key); // 通过 key 移除上下文标识 public static void remove(String key); // 清除 MDC 中所有的 entry public static void clear(); &#125; MDC 类中只包含静态方法。它让开发人员可以在 诊断上下文 中放置信息，而后通过特定的 logback 组件去获取。MDC 在 每个线程的基础上 管理上下文信息。通常，当为一个新客户端启动服务时，开发人员会将特定的上文信息插入到 MDC 中。例如，客户端 id，客户端 IP 地址，请求参数等。如果 logback 组件配置得当的话，会自动在每个日志条目中包含这些信息。 请注意，logback-classic 实现的 MDC，假设值以适当的频率放置。还需注意的一点是，子线程不会自动继承父线程的 MDC。 public class MdcSample &#123; public static void main(String[] args) &#123; LoggerHelper.reconfigure(&quot;logback-mdc.xml&quot;); Logger logger = LoggerFactory.getLogger(MdcSample.class); MDC.put(&quot;userId&quot;, &quot;uncle&quot;); MDC.put(&quot;signed&quot;, &quot;true&quot;); logger.info(&quot;user visited home page..&quot;); &#125; &#125; &lt;configuration debug=&quot;true&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;用户：%mdc&#123;userId&#125; $&#123;pattern&#125;&lt;/pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;true&lt;/outputPatternAsHeader&gt; &lt;/encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 用户：uncle 2020-12-04 23:17:59 [main] INFO com.unclezs.samples.log.slf4j.logback.MdcSample - user visited home page..","text":"简介logback 设计的目标之一是审计与调试复杂的分布式应用。大部分的分布式系统需要同时处理多个客户端。在一个系统典型的多线程实现中，不同的线程处理不同的客户端。一种可能但是不建议的方式是在每个客户端实例化一个新的且独立的 logger，来区分一个客户端与另一个客户端的日志输出。这种方式会导致 logger 急剧增加并且会增加维护成本。 一种轻量级的技术是给每个为客户端服务的 logger 打一个标记。Neil Harrison 在 Patterns for Logging Diagnostic Messages in Pattern Languages of Program Design 3, edited by R. Martin, D. Riehle, and F. Buschmann (Addison-Wesley, 1997) 这本书中描述了这种方法。logback 在 SLF4J API 利用了这种技术的变体：诊断上下文映射 (MDC)。 为了给每个请求打上唯一的标记，用户需要将上下文信息放到 MDC (Mapped Diagnostic Context 的缩写) 中。下面列出了 MDC 类中主要的部分。 package org.slf4j; public class MDC &#123; // 将上下文的值作为 MDC 的 key 放到ThreadContext的 map 中 public static void put(String key, String val); // 通过 key 获取上下文标识 public static String get(String key); // 通过 key 移除上下文标识 public static void remove(String key); // 清除 MDC 中所有的 entry public static void clear(); &#125; MDC 类中只包含静态方法。它让开发人员可以在 诊断上下文 中放置信息，而后通过特定的 logback 组件去获取。MDC 在 每个线程的基础上 管理上下文信息。通常，当为一个新客户端启动服务时，开发人员会将特定的上文信息插入到 MDC 中。例如，客户端 id，客户端 IP 地址，请求参数等。如果 logback 组件配置得当的话，会自动在每个日志条目中包含这些信息。 请注意，logback-classic 实现的 MDC，假设值以适当的频率放置。还需注意的一点是，子线程不会自动继承父线程的 MDC。 public class MdcSample &#123; public static void main(String[] args) &#123; LoggerHelper.reconfigure(&quot;logback-mdc.xml&quot;); Logger logger = LoggerFactory.getLogger(MdcSample.class); MDC.put(&quot;userId&quot;, &quot;uncle&quot;); MDC.put(&quot;signed&quot;, &quot;true&quot;); logger.info(&quot;user visited home page..&quot;); &#125; &#125; &lt;configuration debug=&quot;true&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;用户：%mdc&#123;userId&#125; $&#123;pattern&#125;&lt;/pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;true&lt;/outputPatternAsHeader&gt; &lt;/encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 用户：uncle 2020-12-04 23:17:59 [main] INFO com.unclezs.samples.log.slf4j.logback.MdcSample - user visited home page.. 正确移除MDC因为服务端经常会复用线程，MDC又是利用ThreadContext实现的，所以可能会出现脏数据，最好使用一个过滤器在每次请求到来或者结束的时候移除掉MDC中的数据。 可以通过getCopyOfContextMap来装载初始值。 可以查看ch.qos.logback.classic.util.LogbackMDCAdapter了解MDC的实现。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback中的Filter","slug":"Java/日志框架/10.logback中的Filter","date":"2020-12-04T09:18:28.000Z","updated":"2020-12-04T09:18:28.000Z","comments":true,"path":"Java/日志框架/10.logback中的Filter.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/10.logback%E4%B8%AD%E7%9A%84Filter.html","excerpt":"简介logback 过滤器基于三元逻辑，允许它们组装或者链接在一起组成一个任意复杂的过滤策略。它们在很大程度上受到 Linux iptables 的启发。 在 logback-classic 中，有两种类型的过滤器，regular 过滤器以及 turbo 过滤器。 Regularreqular 过滤器继承自 Filter 这个抽象类。本质上它由一个单一的 decide() 方法组成，接收一个 ILoggingEvent 实例作为参数。 过滤器通过一个有序列表进行管理，并且基于三元逻辑。每个过滤器的 decide(ILoggingEvent event) 被依次调用。这个方法返回 FilterReply 枚举值中的一个， DENY, NEUTRAL 或者 ACCEPT。如果 decide() 方法返回 DENY，那么日志事件会被丢弃掉，并且不会考虑后续的过滤器。如果返回的值是 NEUTRAL，那么才会考虑后续的过滤器。如果没有其它的过滤器了，那么日志事件会被正常处理。如果返回值是 ACCEPT，那么会跳过剩下的过滤器而直接被处理。 在 logback-classic 中，过滤器可以被直接添加到 Appender 实例上。通过将一个或者多个过滤器添加到 appender 上，你可以通过任意标准来过滤日志事件。例如，日志消息的内容，MDC 的内容，时间，或者日志事件的其它部分。 自定义过滤器创建一个自己的过滤器非常的简单。只需要继承 Filter 并且实现 decide() 方法就可以了。 自定一个过滤器，把日志内容包含“different”的不打印","text":"简介logback 过滤器基于三元逻辑，允许它们组装或者链接在一起组成一个任意复杂的过滤策略。它们在很大程度上受到 Linux iptables 的启发。 在 logback-classic 中，有两种类型的过滤器，regular 过滤器以及 turbo 过滤器。 Regularreqular 过滤器继承自 Filter 这个抽象类。本质上它由一个单一的 decide() 方法组成，接收一个 ILoggingEvent 实例作为参数。 过滤器通过一个有序列表进行管理，并且基于三元逻辑。每个过滤器的 decide(ILoggingEvent event) 被依次调用。这个方法返回 FilterReply 枚举值中的一个， DENY, NEUTRAL 或者 ACCEPT。如果 decide() 方法返回 DENY，那么日志事件会被丢弃掉，并且不会考虑后续的过滤器。如果返回的值是 NEUTRAL，那么才会考虑后续的过滤器。如果没有其它的过滤器了，那么日志事件会被正常处理。如果返回值是 ACCEPT，那么会跳过剩下的过滤器而直接被处理。 在 logback-classic 中，过滤器可以被直接添加到 Appender 实例上。通过将一个或者多个过滤器添加到 appender 上，你可以通过任意标准来过滤日志事件。例如，日志消息的内容，MDC 的内容，时间，或者日志事件的其它部分。 自定义过滤器创建一个自己的过滤器非常的简单。只需要继承 Filter 并且实现 decide() 方法就可以了。 自定一个过滤器，把日志内容包含“different”的不打印 /** * @author blog.unclezs.com * @date 2020/12/3 1:05 上午 */ public class CustomRegularFilter extends Filter&lt;ILoggingEvent&gt; &#123; @Override public FilterReply decide(ILoggingEvent event) &#123; return event.getMessage().contains(&quot;different&quot;)?FilterReply.DENY:FilterReply.ACCEPT; &#125; &#125; /** * @author blog.unclezs.com * @since 2020/12/04 17:26 */ public class FilterSample &#123; public static void main(String[] args) &#123; LoggerHelper.reconfigure(&quot;logback-filter.xml&quot;); Logger logger = LoggerFactory.getLogger(FilterSample.class); logger.info(&quot;different log&quot;); logger.info(&quot;same log&quot;); &#125; &#125; &lt;configuration debug=&quot;false&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;filter class=&quot;com.unclezs.samples.log.slf4j.logback.filter.CustomRegularFilter&quot;/&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;true&lt;/outputPatternAsHeader&gt; &lt;/encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; LevelFilterLevelFilter 基于级别来过滤日志事件。如果事件的级别与配置的级别相等，过滤器会根据配置的 onMatch 与 onMismatch 属性，接受或者拒绝事件。如下是一个简单的示例： &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; ThresholdFilterThresholdFilter 基于给定的临界值来过滤事件。如果事件的级别等于或高于给定的临界值，当调用 decide() 时，ThresholdFilter 将会返回 NEUTRAL。但是事件的级别低于临界值将会被拒绝。下面是一个简单的例子： &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; EvaluatorFilterEvaluatorFilter 是一个通用的过滤器，它封装了一个 EventEvaluator。顾名思义，EventEvaluator 根据给定的标准来评估给定的事件是否符合标准。在 match 和 mismatch 的情况下，EvaluatorFilter 将会返回 onMatch 或 onMismatch 指定的值。 注意 EventEvaluator 是一个抽象类。你可以通过继承 EventEvaluator 来实现自己事件评估逻辑。 GEventEvaluator是EventEvaluator一个实现类，通过Groogy脚本判断是否需要过滤。 JaninoEventEvaluatorlogback-classic 附带的另外一个 EventEvaluator 的具体实现名为 JaninoEventEvaluator，它接受任意返回布尔值的 Java 代码块作为评判标准。我们把这种 Java 布尔表达式称为 “评估表达式”。评估表达式在事件过滤中可以更加的灵活。JaninoEventEvaluator 需要 Janino 类库。请参见相关章节进行设置。跟 JaninoEventEvaluator 相比，GEventEvaluator 使用 Groovy 语言，使用起来非常方便。但是 JaninoEventEvaluator 将使用运行更快的等效表达式。 评估表达式在解析配置文件期间被动态编译。作为用户，不需要考虑实际的情况。但是，你需要确保你的 Java 表达式是有效的，保证它的评估结果为 true 或 false。 评估表达式对当前日志事件进行评估。logback-classic 自动导出日志事件的各种字段作为变量，为了可以从评估表达式访问。这些导出的变量是大小写敏感的，如下表所示： 名字 类型 描述 event LoggingEvent 日志请求的原始日志事件。下面所有的变量都来自这个日志事件。例如，event.getMessage() 返回的字符串跟下面的 message 变量返回的字符串一样。 message String 日志请求的原始信息。例如，对于 logger I，当你写的是 I.info(“Hello {}“, name); 时，name 的值被指定为 “Alice”，消息就为 “Hello {}“。 formattedMessage String 日志请求中格式化后的消息。例如，对于 logger I，当你写的是 I.info(“Hello {}“, name); 时，name 的值被指定为 “Alice”，格式化后的消息就为 “Hello Alice”。 logger String logger 的名字 loggerContext LoggerContextVO 日志事件属于 logger 上下文中哪个受限的视图 (值对象) level int 事件级别对应的 int 值。用来创建包含级别的表达式。默认值是 DEBUG，INFO，WARN 以及 ERROR 也是有效的。所以 level &gt; INFO 是有效的表达式。 timeStamp long 日志事件创建的时间 marker Marker 与日志请求相关的 Marker 对象。注意，marker 可能会为 null，因此你需要对这种情况进行检查，进而避免 NullPointerException。 mdc Map 创建日志事件时包含的所有的 MDC 值的一个映射。可以通过 mdc.get(“myKey”) 来获取 MDC 中对应的值。在 0.9.30 版本的 logback-classic，mdc 变量永远不会为 null。java.util.Map 类型是非参数化的，因为 Janino 不支持泛型。因此，mdc.get() 返回值的类型是 Object 而不是 String。但是可以将返回值强制转换为 String。例如， ((String) mdc.get(“k”)).contains(“val”)。 throwable java.lang.Throwable 如果日志事件没有相关的异常，那么变量 “throwable” 的值为 null。”throwable” 不可以被序列化。所以在远程服务器上，这个值永远为 null。想要使用与位置无关的表达式，可以使用下面的 throwableProxy。 throwableProxy IThrowableProxy 日志事件的异常代理。如果日志事件没有相关的异常，那么 throwableProxy 的值为 null。与 “throwable” 相反，即使在远程服务器上序列化之后，日志事件相关的异常也不会为 null。 &lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.core.filter.EvaluatorFilter&quot;&gt; &lt;evaluator&gt; &lt;!-- defaults to type ch.qos.logback.classic.boolex.JaninoEventEvaluator --&gt; &lt;expression&gt;return message.contains(&quot;billing&quot;);&lt;/expression&gt; &lt;/evaluator&gt; &lt;OnMismatch&gt;NEUTRAL&lt;/OnMismatch&gt; &lt;OnMatch&gt;DENY&lt;/OnMatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt; %-4relative [%thread] %-5level %logger - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 上面的配置将 EvaluatorFilter 添加到 ConsoleAppender。一个类型为 JaninoEventEvaluator 的 evaluator 之后被注入到 EvaluatorFilter 中。&lt;evaluator 在缺少 class 属性的情况下，Joran 会指定 evaluator 的默认类型为 JaninoEventEvaluator。这是少数几个需要 Joran 默认指定类型的组件。 expression 元素对应刚才讨论过的评估表达式。表达式 return message.contains(“billing”); 返回一个布尔值。message 变量会被 JaninoEventEvaluator 自动导出。 甚至可以是更复杂的表达式 &lt;evaluator&gt; &lt;expression&gt; if(logger.startsWith(&quot;org.apache.http&quot;)) return true; if(mdc == null || mdc.get(&quot;entity&quot;) == null) return false; String payee = (String) mdc.get(&quot;entity&quot;); if(logger.equals(&quot;org.apache.http.wire&quot;) &amp;amp;&amp;amp; payee.contains(&quot;someSpecialValue&quot;) &amp;amp;&amp;amp; !message.contains(&quot;someSecret&quot;)) &#123; return true; &#125; return false; &lt;/expression&gt; &lt;/evaluator&gt; Matchers虽然可以通过调用 String 类的 matches() 方法来进行模式匹配，但是每次调用 filter 都需要耗费时间重新编译一个新的 Pattern 对象。为了消除这种影响，你可以预先定义一个或者多个 Matcher 对象。一旦定义了一个 matcher，就可以在评估表达式中重复使用了。 &lt;configuration debug=&quot;true&quot;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;filter class=&quot;ch.qos.logback.core.filter.EvaluatorFilter&quot;&gt; &lt;evaluator&gt; &lt;matcher&gt; &lt;Name&gt;odd&lt;/Name&gt; &lt;!-- filter out odd numbered statements --&gt; &lt;regex&gt;statement [13579]&lt;/regex&gt; &lt;/matcher&gt; &lt;expression&gt;odd.matches(formattedMessage)&lt;/expression&gt; &lt;/evaluator&gt; &lt;OnMismatch&gt;NEUTRAL&lt;/OnMismatch&gt; &lt;OnMatch&gt;DENY&lt;/OnMatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; TurboFiltersTurboFilter 对象都继承 TurboFilter 抽象类。对于 regular 过滤器，它们使用三元逻辑来返回对日志事件的评估。 总之，它们跟之前提到的过滤工作原理差不多。主要的不同点在于 Filter 与 TurboFilter 对象。 TurboFilter 对象被绑定刚在 logger 上下文中。因此，在使用给定的 appender 以及每次发出的日志请求都会调用 TurboFilter 对象。因此，turbo 过滤器可以为日志事件提供高性能的过滤，即使是在事件被创建之前。 实现自己的 TurboFilter想要创建自己的 TurboFilter 组件，只需要继承 TurboFilter 这个抽象类就可以了。跟之前的一样，想要实现定制的过滤器对象，开发自定义的 TurboFilter，只需要实现 decide() 方法就可以了。下一个例子，我们会创建一个稍微复杂一点的过滤器： /** * @author blog.unclezs.com * @date 2020/12/4 10:32 下午 */ public class CustomTurboFilter extends TurboFilter &#123; @Override public FilterReply decide(Marker marker, Logger logger, Level level, String format, Object[] params, Throwable t) &#123; if (t == null) &#123; return FilterReply.DENY; &#125; return FilterReply.ACCEPT; &#125; &#125; &lt;configuration debug=&quot;false&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;turboFilter class=&quot;com.unclezs.samples.log.slf4j.logback.filter.CustomTurboFilter&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;filter class=&quot;com.unclezs.samples.log.slf4j.logback.filter.CustomRegularFilter&quot;/&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;true&lt;/outputPatternAsHeader&gt; &lt;/encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 其他loback-classic 附带了几个 TurboFilter 类可以开箱即用。MDCFilter 用来检查给定的值在 MDC 中是否存在。DynamicThresholdFilter 根据 MDC key/level 相关的阀值来进行过滤。MarkerFilter 用来检查日志请求中指定的 marker 是否存在。 DuplicateMessageFilter MarkerFilter MDCFilter DynamicThresholdFilter","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback中的Layouts","slug":"Java/日志框架/9.logback中的Layouts","date":"2020-12-04T03:28:28.000Z","updated":"2020-12-04T03:28:28.000Z","comments":true,"path":"Java/日志框架/9.logback中的Layouts.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/9.logback%E4%B8%AD%E7%9A%84Layouts.html","excerpt":"简介Layout就是负责将事件对象转换为String对象的，而且支持自定义，你可以把日志转换为其他格式html，json等等。 public interface Layout&lt;E&gt; extends ContextAware, LifeCycle &#123; String doLayout(E event); String getFileHeader(); String getPresentationHeader(); String getFileFooter(); String getPresentationFooter(); String getContentType(); &#125; 自定义Layoutpublic class MyLayout extends LayoutBase&lt;ILoggingEvent&gt; &#123; @Override public String doLayout(ILoggingEvent event) &#123; return &quot;自定义布局器：&quot;+ (event.getTimeStamp() - event.getLoggerContextVO().getBirthTime()) + &quot; &quot; + event.getLevel() + &quot; [&quot; + event.getThreadName() + &quot;] &quot; + event.getLoggerName() + &quot; - &quot; + event.getFormattedMessage() + CoreConstants.LINE_SEPARATOR; &#125; &#125; &lt;configuration debug=&quot;false&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.core.encoder.LayoutWrappingEncoder&quot;&gt; &lt;layout class=&quot;com.unclezs.samples.log.slf4j.logback.layouts.MyLayout&quot;/&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 本文代码log-slf4j-logback PatternLayoutlogback 配备了一个更加灵活的 layout 叫做 PatternLayout。跟所有的 layout 一样，PatternLayout 接收一个日志事件并返回一个字符串。但是，可以通过调整 PatternLayout 的转换模式来进行定制。","text":"简介Layout就是负责将事件对象转换为String对象的，而且支持自定义，你可以把日志转换为其他格式html，json等等。 public interface Layout&lt;E&gt; extends ContextAware, LifeCycle &#123; String doLayout(E event); String getFileHeader(); String getPresentationHeader(); String getFileFooter(); String getPresentationFooter(); String getContentType(); &#125; 自定义Layoutpublic class MyLayout extends LayoutBase&lt;ILoggingEvent&gt; &#123; @Override public String doLayout(ILoggingEvent event) &#123; return &quot;自定义布局器：&quot;+ (event.getTimeStamp() - event.getLoggerContextVO().getBirthTime()) + &quot; &quot; + event.getLevel() + &quot; [&quot; + event.getThreadName() + &quot;] &quot; + event.getLoggerName() + &quot; - &quot; + event.getFormattedMessage() + CoreConstants.LINE_SEPARATOR; &#125; &#125; &lt;configuration debug=&quot;false&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;property name=&quot;pattern&quot; value=&quot;%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.core.encoder.LayoutWrappingEncoder&quot;&gt; &lt;layout class=&quot;com.unclezs.samples.log.slf4j.logback.layouts.MyLayout&quot;/&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 本文代码log-slf4j-logback PatternLayoutlogback 配备了一个更加灵活的 layout 叫做 PatternLayout。跟所有的 layout 一样，PatternLayout 接收一个日志事件并返回一个字符串。但是，可以通过调整 PatternLayout 的转换模式来进行定制。 PatternLayout 中的转换模式与 C 语言中 printf() 方法中的转换模式密切相关。转换模式由字面量与格式控制表达式也叫转换说明符组成。你可以在转换模式中自由的插入字面量。每一个转换说明符由一个百分号开始 ‘%’，后面跟随可选的格式修改器，以及用综括号括起来的转换字符与可选的参数。转换字符需要转换的字段。如：logger 的名字，日志级别，日期以及线程名。格式修改器控制字段的宽度，间距以及左右对齐。 正如我们已经在其它地方提到过的，FileAppender 及其子类需要一个 encoder。因为，当将 FileAppender 及其子类与 PatternLayout 结合使用时，PatternLayout 必须用 encoder 包裹起来。鉴于 FileAppender/PatternLayout 结合使用很常见，因此 logback 单独设计了一个名叫 PatternLayoutEncoder 的 encoder，包裹了一个 PatternLayout，因此它可以被当作一个 encoder。下面是通过代码配置 ConsoleAppender 与 PatternLayoutEncoder 使用的例子： public class PatternSample &#123; static public void main(String[] args) throws Exception &#123; Logger rootLogger = (Logger)LoggerFactory.getLogger(Logger.ROOT_LOGGER_NAME); LoggerContext loggerContext = rootLogger.getLoggerContext(); loggerContext.reset(); PatternLayoutEncoder encoder = new PatternLayoutEncoder(); encoder.setContext(loggerContext); encoder.setPattern(&quot;%-5level [%thread]: %message%n&quot;); encoder.start(); ConsoleAppender&lt;ILoggingEvent&gt; appender = new ConsoleAppender&lt;ILoggingEvent&gt;(); appender.setContext(loggerContext); appender.setEncoder(encoder); appender.start(); rootLogger.addAppender(appender); rootLogger.debug(&quot;Message 1&quot;); rootLogger.warn(&quot;Message 2&quot;); &#125; &#125; 转化后输出： DEBUG [main]: Message 1 WARN [main]: Message 2 格式化日志的写法 格式化字符 含义 %logger{length} logger的名字，长度是最大长度，如果全限定类名超过长度了就进行简写，但是类名不会被简写 eg: %logger{3}: com.unclezs.Test=&gt;c.u.Test %class{length} 调用者的全限定类名，通过计算的，比价慢，一般不用 %contextName 输出日志事件附加到的 logger 上下文的名字 %date{pattern,[timezone]} 时区可选，显示当前时间 caller{depth}、caller{depthStart..depthEnd}、caller{depth, evaluator-1, ... evaluator-n}、caller{depthStart..depthEnd, evaluator-1, ... evaluator-n} %caller{2} 显示2层调用栈 %line 行号，效率低，不建议使用 %n 换行 %level 日志级别 %relative 打日志消耗时间毫秒数 %thread 输出生成日志事件的线程名。 m / msg / message 日志信息 method 调用打印日志的所在方法名字，比较慢，不建议用 X/mdc 如果 MDC 转换字符后面跟着用花括号括起来的 ，例 %mdc{userid}，那么 ‘userid’ 所对应 MDC 的值将会输出。如果该值为 null，那么通过 :- 指定的默认值 将会输出。如果没有指定默认值，那么将会输出空字符串。 如果没有指定的 key，那么 MDC 的整个内容将会以 “key1=val1, key2=val2” 的格式输出。 exception{depth}/throwable{depth} depth: short第一行、full全部、数字指定几行。 %xException /xE/xThrowbale 和exception一样，不过会在每行后面显示jar包名字和版本号 %rootException 和xeception一样，反向输出 marker 输出相关的标签 property{key} 输出属性值 replace(p){r, t} 在子模式 ‘p’ 产生的字符中，将所有出现正则表达式 ‘r’ 的地方替换为 ‘t’。例如，”%replace(%msg){‘\\s’, ‘’}“ 将会移除事件消息中所有空格。 对齐方式默认情况下，相关信息按照原样输出。但是，在格式修改器的帮助下，可以对每个数据字段进行对齐，以及更改最大最小宽度。 可选的格式修改器放在百分号跟转换字符之间。 第一个可选的格式修改器是左对齐标志，也就是减号 (-) 字符。接下来的是最小字段宽度修改器，它是一个十进制常量，表示输出至少多少个字符。如果字段包含很少的数据，它会选择填充左边或者右边，直到满足最小宽度。默认是填充左边 (右对齐)，但是你可以通过左对齐标志来对右边进行填充。填充字符为空格。如果字段的数据大于最小字段的宽度，会自动扩容去容纳所有的数据。字段的数据永远不会被截断。 这个行为可以通过使用最大字段宽度修改器来改变，它通过一个点后面跟着一个十进制常量来指定。如果字段的数据长度大于最大字段的宽度，那么会从数据字段的开头移除多余的字符。举个🌰，如果最大字段的宽度是 8，数据长度是十个字符的长度，那么开头的两个字符将会被丢弃。这个行为跟 C 语言中 printf 函数从后面开始截断的行为相违背。 如果想从后面开始截断，可以在点后面增加一个减号。如果是这样的话，最大字段宽度是 8，数据长度是十个字符的长度，那么最后两个字符将会被丢弃。 下面是各种格式修改器的例子： 格式修改器 左对齐 最小宽度 最大宽度 备注 %20logger false 20 none 如果 logger 的名字小于 20 个字符的长度，那么会在左边填充空格 %-20logger true 20 none 如果 logger 的名字小于 20 个字符的长度，那么会在右边填充空格 %.30logger NA none 30 如果 logger 的名字大于 30 个字符的长度，那么从前面开始截断 %20.30logger false 20 30 如果 logger 的名字大于 20 个字符的长度，那么会从左边填充空格。但是如果 logger 的名字大于 30 字符，将会从前面开始截断 %-20.30logger true 20 30 如果 logger 的名字小于 20 个字符的长度，那么从右边开始填充空格。但是如果 logger 的名字大于 30 个字符，将会从前面开始截断 %.-30logger NA none 30 如果 logger 的名字大于 30 个字符的长度，那么从后面开始截断 下面的表格列出了格式修改器截断的例子。但是请注意综括号 “[]” 不是输出结果的一部分，它只是用来区分输出的长度： 格式修改器 logger 的名字 结果 [%20.20logger] main.Name [ main.Name] [%-20.20logger] main.Name [main.Name ] [%10.10logger] main.foo.foo.bar.Name [o.bar.Name] [%10.-10logger] main.foo.foo.bar.Name [main.foo.f] 转义字符的选项&lt;pattern&gt;%-5level - %replace(%msg)&#123;&#39;\\d&#123;14,16&#125;&#39;, &#39;XXXX&#39;&#125;%n&lt;&#x2F;pattern&gt; 我们传递 \\d{16} 与 XXXX 给 replace 转换字符。它将消息中 14，15 或者 16 位的数字替换为 XXXX，用来混淆信用卡号码。在正则表达式中，”\\d” 表示一个数字的简写。”{14,16}” 会被解析成 “{14,16}”，也就是说前一个项将会被重复至少 14 次，至多 16 次。 特殊的圆括号在 logback 里，模式字符串中的圆括号被看作为分组标记。因此，它能够对子模式进行分组，并且直接对子模式进行格式化。在 0.9.27 版本，logback 开始支持综合转换字符，例如 %replace 可以对子模式进行转换。 例如一下模式： %-30(%d&#123;HH:mm:ss.SSS&#125; [%thread]) %-5level %logger&#123;32&#125; - %msg%n 将会对子模式 “%d{HH:mm:ss.SSS} [%thread]” 进行分组输出，为了在少于 30 个字符时进行右填充。 13:09:30 [main] DEBUG c.q.logback.demo.ContextListener - Classload hashcode is 13995234 13:09:30 [main] DEBUG c.q.logback.demo.ContextListener - Initializing for ServletContext 13:09:30 [main] DEBUG c.q.logback.demo.ContextListener - Trying platform Mbean server 13:09:30 [pool-1-thread-1] INFO ch.qos.logback.demo.LoggingTask - Howdydy-diddly-ho - 0 13:09:38 [btpool0-7] INFO c.q.l.demo.lottery.LotteryAction - Number: 50 was tried. 13:09:40 [btpool0-7] INFO c.q.l.d.prime.NumberCruncherImpl - Beginning to factor. 13:09:40 [btpool0-7] DEBUG c.q.l.d.prime.NumberCruncherImpl - Trying 2 as a factor. 13:09:40 [btpool0-7] INFO c.q.l.d.prime.NumberCruncherImpl - Found factor 2 高亮彩色日志如上所述的圆括号分组，允许对子模式进行着色。在 1.0.5 版本，PatternLayout 可以识别 “%black”，”%red”，”%green”，”%yellow”，”%blue”，”%magenta”,”%cyan”, “%white”, “%gray”, “%boldRed”,”%boldGreen”, “%boldYellow”, “%boldBlue”, “%boldMagenta””%boldCyan”, “%boldWhite” 以及 “%highlight” 作为转换字符。这些转换字符都还可以包含一个子模式。任何被颜色转换字符包裹的子模式都会通过指定的颜色输出。 然后在pattern中使用即可。 Evaluators可以用来动态判断是否需要显示某些信息，比如异常信息,调用信息。 由于 XML 的编码规则，&amp; 符号需要被转义为 &amp; 判断打印的消息中是否包含different字符串： &lt;configuration debug&#x3D;&quot;false&quot; scan&#x3D;&quot;false&quot; scanPeriod&#x3D;&quot;1 second&quot; packagingData&#x3D;&quot;false&quot;&gt; &lt;evaluator name&#x3D;&quot;isError&quot;&gt; &lt;expression&gt;message.contains(&quot;different&quot;)&lt;&#x2F;expression&gt; &lt;&#x2F;evaluator&gt; &lt;property name&#x3D;&quot;pattern&quot; value&#x3D;&quot; %-4relative [%thread] %-5level - %msg%n%caller&#123;2, isError&#125;&quot;&#x2F;&gt; &lt;appender name&#x3D;&quot;console&quot; class&#x3D;&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class&#x3D;&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;&#x2F;pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;true&lt;&#x2F;outputPatternAsHeader&gt; &lt;&#x2F;encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;&#x2F;immediateFlush&gt; &lt;&#x2F;appender&gt; &lt;logger name&#x3D;&quot;com.unclezs.samples.log.slf4j.logback&quot; level&#x3D;&quot;info&quot; additivity&#x3D;&quot;false&quot;&gt; &lt;appender-ref ref&#x3D;&quot;console&quot;&#x2F;&gt; &lt;&#x2F;logger&gt; &lt;root level&#x3D;&quot;off&quot;&gt; &lt;&#x2F;root&gt; &lt;&#x2F;configuration&gt; 741 [main] INFO - test message by different level Caller+0 at com.unclezs.samples.log.slf4j.logback.utils.LoggerHelper.logMsg(LoggerHelper.java:46) Caller+1 at com.unclezs.samples.log.slf4j.logback.utils.LoggerHelper.logMsg(LoggerHelper.java:57) 自定义转换说明符我们可以在 PatternLayout 中使用内置的转换字符。我们也可以使用自己新建的转换字符。 新建一个自定义的转换字符需要两步。 1. 自定义 首先，你必须继承 ClassicConverter 类。ClassicConverter 对象负责从 ILoggingEvent 实例中抽取信息并输出字符串。例如，%logger 对应的转换器 LoggerConverter，可以从 ILoggingEvent 从抽取 logger 的名字，返回一个字符串。它可以缩写 logger 的名字。 下面是一个自定义的转换器，获取当前时间戳。 /** * @author blog.unclezs.com * @since 2020/12/04 17:03 */ public class CustomNowTimeConverter extends ClassicConverter &#123; @Override public String convert(ILoggingEvent event) &#123; return String.valueOf(System.currentTimeMillis()); &#125; &#125; 2. 配置 &lt;configuration debug=&quot;false&quot; scan=&quot;false&quot; scanPeriod=&quot;1 second&quot; packagingData=&quot;false&quot;&gt; &lt;conversionRule conversionWord=&quot;nowTime&quot; converterClass=&quot;com.unclezs.samples.log.slf4j.logback.converter.CustomNowTimeConverter&quot; /&gt; &lt;property name=&quot;pattern&quot; value=&quot;%nowTime - %cyan(%msg%n)&quot;/&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;!--在头部打印出pattern--&gt; &lt;outputPatternAsHeader&gt;false&lt;/outputPatternAsHeader&gt; &lt;/encoder&gt; &lt;!--立即刷新到流--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/appender&gt; &lt;logger name=&quot;com.unclezs.samples.log.slf4j.logback&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;off&quot;&gt; &lt;/root&gt; &lt;/configuration&gt; 3. 输出 1607072991810 - test message by different level 1607072991810 - test message by different level 1607072991810 - test message by different level 其他 HTMLLayout XMLLayout 还有Logback Access包中也有提供 了解更多Chapter 6: Layouts示例代码","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback配置中的Encoder","slug":"Java/日志框架/8.logback配置中的Encoder","date":"2020-12-03T14:48:15.000Z","updated":"2020-12-03T14:48:15.000Z","comments":true,"path":"Java/日志框架/8.logback配置中的Encoder.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/8.logback%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%9A%84Encoder.html","excerpt":"介绍Ecoder负责将事件转换为字节数组，并将该字节数组写出到OutputStream中 Encoder接口public interface Encoder&lt;E&gt; extends ContextAware, LifeCycle &#123; //日志打印时头部显示内容 byte[] headerBytes(); //日志转码 byte[] encode(E event); //尾部内容，通常是结束之后调用 byte[] footerBytes(); &#125; LayoutWrappingEncoder在0.9.19版本的Logback之前，许多Appender都依赖Layout实例来控制日志输出的格式。由于存在大量基于布局接口的代码，因此我们需要一种encoder与layout进行互操作的方法。 LayoutWrappingEncoder弥合了encoder和layout之间的差距。它实现了编码器接口，并包装了一个布局，该布局委派了将事件转换为字符串的工作。 public class LayoutWrappingEncoder&lt;E&gt; extends EncoderBase&lt;E&gt; &#123; protected Layout&lt;E&gt; layout; private Charset charset; Appender&lt;?&gt; parent; Boolean immediateFlush = null; @Override public byte[] headerBytes() &#123; if (layout == null) return null; StringBuilder sb = new StringBuilder(); appendIfNotNull(sb, layout.getFileHeader()); appendIfNotNull(sb, layout.getPresentationHeader()); if (sb.length() &gt; 0) &#123; sb.append(CoreConstants.LINE_SEPARATOR); &#125; return convertToBytes(sb.toString()); &#125; @Override public byte[] footerBytes() &#123; if (layout == null) return null; StringBuilder sb = new StringBuilder(); appendIfNotNull(sb, layout.getPresentationFooter()); appendIfNotNull(sb, layout.getFileFooter()); return convertToBytes(sb.toString()); &#125; private byte[] convertToBytes(String s) &#123; if (charset == null) &#123; return s.getBytes(); &#125; else &#123; return s.getBytes(charset); &#125; &#125; public byte[] encode(E event) &#123; String txt = layout.doLayout(event); return convertToBytes(txt); &#125; public void start() &#123; if (immediateFlush != null) &#123; if (parent instanceof OutputStreamAppender) &#123; addWarn(&quot;Setting the \\&quot;immediateFlush\\&quot; property of the enclosing appender to &quot; + immediateFlush); @SuppressWarnings(&quot;unchecked&quot;) OutputStreamAppender&lt;E&gt; parentOutputStreamAppender = (OutputStreamAppender&lt;E&gt;) parent; parentOutputStreamAppender.setImmediateFlush(immediateFlush); &#125; else &#123; addError(&quot;Could not set the \\&quot;immediateFlush\\&quot; property of the enclosing appender.&quot;); &#125; &#125; started = true; &#125; &#125; PatternLayoutEncoder鉴于PatternLayout是最常用的布局，因此Logback通过PatternLayoutEncoder迎合了这种常见用例，PatternLayoutEncoder是LayoutWrappingEncoder的扩展，仅限于包装PatternLayout实例。 从0.9.19版开始，每当FileAppender或其子类之一配置有PatternLayout时，都必须改用PatternLayoutEncoder。","text":"介绍Ecoder负责将事件转换为字节数组，并将该字节数组写出到OutputStream中 Encoder接口public interface Encoder&lt;E&gt; extends ContextAware, LifeCycle &#123; //日志打印时头部显示内容 byte[] headerBytes(); //日志转码 byte[] encode(E event); //尾部内容，通常是结束之后调用 byte[] footerBytes(); &#125; LayoutWrappingEncoder在0.9.19版本的Logback之前，许多Appender都依赖Layout实例来控制日志输出的格式。由于存在大量基于布局接口的代码，因此我们需要一种encoder与layout进行互操作的方法。 LayoutWrappingEncoder弥合了encoder和layout之间的差距。它实现了编码器接口，并包装了一个布局，该布局委派了将事件转换为字符串的工作。 public class LayoutWrappingEncoder&lt;E&gt; extends EncoderBase&lt;E&gt; &#123; protected Layout&lt;E&gt; layout; private Charset charset; Appender&lt;?&gt; parent; Boolean immediateFlush = null; @Override public byte[] headerBytes() &#123; if (layout == null) return null; StringBuilder sb = new StringBuilder(); appendIfNotNull(sb, layout.getFileHeader()); appendIfNotNull(sb, layout.getPresentationHeader()); if (sb.length() &gt; 0) &#123; sb.append(CoreConstants.LINE_SEPARATOR); &#125; return convertToBytes(sb.toString()); &#125; @Override public byte[] footerBytes() &#123; if (layout == null) return null; StringBuilder sb = new StringBuilder(); appendIfNotNull(sb, layout.getPresentationFooter()); appendIfNotNull(sb, layout.getFileFooter()); return convertToBytes(sb.toString()); &#125; private byte[] convertToBytes(String s) &#123; if (charset == null) &#123; return s.getBytes(); &#125; else &#123; return s.getBytes(charset); &#125; &#125; public byte[] encode(E event) &#123; String txt = layout.doLayout(event); return convertToBytes(txt); &#125; public void start() &#123; if (immediateFlush != null) &#123; if (parent instanceof OutputStreamAppender) &#123; addWarn(&quot;Setting the \\&quot;immediateFlush\\&quot; property of the enclosing appender to &quot; + immediateFlush); @SuppressWarnings(&quot;unchecked&quot;) OutputStreamAppender&lt;E&gt; parentOutputStreamAppender = (OutputStreamAppender&lt;E&gt;) parent; parentOutputStreamAppender.setImmediateFlush(immediateFlush); &#125; else &#123; addError(&quot;Could not set the \\&quot;immediateFlush\\&quot; property of the enclosing appender.&quot;); &#125; &#125; started = true; &#125; &#125; PatternLayoutEncoder鉴于PatternLayout是最常用的布局，因此Logback通过PatternLayoutEncoder迎合了这种常见用例，PatternLayoutEncoder是LayoutWrappingEncoder的扩展，仅限于包装PatternLayout实例。 从0.9.19版开始，每当FileAppender或其子类之一配置有PatternLayout时，都必须改用PatternLayoutEncoder。 public class PatternLayoutEncoder extends PatternLayoutEncoderBase&lt;ILoggingEvent&gt; &#123; @Override public void start() &#123; PatternLayout patternLayout = new PatternLayout(); patternLayout.setContext(context); patternLayout.setPattern(getPattern()); patternLayout.setOutputPatternAsHeader(outputPatternAsHeader); patternLayout.start(); this.layout = patternLayout; super.start(); &#125; &#125; encoder的默认class为PatternLayoutEncoder,可以省略 &lt;appender name=&quot;STDOUT_HIGHLIGHT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;$&#123;highlightPattern&#125;&lt;/pattern&gt; &lt;outputPatternAsHeader&gt;true&lt;/outputPatternAsHeader&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;/encoder&gt; &lt;/appender&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"Jmeter进行并发测试之快速开始","slug":"性能调优/Jmeter进行并发测试之快速开始","date":"2020-12-03T11:22:54.000Z","updated":"2020-12-03T11:22:54.000Z","comments":true,"path":"性能调优/Jmeter进行并发测试之快速开始.html","link":"","permalink":"https://blog.unclezs.com/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/Jmeter%E8%BF%9B%E8%A1%8C%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95%E4%B9%8B%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.html","excerpt":"下载安装到http://jmeter.apache.org/download_jmeter.cgi去下载。 安装解压即安装，只需要配置Java环境即可。 点击启动即可 创建线程组配置10个并发，请求一次 测试接口","text":"下载安装到http://jmeter.apache.org/download_jmeter.cgi去下载。 安装解压即安装，只需要配置Java环境即可。 点击启动即可 创建线程组配置10个并发，请求一次 测试接口 创建Http请求 创建查看结果树监听器 运行测试 监听器可以创建多个。自己慢慢试试可以。 更加详细的文档《jmeter：菜鸟入门到进阶》系列","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"name":"其他","slug":"性能调优/其他","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Jmeter","slug":"Jmeter","permalink":"https://blog.unclezs.com/tags/Jmeter/"}],"author":"Unclezs"},{"title":"logback中的Appender","slug":"Java/日志框架/7.logback中的Appender","date":"2020-12-03T02:52:59.000Z","updated":"2020-12-03T02:52:59.000Z","comments":true,"path":"Java/日志框架/7.logback中的Appender.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/7.logback%E4%B8%AD%E7%9A%84Appender.html","excerpt":"介绍Appender最终负责输出日志记录事件。但是，他们可以将事件的实际格式委托给Layout或Encoder对象。每个布局/编码器都与一个且只有一个appender相关联。一些appender具有内置或固定的事件格式。因此，它们不需要布局/编码器。例如，SocketAppender可以简单地序列化日志记录事件，然后再通过网络传输它们 AppenderBasech.qos.logback.core.AppenderBase类是实现Appender接口的抽象类。它提供了所有Appender共享的基本功能，例如获取或设置其名称的方法，其激活状态，其布局和其过滤器。它是Logback附带的所有附加程序的超类。尽管是抽象类，但AppenderBase实际上在Append接口中实现了doAppend（）方法。 可以看到这是一个同步方法，最终还是调用了实现类来进行append. public synchronized void doAppend(E eventObject) &#123; // prevent re-entry. if (guard) &#123; return; &#125; try &#123; guard = true; if (!this.started) &#123; if (statusRepeatCount++ &lt; ALLOWED_REPEATS) &#123; addStatus(new WarnStatus( &quot;Attempted to append to non started appender [&quot; + name + &quot;].&quot;,this)); &#125; return; &#125; if (getFilterChainDecision(eventObject) == FilterReply.DENY) &#123; return; &#125; // ok, we now invoke the derived class&#x27;s implementation of append this.append(eventObject); &#125; finally &#123; guard = false; &#125; &#125; OutputStreamAppender负责基于Java中java.io.OutputStream实现的一个Appender，可以结合类图了解一下 参数： encoder(Encoder)：编码器 immediateFlush(boolean)：是否立即刷新流，默认true","text":"介绍Appender最终负责输出日志记录事件。但是，他们可以将事件的实际格式委托给Layout或Encoder对象。每个布局/编码器都与一个且只有一个appender相关联。一些appender具有内置或固定的事件格式。因此，它们不需要布局/编码器。例如，SocketAppender可以简单地序列化日志记录事件，然后再通过网络传输它们 AppenderBasech.qos.logback.core.AppenderBase类是实现Appender接口的抽象类。它提供了所有Appender共享的基本功能，例如获取或设置其名称的方法，其激活状态，其布局和其过滤器。它是Logback附带的所有附加程序的超类。尽管是抽象类，但AppenderBase实际上在Append接口中实现了doAppend（）方法。 可以看到这是一个同步方法，最终还是调用了实现类来进行append. public synchronized void doAppend(E eventObject) &#123; // prevent re-entry. if (guard) &#123; return; &#125; try &#123; guard = true; if (!this.started) &#123; if (statusRepeatCount++ &lt; ALLOWED_REPEATS) &#123; addStatus(new WarnStatus( &quot;Attempted to append to non started appender [&quot; + name + &quot;].&quot;,this)); &#125; return; &#125; if (getFilterChainDecision(eventObject) == FilterReply.DENY) &#123; return; &#125; // ok, we now invoke the derived class&#x27;s implementation of append this.append(eventObject); &#125; finally &#123; guard = false; &#125; &#125; OutputStreamAppender负责基于Java中java.io.OutputStream实现的一个Appender，可以结合类图了解一下 参数： encoder(Encoder)：编码器 immediateFlush(boolean)：是否立即刷新流，默认true ConsoleAppender参数： encoder(Encoder)：编码器 target(String)：System.out 或者 System.err，默认前者。 withJansi(boolean)：是否启用Jansi，这个会开启ANSI的颜色支持。windows需要下依赖org.fusesource.jansi:jansi:1.17 ，默认false。 FileAppender append(boolean)：追加模式，文件内容追加/覆盖，默认为true encoder(Encoder)：编码器 file(String)：文件全路径 prudent(boolean): 谨慎模式，开启后保证文件安全被写入，默认false 例子： &lt;configuration&gt; &lt;timestamp key=&quot;bySecond&quot; datePattern=&quot;yyyyMMdd&#x27;T&#x27;HHmmss&quot;/&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;testFile.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;!--设置为false，吞吐量更高--&gt; &lt;immediateFlush&gt;true&lt;/immediateFlush&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; RollingFileAppender这个是一个日志滚动记录器，也是是可以指定日志在什么情况下换一个日志文件进行存储，也是继承自FileAppnder. 参数： fileName(String) append(boolean) encoder rollingPolicy：在预警达到后做的操作 triggeringPolicy：控制在什么条件下出发 prudent: 谨慎模式，FixedWindowRollingPolicy不支持，TimeBasedRollingPolicy支持。 rollingPolicies TimeBasedRollingPolicy fileNamePattern(String)：文件名字的格式化，指定出发 maxHistory(int)，日志文件最多多少个 totalSizeCap(int)，所有日志文件可以用的最大空间，超过了会异步删除旧的，先判断maxHistory再判断totalSizeCap。 cleanHistoryOnStart(boolean)，启动的时候删除旧的文件 &lt;appender name=&quot;ROLLING_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;access-rolling-$&#123;today&#125;.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;%d&#123;yyyy-MM-dd,aux&#125;/%d&#123;yyyy-MM-dd_HH-mm&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt; &lt;cleanHistoryOnStart&gt;false&lt;/cleanHistoryOnStart&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; SizeAndTimeBasedRollingPolicy maxFileSize 单个文件的最大大小。 其他参数同TimeBasedRollingPolicy &lt;appender name=&quot;ROLLING_FILE_SIZE_TIME&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;access-rolling-$&#123;today&#125;.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;%d&#123;yyyy-MM-dd,aux&#125;/%d&#123;yyyy-MM-dd_HH-mm&#125;.log&lt;/fileNamePattern&gt; &lt;maxFileSize&gt;100M&lt;/maxFileSize&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt; &lt;cleanHistoryOnStart&gt;false&lt;/cleanHistoryOnStart&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; FixedWindowRollingPolicy minIndex：初始,触发一次就会+1 maxIndex：最大， fileNamePattern，文件名字，%i代表索引，%d代表时间 &lt;appender name=&quot;FILE_INDEX&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;test.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;tests.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;3&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;1MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; 第三个也看到了通过SizeBasedTriggeringPolicy达到了最大文件大小，触发索引的+1操作。到达最大值后进行归档。 SiftingAppender顾名思义，SiftingAppender可以根据给定的运行时属性来分离（或筛选）日志记录。例如，SiftingAppender可以根据用户会话将日志记录事件分开，以便将不同用户生成的日志放入不同的日志文件中，每个用户一个日志文件. 通过MDC传入userId logger.debug(&quot;Application started&quot;); MDC.put(&quot;userid&quot;, &quot;Alice&quot;); logger.debug(&quot;Alice says hello&quot;); &lt;configuration&gt; &lt;appender name=&quot;SIFT&quot; class=&quot;ch.qos.logback.classic.sift.SiftingAppender&quot;&gt; &lt;discriminator&gt; &lt;key&gt;userid&lt;/key&gt; &lt;defaultValue&gt;unknown&lt;/defaultValue&gt; &lt;/discriminator&gt; &lt;sift&gt; &lt;appender name=&quot;FILE-$&#123;userid&#125;&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;$&#123;userid&#125;.log&lt;/file&gt; &lt;append&gt;false&lt;/append&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt;%d [%thread] %level %mdc %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;/sift&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;SIFT&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 自定义Appender 编写Appender package com.unclezs.samples.log.slf4j.logback.appender; import ch.qos.logback.classic.encoder.PatternLayoutEncoder; import ch.qos.logback.classic.spi.ILoggingEvent; import ch.qos.logback.core.AppenderBase; public class MyAppender extends AppenderBase&lt;ILoggingEvent&gt; &#123; static int MAX_COUNT = 10; int counter = 0; int limit = MAX_COUNT; PatternLayoutEncoder encoder; @Override public void start() &#123; if (this.encoder == null) &#123; addError(&quot;No encoder set for the appender named [&quot; + name + &quot;].&quot;); return; &#125; super.start(); &#125; @Override public void append(ILoggingEvent event) &#123; if (counter &gt;= limit) &#123; return; &#125; //格式化 String bytes = this.encoder.getLayout().doLayout(event); System.out.print(bytes); counter++; &#125; /** * 通过getter setter设置 */ public PatternLayoutEncoder getEncoder() &#123; return encoder; &#125; public void setEncoder(PatternLayoutEncoder encoder) &#123; this.encoder = encoder; &#125; public void setLimit(int limit) &#123; this.limit = limit; &#125; public int getLimit() &#123; return limit; &#125; &#125; 配置 &lt;appender name=&quot;MY_APPENDER&quot; class=&quot;com.unclezs.samples.log.slf4j.logback.appender.MyAppender&quot;&gt; &lt;limit&gt;2&lt;/limit&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;highlightPattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; 测试 public class MyAppenderSample &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(MyAppenderSample.class); for (int i = 0; i &lt; 20; i++) &#123; logger.info(&quot;第&#123;&#125;次&quot;, i); &#125; &#125; &#125; 其他appender SMTP DB Syslog Socket 略，官网查看 Logback Appender","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback配置文件语法","slug":"Java/日志框架/6.logback配置文件语法","date":"2020-12-02T16:14:07.000Z","updated":"2020-12-02T16:14:07.000Z","comments":true,"path":"Java/日志框架/6.logback配置文件语法.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/6.logback%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%AD%E6%B3%95.html","excerpt":"配置文件的结构因为logback的配置十分灵活，所以无法通过一个DTD文件或者XML Schema来指定允许的语法。 标签名区分大小写对于特定的标签名字是大小写不敏感的，比如, 和 都是合法的配置，但是只能用关闭，不能是，但是针对驼峰规则是适用的，比如只能用关闭，不能是。驼峰规则可以参考维基百科camelCase convention configuration标签根标签，其中可以包含: Appender Logger Root property logger标签 name(string): 必填，logger的名称 additivity（boolean）：选填，是否最累加Appender（是否继承是用父logger的Appender） level(TRACE,DEBUG,INFO,WARN,ERROR,ALL,OFF,INHERITED):选填，不填则同INHERITED，代表继承父logger的日志级别，大小写不敏感。 appender-ref：选填，子标签（非属性），可以配置多个。中有ref标签指定Appender的name.","text":"配置文件的结构因为logback的配置十分灵活，所以无法通过一个DTD文件或者XML Schema来指定允许的语法。 标签名区分大小写对于特定的标签名字是大小写不敏感的，比如, 和 都是合法的配置，但是只能用关闭，不能是，但是针对驼峰规则是适用的，比如只能用关闭，不能是。驼峰规则可以参考维基百科camelCase convention configuration标签根标签，其中可以包含: Appender Logger Root property logger标签 name(string): 必填，logger的名称 additivity（boolean）：选填，是否最累加Appender（是否继承是用父logger的Appender） level(TRACE,DEBUG,INFO,WARN,ERROR,ALL,OFF,INHERITED):选填，不填则同INHERITED，代表继承父logger的日志级别，大小写不敏感。 appender-ref：选填，子标签（非属性），可以配置多个。中有ref标签指定Appender的name. root标签在整个配置文件中只能存在一个，可以当做是一个name为”ROOT”的Logger标签，但是不能有additivity属性，全局只能存在一个。 level（TRACE, DEBUG, INFO, WARN, ERROR, ALL or OFF）：选填，不填则默认为debug appender-ref：同logger appenders标签 name(string):必填，名称，用于引用 class(string):必填，Appender全限定类名，指定Appender 设置上下文名称每个logger都属于loggerContext, loggerContext默认的名字是“default”,这个名字可以设置 &lt;configuration&gt; &lt;contextName&gt;myAppName&lt;/contextName&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d %contextName [%t] %level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 定义变量可以用定义变量，在 1.0.7 版本之后可以使用互换。 可以通过file属性引入指定路径的properties文件进行变量填充。 通过resource属性可以加载classpath下面的properties文件。 可以通过${xxx}读取变量，可以是声明的变量，也可以是System.properties &lt;configuration&gt; &lt;property name=&quot;USER_HOME&quot; value=&quot;/home/sebastien&quot; /&gt; &lt;property file=&quot;src/main/java/resource/var.properties&quot; /&gt; &lt;property resource=&quot;resource1.properties&quot; /&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;$&#123;USER_HOME&#125;/myApp.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 变量的范围${xxx}到底可以引用哪些地方的变量呢？ 读取顺序依次： 配置文件直接定义的 LoggerContext VM的参数列表 环境变量 可以通过scope指定property的作用域,可选值:”local”, “context” 和 “system”，不填默认为local 定义一个context作用域的变量: &lt;configuration&gt; &lt;property scope=&quot;context&quot; name=&quot;nodeId&quot; value=&quot;firstNode&quot; /&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;/opt/$&#123;nodeId&#125;/myApp.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 变量的默认值可以通过 -: 操作符合来使用默认值，比如${LOG_DIR -: /path/logdir} 如果LOG_DIR在域中取不到，则用默认值/path/logdir 变量的嵌套名称和值都是支持嵌套的，默认值中也可以使用。 假设 userid=uncle 比如${${userid}.password},可能值就是变为取${uncle.password}这个变量的值。 ${id:-${userid}}，id不存在则返回uncle 设置时间戳可以定义一个根据当前时间的动态变化的变量。 key：引用名字 datePattern：时间格式化，和Java的SimpleDateFormat一样。 timeReference 设置值“contextBirth”为logback启动时间，不写默认为当前时间 &lt;configuration&gt; &lt;!-- Insert the current time formatted as &quot;yyyyMMdd&#x27;T&#x27;HHmmss&quot; under the key &quot;bySecond&quot; into the logger context. This value will be available to all subsequent configuration elements. --&gt; &lt;timestamp key=&quot;now&quot; datePattern=&quot;yyyyMMdd&#x27;T&#x27;HHmmss&quot;/&gt; &lt;timestamp key=&quot;startTime&quot; datePattern=&quot;yyyyMMdd&#x27;T&#x27;HHmmss&quot; timeReference=&quot;contextBirth&quot;/&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;!-- use the previously created timestamp to create a uniquely named log file --&gt; &lt;file&gt;log-$&#123;bySecond&#125;.txt&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;%logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 定义动态的变量通过define标签定义变量，name为变量的值，class为PropertyDefiner接口的实现类，其中的属性是将会通过setter注入这个类，最后这个类的getPropertyValue（）方法将为name对应的值。 目前已经有的实现类： FileExistsPropertyDefiner 变量为主机名 ResourceExistsPropertyDefiner 校验文件是否存在 CanonicalHostNamePropertyDefiner 校验资源是否存在 可间一般用于动态获取一些值。 &lt;configuration&gt; &lt;define name=&quot;rootLevel&quot; class=&quot;a.class.implementing.PropertyDefiner&quot;&gt; &lt;shape&gt;round&lt;/shape&gt; &lt;color&gt;brown&lt;/color&gt; &lt;size&gt;24&lt;/size&gt; &lt;/define&gt; &lt;root level=&quot;$&#123;rootLevel&#125;&quot;/&gt; &lt;/configuration&gt; 条件判断需要依赖Janino库，支持嵌套 &lt;dependency&gt; &lt;groupId&gt;org.codehaus.janino&lt;/groupId&gt; &lt;artifactId&gt;janino&lt;/artifactId&gt; &lt;version&gt;3.0.6&lt;/version&gt; &lt;/dependency&gt; 例子： 其中property可以简写为p，语法和java中字符串语法一样 %d %-5level %logger{35} - %msg %n ${randomOutputDir}/conditional.log %d %-5level %logger{35} - %msg %n 从JNDI中获取变量从JNDI中检索一个AppName的值，赋值给contextName。 &lt;configuration&gt; &lt;insertFromJNDI env-entry-name=&quot;java:comp/env/appName&quot; as=&quot;appName&quot; /&gt; &lt;contextName&gt;$&#123;appName&#125;&lt;/contextName&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d $&#123;CONTEXT_NAME&#125; %level %msg %logger&#123;50&#125;%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;CONSOLE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 配置引入可以通过include标签引入一个配置从其他xml中 include：可以多种方式 resource：类路径 url：web file: 文件路径 include如果引入文件不存在，则会报告这个错误信息，如果想不报，可以使用属性 optional=”true” &lt;configuration&gt; &lt;include file=&quot;src/main/java/chapters/configuration/includedConfig.xml&quot;/&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;includedConsole&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; includedConfig.xml： &lt;included&gt; &lt;appender name=&quot;includedConsole&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;&quot;%d - %m%n&quot;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;/included&gt; 日志级别改变传播器0.9.25版本开始， logback-classic附带了LevelChangePropagator，是LoggerContextListener的实现类，用于监控日志等级改变，然后传输到java.util.logging框架中，这种传播消除了禁用日志语句对性能的影响 &lt;configuration debug=&quot;true&quot;&gt; &lt;contextListener class=&quot;ch.qos.logback.classic.jul.LevelChangePropagator&quot;/&gt; .... &lt;/configuration&gt; 设置resetJUL属性来实现日志等级改变时重置jcl。 &lt;configuration debug=&quot;true&quot;&gt; &lt;contextListener class=&quot;ch.qos.logback.classic.jul.LevelChangePropagator&quot;&gt; &lt;resetJUL&gt;true&lt;/resetJUL&gt; &lt;/contextListener&gt; .... &lt;/configuration&gt; 参考Chapter 3: Logback configuration","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback的配置","slug":"Java/日志框架/5.logback的配置","date":"2020-12-02T11:16:54.000Z","updated":"2020-12-02T11:16:54.000Z","comments":true,"path":"Java/日志框架/5.logback的配置.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/5.logback%E7%9A%84%E9%85%8D%E7%BD%AE.html","excerpt":"配置文件的加载顺序依次： classpath下的logback-test.xml classpath下的logback.groovy classpath下的logback.xml 通过SPI机制加载META-INF/services/com.qos.logback.classic.spi.Configurator文件，里面写配置类的全限定类名 以上都没有则使用自带的BasicConfigurator配置一个控制台输出日志的配置 设置其他方式加载配置文件 通过vm参数指定配置文件 -Dlogback.configurationFile=/path/to/config.xml 通过代码内设置System.setProperty(ContextInitializer.CONFIG_FILE_PROPERTY, &quot;/path/to/config.xml&quot;); 打印配置初始化信息 手动打印 public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(&quot;ROOT&quot;); logger.info(&quot;internal info&quot;); // assume SLF4J is bound to logback in the current environment LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); // print logback&#x27;s internal status StatusPrinter.print(lc); ... &#125; 自动打印 &lt;configuration debug=&quot;true&quot;&gt; ... &lt;/configuration&gt;","text":"配置文件的加载顺序依次： classpath下的logback-test.xml classpath下的logback.groovy classpath下的logback.xml 通过SPI机制加载META-INF/services/com.qos.logback.classic.spi.Configurator文件，里面写配置类的全限定类名 以上都没有则使用自带的BasicConfigurator配置一个控制台输出日志的配置 设置其他方式加载配置文件 通过vm参数指定配置文件 -Dlogback.configurationFile=/path/to/config.xml 通过代码内设置System.setProperty(ContextInitializer.CONFIG_FILE_PROPERTY, &quot;/path/to/config.xml&quot;); 打印配置初始化信息 手动打印 public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(&quot;ROOT&quot;); logger.info(&quot;internal info&quot;); // assume SLF4J is bound to logback in the current environment LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); // print logback&#x27;s internal status StatusPrinter.print(lc); ... &#125; 自动打印 &lt;configuration debug=&quot;true&quot;&gt; ... &lt;/configuration&gt; StatusListener方式 自带的有OnConsoleStatusListener，也可以自己实现 &lt;configuration&gt; &lt;statusListener class=&quot;ch.qos.logback.core.status.OnConsoleStatusListener&quot; /&gt; &lt;/configuration&gt; 自动扫描更改并且更新配置文件设置scan为true，则会启动ReconfigureOnChangeTask按照指定周期更新配置。 &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;30 seconds&quot; &gt; ... &lt;/configuration&gt; /** * @author zhanghongguo@sensorsdata.cn * @since 2020/12/02 19:54 */ public class ScanConfigModifySample &#123; public static void main(String[] args) throws InterruptedException &#123; Logger logger = LoggerFactory.getLogger(ScanConfigModifySample.class); while (true) &#123; logger.info(&quot;scan period by 1 seconds&quot;); Thread.sleep(2000); &#125; &#125; &#125; 然后修改编译后的target/的配置文件，自动更新。 启用在堆栈跟踪中显示Jar包信息也就是在打印除了打印堆栈信息外还会显示这一栈信息中属于哪个jar包合jar包的版本信息。这个计算代价很高，特别是在异常频繁发生的情况下。 配置中启用 &lt;configuration packagingData=&quot;true&quot;&gt; ... &lt;/configuration&gt; 代码中启用 LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); lc.setPackagingDataEnabled(true); 停止日志记录代码控制直接停止日志记录器。 LoggerContext context = (LoggerContext) LoggerFactory.getILoggerFactory(); Logger logger = context.getLogger(&quot;ROOT&quot;); logger.info(&quot;stop start&quot;); context.stop(); //不显示 logger.info(&quot;is stop?&quot;); 注册日志停止记录的shutdownHook，在独立的Java应用程序中，向配置文件中添加指令是确保JVM退出之前允许任何正在进行的压缩任务完成的简便方法，在web应用中，这个会自动注册，shutdownHook /&gt;指令是多余的。 可以通过class来指定自己的showdownHook &lt;configuration debug=&quot;true&quot;&gt; &lt;shutdownHook/&gt; .... &lt;/configuration&gt; 参考Chapter 3: Logback configuration","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback的架构","slug":"Java/日志框架/4.logback的架构","date":"2020-12-02T06:54:18.000Z","updated":"2020-12-02T06:54:18.000Z","comments":true,"path":"Java/日志框架/4.logback的架构.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/4.logback%E7%9A%84%E6%9E%B6%E6%9E%84.html","excerpt":"模块划分当前logback被分为了三个模块 logback-core，为其他两个模块提供基础功能 logback-classic，是一个相对于log4j的显著改进版本，实现了slf4j的api，所以可以轻松的切换其他日志框架，比如jul logback-access.提供了servlet容器的http访问日志记录的功能 Logger,Appenders和Layouts这个logback建立在这三个主要的类上面，这三个组件提供了，允许开发着在选择何种等级的日志(Appenders) 、控制日志的格式（Layouts）、和在哪里打日志（logger） Logger是在logback-classic中的、Appenders和Layouts是在logback-core中的。 Logger名称继承通常情况下，我们给Logger命名都是通过类的全限定类名。 LoggerContext负责创建Logger，并且按照树一样的格式来进行管理，所以Logger也是分等级的，root logger就是顶端，分级规则也很简单，就是通过一个英文点来进行分，比如 com.unclezs.log，名字为com.unclezs的Logger就比名字为com.unclezs.log的Logger等级高。","text":"模块划分当前logback被分为了三个模块 logback-core，为其他两个模块提供基础功能 logback-classic，是一个相对于log4j的显著改进版本，实现了slf4j的api，所以可以轻松的切换其他日志框架，比如jul logback-access.提供了servlet容器的http访问日志记录的功能 Logger,Appenders和Layouts这个logback建立在这三个主要的类上面，这三个组件提供了，允许开发着在选择何种等级的日志(Appenders) 、控制日志的格式（Layouts）、和在哪里打日志（logger） Logger是在logback-classic中的、Appenders和Layouts是在logback-core中的。 Logger名称继承通常情况下，我们给Logger命名都是通过类的全限定类名。 LoggerContext负责创建Logger，并且按照树一样的格式来进行管理，所以Logger也是分等级的，root logger就是顶端，分级规则也很简单，就是通过一个英文点来进行分，比如 com.unclezs.log，名字为com.unclezs的Logger就比名字为com.unclezs.log的Logger等级高。 获取root logger: Logger rootLogger = LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); 日志级别与继承的关系slf4j提供的日志级别TRACE, DEBUG, INFO, WARN 和 ERROR TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR. 获取日志的有效等级，当一个log.xx方法执行时，如果当前命名空间没有对应Level，就会根去查找祖先节点的日志级别，直到找到为止 判断日志是否会被打印： 摘自官方文档： A log request of level p issued to a logger having an effective level q, is enabled if p &gt;= q. 比如com.unclezs.a 配置的logger日志级别为infocom.unclezs.a.b 配置的logger日志级别为error在com.unclezs.a.b调用log.warn 得到有效日志等级为error,请求日志等级为warn，warn &lt; error则不打印 检索Logger通常情况下我们都是通过Clazz.class来获取Logger，但是也可以传入他的全限定类名。 当然这个名字都是自己定义的，你可以命名为abc，bcd之类的，但是没有什么意义，安装全限定类名进行命名可以很好的利用日志级别按照名称继承等级的好处。 AppenderAppender允许我们将日志打到各种地方，可以是控制台，可以是文件，也可以是数据库、JML等等 一个logger可以拥有多个Appender，并且都会执行，所以你可以通过一个logger就能把日志打到控制台和文件。 Appender也是有累加性质的，也就是会查看父及logger有没有Appender ，如果有，则一起执行。可以在logger上配置additivity=false来关闭这个特性。 LayoutAppender的子节点，定义日志的格式。 %-4relative [%thread] %-5level %logger&#123;32&#125; - %msg%n 输出 176 [main] DEBUG manual.architecture.HelloWorld2 - Hello world. 第一个参数代表程序启动后所过时间。 参数化打印日志下面这种方式会引起 不论是否启用日志记录，都会有构造消息参数的消耗（类型转换） logger.debug(&quot;Entry number: &quot; + i + &quot; is &quot; + String.valueOf(entry[i])); 通常情况下通过下面这种防止来防止消息参数的构造消耗，但是通过这种方法如果日志是开启的情况下，还是会出现同样的情况，甚至还多了个boolean类型的判断消耗 if(logger.isDebugEnabled()) &#123; logger.debug(&quot;Entry number: &quot; + i + &quot; is &quot; + String.valueOf(entry[i])); &#125; 更好的方案，这样的操作的好处就是，在不进行日志打印的时候，不会进行消息参数构造，也就不会有类型转换的消耗。 logger.debug(&quot;The new entry is &#123;&#125;.&quot;, entry); logger.debug(&quot;Value &#123;&#125; was inserted between &#123;&#125; and &#123;&#125;.&quot;, paramArray); 从一次log.info()的过程 参考Chapter 2: Architecture","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"logback介绍","slug":"Java/日志框架/3.logback介绍","date":"2020-12-02T06:21:57.000Z","updated":"2020-12-02T06:21:57.000Z","comments":true,"path":"Java/日志框架/3.logback介绍.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/3.logback%E4%BB%8B%E7%BB%8D.html","excerpt":"什么是logback?logback是继log4j之后的一个日志框架，比其他现存的日志框架更快占用空间更小，有时候差距很大，还提供了一些其他日志框架没有的功能，作者Ceki Gülcü,也是log4j的开发者之一。 需要的库 slf4j-api.jar logback-core.jar logback-classic.jar 获取内部日志信息我们可以通过StatusManager来访问发生在logback生命周期中的一些事件，可以通过StatusPrinter.print方法打印到控制台 // print internal state LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); StatusPrinter.print(lc); 可以看到logback查找配置文件和装载配置的过程。如果没有配置会打印配置文件缺失的信息 12:49:22.203 [main] DEBUG chapters.introduction.HelloWorld2 - Hello world. 12:49:22,076 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy] 12:49:22,078 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml] 12:49:22,093 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml] 12:49:22,093 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Setting up default configuration. 配置使用","text":"什么是logback?logback是继log4j之后的一个日志框架，比其他现存的日志框架更快占用空间更小，有时候差距很大，还提供了一些其他日志框架没有的功能，作者Ceki Gülcü,也是log4j的开发者之一。 需要的库 slf4j-api.jar logback-core.jar logback-classic.jar 获取内部日志信息我们可以通过StatusManager来访问发生在logback生命周期中的一些事件，可以通过StatusPrinter.print方法打印到控制台 // print internal state LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); StatusPrinter.print(lc); 可以看到logback查找配置文件和装载配置的过程。如果没有配置会打印配置文件缺失的信息 12:49:22.203 [main] DEBUG chapters.introduction.HelloWorld2 - Hello world. 12:49:22,076 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy] 12:49:22,078 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml] 12:49:22,093 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml] 12:49:22,093 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Setting up default configuration. 配置使用 引入依赖 配置logback.xml 在想要打日志的类中通过org.slf4j.LoggerFactory.getLogger()获取日志记录器 调用logger的debug(), info(), warn() ，error() 方法记录日志 依赖使用&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 参考Chapter 1: Introduction to logback","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"两种常用日志框架搭配快速上手","slug":"Java/日志框架/2.两种常用日志框架搭配快速上手","date":"2020-12-02T06:14:42.000Z","updated":"2020-12-02T06:14:42.000Z","comments":true,"path":"Java/日志框架/2.两种常用日志框架搭配快速上手.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/2.%E4%B8%A4%E7%A7%8D%E5%B8%B8%E7%94%A8%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E6%90%AD%E9%85%8D%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B.html","excerpt":"SLF4J+LogBack用法依赖&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 基本用法/** * @author blog.unclezs.com * @date 2020/12/1 10:46 下午 */ public class LogbackSample &#123; static final Logger logger = LoggerFactory.getLogger(LogbackSample.class); public static void main(String[] args) &#123; logger.info(&quot;log by Logback&quot;); logger.warn(&quot;log by Logback&quot;); logger.error(&quot;log by Logback&quot;); logger.debug(&quot;log by Logback&quot;); logger.trace(&quot;log by Logback&quot;); &#125; &#125; 如何配置logback.xmlLogback 配置官方文档 Common-Logging+Log4J的用法依赖&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt;","text":"SLF4J+LogBack用法依赖&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 基本用法/** * @author blog.unclezs.com * @date 2020/12/1 10:46 下午 */ public class LogbackSample &#123; static final Logger logger = LoggerFactory.getLogger(LogbackSample.class); public static void main(String[] args) &#123; logger.info(&quot;log by Logback&quot;); logger.warn(&quot;log by Logback&quot;); logger.error(&quot;log by Logback&quot;); logger.debug(&quot;log by Logback&quot;); logger.trace(&quot;log by Logback&quot;); &#125; &#125; 如何配置logback.xmlLogback 配置官方文档 Common-Logging+Log4J的用法依赖&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt; 基本用法/** * @author blog.unclezs.com * @date 2020/12/1 10:50 下午 */ public class Log4jSample &#123; public static void main(String[] args) &#123; Logger logger = LogManager.getLogger(Log4jSample.class); logger.info(&quot;log by log4j2&quot;); logger.warn(&quot;log by log4j2&quot;); logger.error(&quot;log by log4j2&quot;); logger.debug(&quot;log by log4j2&quot;); logger.trace(&quot;log by log4j2&quot;); &#125; &#125; 配置log4j2.xml Apache Log4J2 官方配置文档","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"好看的彩色日志输出","slug":"Java/日志框架/13.好看的彩色日志输出","date":"2020-12-02T06:09:55.000Z","updated":"2020-12-02T06:09:55.000Z","comments":true,"path":"Java/日志框架/13.好看的彩色日志输出.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/13.%E5%A5%BD%E7%9C%8B%E7%9A%84%E5%BD%A9%E8%89%B2%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA.html","excerpt":"高亮配置IDEA无法显示彩色日志 VM参数方式 -Dlog4j.skipJansi&#x3D;false Jar包方式 &lt;dependency&gt; &lt;groupId&gt;org.fusesource.jansi&lt;/groupId&gt; &lt;artifactId&gt;jansi&lt;/artifactId&gt; &lt;version&gt;1.18&lt;/version&gt; &lt;/dependency&gt; log4j2方案一%style&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;black&#125; [%highlight&#123;%thread&#125;] %highlight&#123;%-5level&#125; %style&#123;%C&#125;&#123;bright,Magenta&#125; - %style&#123;%msg&#125;&#123;bright,Green&#125;%n","text":"高亮配置IDEA无法显示彩色日志 VM参数方式 -Dlog4j.skipJansi&#x3D;false Jar包方式 &lt;dependency&gt; &lt;groupId&gt;org.fusesource.jansi&lt;/groupId&gt; &lt;artifactId&gt;jansi&lt;/artifactId&gt; &lt;version&gt;1.18&lt;/version&gt; &lt;/dependency&gt; log4j2方案一%style&#123;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;&#125;&#123;black&#125; [%highlight&#123;%thread&#125;] %highlight&#123;%-5level&#125; %style&#123;%C&#125;&#123;bright,Magenta&#125; - %style&#123;%msg&#125;&#123;bright,Green&#125;%n 方案二%style&#123;%d&#123;ISO8601&#125;&#125;&#123;bright,white&#125; %highlight&#123;%-5level&#125; %style&#123;[LOGID:%X&#123;ydbus_logid&#125;]&#125;&#123;cyan&#125; [%style&#123;%t&#125;&#123;bright,blue&#125;] [%style&#123;%C&#123;5.&#125;&#125;&#123;bright,yellow&#125;:%L] %msg%n%style&#123;%throwable&#125;&#123;red&#125; logbackLogBack 彩色配置文档 方案一%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %easyHighlight(%5.5level) %magenta(%pid) --- [%15.15thread] %cyan(%-40.40logger&#123;39&#125; [%4.4line]) : %msg%n 方案二%red(%d&#123;yyyy-MM-dd HH:mm:ss&#125;) %green([%thread]) %highlight(%-5level) %boldMagenta(%logger) - %cyan(%msg%n) 参考 LogBack 彩色配置文档","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"初识Java中的日志","slug":"Java/日志框架/1.初识Java中的日志","date":"2020-12-01T16:57:46.000Z","updated":"2020-12-01T16:57:46.000Z","comments":true,"path":"Java/日志框架/1.初识Java中的日志.html","link":"","permalink":"https://blog.unclezs.com/Java/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/1.%E5%88%9D%E8%AF%86Java%E4%B8%AD%E7%9A%84%E6%97%A5%E5%BF%97.html","excerpt":"Java中的日志框架 上图不是非常精准，但是能够比较清晰地展示现有Java日志体系的主体架构。Java日志体系大体可以分为三个部分：日志门面接口、桥接器、日志框架具体实现。 常用日志框架类别 Log4j： Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。Log4j是几种Java日志框架之一。 Log4j2： Apache Log4j 2是apache开发的一款Log4j的升级产品。 Commons Logging： Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging。 Slf4j： 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）。 Logback： 一套日志组件的实现(Slf4j阵营)。 Jul (Java Util Logging)：自Java1.4以来的官方日志实现。 发展史 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议Sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，Log4j就已经成为一项成熟的技术，使得Log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是Log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü不适应Apache的工作方式，离开了Apache。然后先后创建了Slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。 现今，Java日志领域被划分为两大阵营：Commons Logging阵营和Slf4j阵营。Commons Logging在Apache大树的笼罩下，有很大的用户基数。但有证据表明，形式正在发生变化。2013年底有人分析了GitHub上30000个项目，统计出了最流行的100个Libraries，可以看出Slf4j的发展趋势更好： Apache眼看有被Logback反超的势头，于2012-07重写了Log4j 1.x，成立了新的项目Log4j 2, Log4j 2具有Logback的所有特性。 常用日志框架关系 Log4j 2与Log4j 1发生了很大的变化，Log4j 2不兼容Log4j 1。 Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接口，使得子系统更容易使用)。Log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用者只需要关注接口而无需关注具体的实现，做到解耦。 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 Logback必须配合Slf4j使用。由于Logback和Slf4j是同一个作者，其兼容性不言而喻。 Commons Logging与Slf4j实现机制对比","text":"Java中的日志框架 上图不是非常精准，但是能够比较清晰地展示现有Java日志体系的主体架构。Java日志体系大体可以分为三个部分：日志门面接口、桥接器、日志框架具体实现。 常用日志框架类别 Log4j： Apache Log4j是一个基于Java的日志记录工具。它是由Ceki Gülcü首创的，现在则是Apache软件基金会的一个项目。Log4j是几种Java日志框架之一。 Log4j2： Apache Log4j 2是apache开发的一款Log4j的升级产品。 Commons Logging： Apache基金会所属的项目，是一套Java日志接口，之前叫Jakarta Commons Logging，后更名为Commons Logging。 Slf4j： 类似于Commons Logging，是一套简易Java日志门面，本身并无日志的实现。（Simple Logging Facade for Java，缩写Slf4j）。 Logback： 一套日志组件的实现(Slf4j阵营)。 Jul (Java Util Logging)：自Java1.4以来的官方日志实现。 发展史 1996年早期，欧洲安全电子市场项目组决定编写它自己的程序跟踪API(Tracing API)。经过不断的完善，这个API终于成为一个十分受欢迎的Java日志软件包，即Log4j。后来Log4j成为Apache基金会项目中的一员。 期间Log4j近乎成了Java社区的日志标准。据说Apache基金会还曾经建议Sun引入Log4j到java的标准库中，但Sun拒绝了。 2002年Java1.4发布，Sun推出了自己的日志库JUL(Java Util Logging),其实现基本模仿了Log4j的实现。在JUL出来以前，Log4j就已经成为一项成熟的技术，使得Log4j在选择上占据了一定的优势。 接着，Apache推出了Jakarta Commons Logging，JCL只是定义了一套日志接口(其内部也提供一个Simple Log的简单实现)，支持运行时动态加载日志组件的实现，也就是说，在你应用代码里，只需调用Commons Logging的接口，底层实现可以是Log4j，也可以是Java Util Logging。 后来(2006年)，Ceki Gülcü不适应Apache的工作方式，离开了Apache。然后先后创建了Slf4j(日志门面接口，类似于Commons Logging)和Logback(Slf4j的实现)两个项目，并回瑞典创建了QOS公司，QOS官网上是这样描述Logback的：The Generic，Reliable Fast&amp;Flexible Logging Framework(一个通用，可靠，快速且灵活的日志框架)。 现今，Java日志领域被划分为两大阵营：Commons Logging阵营和Slf4j阵营。Commons Logging在Apache大树的笼罩下，有很大的用户基数。但有证据表明，形式正在发生变化。2013年底有人分析了GitHub上30000个项目，统计出了最流行的100个Libraries，可以看出Slf4j的发展趋势更好： Apache眼看有被Logback反超的势头，于2012-07重写了Log4j 1.x，成立了新的项目Log4j 2, Log4j 2具有Logback的所有特性。 常用日志框架关系 Log4j 2与Log4j 1发生了很大的变化，Log4j 2不兼容Log4j 1。 Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接口，使得子系统更容易使用)。Log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用者只需要关注接口而无需关注具体的实现，做到解耦。 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 Logback必须配合Slf4j使用。由于Logback和Slf4j是同一个作者，其兼容性不言而喻。 Commons Logging与Slf4j实现机制对比Commons Logging实现机制Commons Logging是通过动态查找机制，在程序运行时，使用自己的ClassLoader寻找和载入本地具体的实现。详细策略可以查看commons-logging-*.jar包中的org.apache.commons.logging.impl.LogFactoryImpl.java文件。由于Osgi不同的插件使用独立的ClassLoader，Osgi的这种机制保证了插件互相独立, 其机制限制了Commons Logging在Osgi中的正常使用。 Slf4j实现机制Slf4j在编译期间，静态绑定本地的Log库，因此可以在Osgi中正常使用。它是通过查找类路径下org.slf4j.impl.StaticLoggerBinder，然后在StaticLoggerBinder中进行绑定。 参考 LogBack 官方手册 LogBack 官方配置文档 Apache Log4J2 官方配置文档 Java常用日志框架介绍","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"}],"tags":[{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"}],"author":"Unclezs"},{"title":"用Jcommander打造自己的Java的命令行工具","slug":"Java/工具/用Jcommander打造自己的Java的命令行工具","date":"2020-11-30T16:34:35.000Z","updated":"2020-11-30T16:34:35.000Z","comments":true,"path":"Java/工具/用Jcommander打造自己的Java的命令行工具.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B7%A5%E5%85%B7/%E7%94%A8Jcommander%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84Java%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7.html","excerpt":"前言有时候我们用Java开发了一个小工具，希望通过命令行(CLI)或者图形界面直接调用。命令行相较于图形界面，实现迅速，交互更接近于程序员人群，而Jcommander就是Java的这样一款工具。 示例依赖&lt;dependency&gt; &lt;groupId&gt;com.beust&lt;/groupId&gt; &lt;artifactId&gt;jcommander&lt;/artifactId&gt; &lt;version&gt;1.78&lt;/version&gt; &lt;/dependency&gt; 例子package com.unclezs.jcommander; import com.beust.jcommander.JCommander; import com.beust.jcommander.Parameter; import com.beust.jcommander.UnixStyleUsageFormatter; import java.nio.file.Files; import java.nio.file.Paths; /** * 用法示例 * * @author blog.unclezs.com * @date 2020/12/1 12:15 上午 */ public class Main &#123; @Parameter(names = &#123;&quot;--path&quot;, &quot;-p&quot;&#125;, description = &quot;文件路径&quot;, order = 1) private String path; @Parameter(names = &#123;&quot;--version&quot;, &quot;-v&quot;&#125;, description = &quot;版本&quot;, order = 2, arity = 0) private boolean version; @Parameter(names = &#123;&quot;-h&quot;&#125;, description = &quot;帮助&quot;, order = 3, arity = 0) private boolean usage; @Parameter(names = &quot;--help&quot;, help = true) private boolean help; public static void main(String[] args) &#123; Main pathUtil = new Main(); JCommander jCommander = JCommander.newBuilder() .programName(&quot;pathUtil&quot;) .addObject(pathUtil) .build(); jCommander.setUsageFormatter(new UnixStyleUsageFormatter(jCommander)); jCommander.parse(args); if (pathUtil.version) &#123; System.out.println(&quot;pathUtil version 6.6.6&quot;); return; &#125; if (pathUtil.path != null) &#123; System.out.println(&quot;path exist? &quot; + Files.exists(Paths.get(pathUtil.path))); return; &#125; if (pathUtil.usage) &#123; jCommander.usage(); return; &#125; if (pathUtil.help) &#123; System.out.println(&quot;help invoke&quot;); &#125; &#125; &#125; 运行后的效果图 了解更多","text":"前言有时候我们用Java开发了一个小工具，希望通过命令行(CLI)或者图形界面直接调用。命令行相较于图形界面，实现迅速，交互更接近于程序员人群，而Jcommander就是Java的这样一款工具。 示例依赖&lt;dependency&gt; &lt;groupId&gt;com.beust&lt;/groupId&gt; &lt;artifactId&gt;jcommander&lt;/artifactId&gt; &lt;version&gt;1.78&lt;/version&gt; &lt;/dependency&gt; 例子package com.unclezs.jcommander; import com.beust.jcommander.JCommander; import com.beust.jcommander.Parameter; import com.beust.jcommander.UnixStyleUsageFormatter; import java.nio.file.Files; import java.nio.file.Paths; /** * 用法示例 * * @author blog.unclezs.com * @date 2020/12/1 12:15 上午 */ public class Main &#123; @Parameter(names = &#123;&quot;--path&quot;, &quot;-p&quot;&#125;, description = &quot;文件路径&quot;, order = 1) private String path; @Parameter(names = &#123;&quot;--version&quot;, &quot;-v&quot;&#125;, description = &quot;版本&quot;, order = 2, arity = 0) private boolean version; @Parameter(names = &#123;&quot;-h&quot;&#125;, description = &quot;帮助&quot;, order = 3, arity = 0) private boolean usage; @Parameter(names = &quot;--help&quot;, help = true) private boolean help; public static void main(String[] args) &#123; Main pathUtil = new Main(); JCommander jCommander = JCommander.newBuilder() .programName(&quot;pathUtil&quot;) .addObject(pathUtil) .build(); jCommander.setUsageFormatter(new UnixStyleUsageFormatter(jCommander)); jCommander.parse(args); if (pathUtil.version) &#123; System.out.println(&quot;pathUtil version 6.6.6&quot;); return; &#125; if (pathUtil.path != null) &#123; System.out.println(&quot;path exist? &quot; + Files.exists(Paths.get(pathUtil.path))); return; &#125; if (pathUtil.usage) &#123; jCommander.usage(); return; &#125; if (pathUtil.help) &#123; System.out.println(&quot;help invoke&quot;); &#125; &#125; &#125; 运行后的效果图 了解更多 我自己写的一些示例 官方文档 另外一款命令行解析工具Apache Commons CLI","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://blog.unclezs.com/categories/Java/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"Jcommander","slug":"Jcommander","permalink":"https://blog.unclezs.com/tags/Jcommander/"}],"author":"Unclezs"},{"title":"把自己的包到Maven中央仓库","slug":"Java/Maven/把自己的包到Maven中央仓库","date":"2020-11-29T13:16:57.000Z","updated":"2020-11-29T13:16:57.000Z","comments":true,"path":"Java/Maven/把自己的包到Maven中央仓库.html","link":"","permalink":"https://blog.unclezs.com/Java/Maven/%E6%8A%8A%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8C%85%E5%88%B0Maven%E4%B8%AD%E5%A4%AE%E4%BB%93%E5%BA%93.html","excerpt":"Sonatype 注册Sonatype 账户。 登录Sonaytype Jira 创建如下的 issue，申请发版权限，等待管理员审核。 等待回复，如果你填了自定义域名则会这么回复你。也就是有自定义域名就解析自定义域名TXT到这个issue，如果没有则用github的 我是自定义域名所以提交了 然后回复issue,说你已经成功解析了，然后等他处理就行了 准备 GPG这个用于加密的，在发release的时候会校验，发快照版本不会校验。 查看是否安装gpg --version 能够显示 GPG 的版本信息，说明已经安装，否则需要去官网下载安装。下载地址如下： window: http://www.gpg4win.org/download.html OSX: https://gnupg.org/download/index.html 能够显示 GPG 的版本信息，说明已经安装，否则需要去官网下载安装。下载地址如下：","text":"Sonatype 注册Sonatype 账户。 登录Sonaytype Jira 创建如下的 issue，申请发版权限，等待管理员审核。 等待回复，如果你填了自定义域名则会这么回复你。也就是有自定义域名就解析自定义域名TXT到这个issue，如果没有则用github的 我是自定义域名所以提交了 然后回复issue,说你已经成功解析了，然后等他处理就行了 准备 GPG这个用于加密的，在发release的时候会校验，发快照版本不会校验。 查看是否安装gpg --version 能够显示 GPG 的版本信息，说明已经安装，否则需要去官网下载安装。下载地址如下： window: http://www.gpg4win.org/download.html OSX: https://gnupg.org/download/index.html 能够显示 GPG 的版本信息，说明已经安装，否则需要去官网下载安装。下载地址如下： 生成秘钥对此时需要输入姓名、邮箱等字段，其它字段可使用默认值，此外，还需要输入一个 Passphase，相当于一个密钥库的密码，一定不要忘了，也不要告诉别人，一定要记下来，后面会用到。 gpg --gen-key 查看公钥gpg --list-keys 可见这里的公钥的 ID是：5A68166AF292264925C6A5053C6675A0EE56F4AA，稍后就会用到。 将公钥发布到 PGP 密钥服务器gpg --keyserver hkp:&#x2F;&#x2F;pool.sks-keyservers.net --send-keys 5A68166AF292264925C6A5053C6675A0EE56F4AA 此后可使用本地的私钥来对上传构件进行数字签名，而下载该构件的用户可通过上传的公钥来验证签名，也就是说，大家可以验证这个构件是否由本人上传的，因为有可能该构件被坏人给篡改了。 如果提示发布失败，可以多尝试几次，如果实在不行，可更换地址源，如 hkp://keyserver.ubuntu.com:11371。 查询公钥是否发布成功gpg --keyserver hkp:&#x2F;&#x2F;pool.sks-keyservers.net --recv-keys 5A68166AF292264925C6A5053C6675A0EE56F4AA 实际上就是从 key server 上通过公钥 ID 来接收公钥，此外也可以到 sks-keyservers.net 上通过公钥 ID 去查询。 修改 Maven 配置文件使用自己注册的 Sonatype 账号的用户名与密码来配置server信息到setting.xml &lt;settings&gt; ... &lt;servers&gt; &lt;server&gt; &lt;id&gt;oss&lt;/id&gt; &lt;username&gt;用户名&lt;/username&gt; &lt;password&gt;密码&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; ... &lt;/settings&gt; 修改项目的Maven配置pom.xml，注意下面的都是必备的 &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceencoding&gt;UTF-8&lt;/project.build.sourceencoding&gt; &lt;/properties&gt; &lt;name&gt;Unclezs&#x27;s tools repo&lt;/name&gt; &lt;description&gt;Unclezs&#x27;s repo&lt;/description&gt; &lt;url&gt;https://github.com/unclezs/xtools&lt;/url&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;developers&gt; &lt;developer&gt; &lt;name&gt;unclezs&lt;/name&gt; &lt;email&gt;1585503310@qq.com&lt;/email&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;scm&gt; &lt;url&gt;https://github.com/unclezs/xtools.git&lt;/url&gt; &lt;connection&gt;scm:git:https://github.com/xtools.git&lt;/connection&gt; &lt;/scm&gt; &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;!-- 对应setting.xml里面的ID --&gt; &lt;id&gt;oss&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;oss&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- doc plugin,Maven API文档生成插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;additionalJOptions&gt; &lt;additionalJOption&gt;-Xdoclint:none&lt;/additionalJOption&gt; &lt;/additionalJOptions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- resources plugin,Maven 资源插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- compiler plugin,Maven 编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- gpg 加密校验 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sign&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 部署mvn clean deploy 如果成功了直接上 https://oss.sonatype.org/ 去查看 打release包会先进行暂存，需要到这上面进行操作发布，首先选中发布的版本（上传后看的到），点击close，如果校验通过，则点击release发布，然后在issue处回复并关闭。 一些问题gpg: 签名时失败处理gpg: signing failed: Inappropriate ioctl for device 添加环境变量 export GPG_TTY&#x3D;$(tty) 执行 Close 出现 Failed: Signature Validation 到 https://gpgtools.org/ 上下载了macOS 版本的 GPG Suite Tools客户端工具，安装好之后，打开 GPG Keychain，这是你可能会直接看到刚才生成的GPG秘钥被列出来，你只需要选中，然后右键选中 Send Public to Key Server，接着等待3-5秒，弹出提示 successfully，这一次是真的上传成功了；再次重复 deploy=》Close-》release 到仓库查看https://search.maven.org/ 去搜索自己的包看看是不是存在。同步会有一定延迟。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://blog.unclezs.com/categories/Java/Maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://blog.unclezs.com/tags/maven/"}],"author":"Unclezs"},{"title":"设计模式-外观模式","slug":"Java/设计模式/设计模式-外观模式","date":"2020-11-27T08:54:20.000Z","updated":"2020-11-27T08:54:20.000Z","comments":true,"path":"Java/设计模式/设计模式-外观模式.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F.html","excerpt":"定义与特点外观（Facade）模式又叫作门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 在日常编码工作中，我们都在有意无意的大量使用外观模式。只要是高层模块需要调度多个子系统（2个以上的类对象），我们都会自觉地创建一个新的类封装这些子系统，提供精简的接口，让高层模块可以更加容易地间接调用这些子系统的功能。尤其是现阶段各种第三方SDK、开源类库，很大概率都会使用外观模式。 外观（Facade）模式是“迪米特法则”的典型应用，它有以下主要优点。 降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。 外观（Facade）模式的主要缺点如下。 不能很好地限制客户使用子系统类，很容易带来未知风险。 增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 结构与实现外观（Facade）模式的结构比较简单，主要是定义了一个高层接口。它包含了对各个子系统的引用，客户端可以通过它访问各个子系统的功能。现在来分析其基本结构和实现方法。 模式的结构","text":"定义与特点外观（Facade）模式又叫作门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 在日常编码工作中，我们都在有意无意的大量使用外观模式。只要是高层模块需要调度多个子系统（2个以上的类对象），我们都会自觉地创建一个新的类封装这些子系统，提供精简的接口，让高层模块可以更加容易地间接调用这些子系统的功能。尤其是现阶段各种第三方SDK、开源类库，很大概率都会使用外观模式。 外观（Facade）模式是“迪米特法则”的典型应用，它有以下主要优点。 降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。 外观（Facade）模式的主要缺点如下。 不能很好地限制客户使用子系统类，很容易带来未知风险。 增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 结构与实现外观（Facade）模式的结构比较简单，主要是定义了一个高层接口。它包含了对各个子系统的引用，客户端可以通过它访问各个子系统的功能。现在来分析其基本结构和实现方法。 模式的结构外观（Facade）模式包含以下主要角色。 外观（Facade）角色：为多个子系统对外提供一个共同的接口。 子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。 客户（Client）角色：通过一个外观角色访问各个子系统的功能。 模式的实现package com.unclezs.facade; public class FacadePattern &#123; public static void main(String[] args) &#123; Facade f=new Facade(); f.method(); &#125; &#125; //外观角色 class Facade &#123; private SubSystem01 obj1=new SubSystem01(); private SubSystem02 obj2=new SubSystem02(); private SubSystem03 obj3=new SubSystem03(); public void method() &#123; obj1.method1(); obj2.method2(); obj3.method3(); &#125; &#125; //子系统角色 class SubSystem01 &#123; public void method1() &#123; System.out.println(&quot;子系统01的method1()被调用！&quot;); &#125; &#125; //子系统角色 class SubSystem02 &#123; public void method2() &#123; System.out.println(&quot;子系统02的method2()被调用！&quot;); &#125; &#125; //子系统角色 class SubSystem03 &#123; public void method3() &#123; System.out.println(&quot;子系统03的method3()被调用！&quot;); &#125; &#125; 实际应用 在Shiro中的SecurityManager就是典型的Facade设计模式 SLF4J也是使用的Facade模式","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Facade","slug":"Facade","permalink":"https://blog.unclezs.com/tags/Facade/"},{"name":"外观模式","slug":"外观模式","permalink":"https://blog.unclezs.com/tags/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/"}],"author":"Unclezs"},{"title":"Java应用诊断利器Arthas","slug":"性能调优/Java应用诊断利器Arthas","date":"2020-11-26T10:51:57.000Z","updated":"2020-11-26T10:51:57.000Z","comments":true,"path":"性能调优/Java应用诊断利器Arthas.html","link":"","permalink":"https://blog.unclezs.com/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/Java%E5%BA%94%E7%94%A8%E8%AF%8A%E6%96%AD%E5%88%A9%E5%99%A8Arthas.html","excerpt":"简介简介Arthas是一个款Java的诊断工具，比如当前JVM中有哪些线程、动态监控方法的调用链、每个方法的调用时间等等，很强大。 安装使用arthas-boot下载arthas-boot.jar，然后用java -jar的方式启动： curl -O https:&#x2F;&#x2F;arthas.aliyun.com&#x2F;arthas-boot.jar java -jar arthas-boot.jar 打印帮助信息： java -jar arthas-boot.jar -h 如果下载速度比较慢，可以使用aliyun的镜像：","text":"简介简介Arthas是一个款Java的诊断工具，比如当前JVM中有哪些线程、动态监控方法的调用链、每个方法的调用时间等等，很强大。 安装使用arthas-boot下载arthas-boot.jar，然后用java -jar的方式启动： curl -O https:&#x2F;&#x2F;arthas.aliyun.com&#x2F;arthas-boot.jar java -jar arthas-boot.jar 打印帮助信息： java -jar arthas-boot.jar -h 如果下载速度比较慢，可以使用aliyun的镜像： java -jar arthas-boot.jar --repo-mirror aliyun --use-http 使用as.shArthas 支持在 Linux/Unix/Mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可： curl -L https:&#x2F;&#x2F;arthas.aliyun.com&#x2F;install.sh | sh 查看线程及MainClassthread 1会打印线程ID 1的栈，通常是main函数的线程。 反编译类jad fxlauncher.Launcher 可以查看类的加载器、类的位置、及反编译后的源码 watch用户查看方法返回值，及入参 web命令行Arthas目前支持Web Console，用户在attach成功之后，可以直接访问：http://127.0.0.1:3658/。 可以填入IP，远程连接其它机器上的arthas。 其他还有更强大的: Trace 方法内部调用路径，并输出方法路径上的每个节点上耗时 stack 输出当前方法被调用的调用路径 建议看看文档，神器值得一学 官网Arthas官网命令大全","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"name":"Java","slug":"性能调优/Java","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/Java/"}],"tags":[{"name":"arthas","slug":"arthas","permalink":"https://blog.unclezs.com/tags/arthas/"}],"author":"Unclezs"},{"title":"GRPC初识与快速入门","slug":"后端研发/RPC/GRPC初识与快速入门","date":"2020-11-20T10:05:55.000Z","updated":"2020-11-20T10:05:55.000Z","comments":true,"path":"后端研发/RPC/GRPC初识与快速入门.html","link":"","permalink":"https://blog.unclezs.com/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/RPC/GRPC%E5%88%9D%E8%AF%86%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.html","excerpt":"简介所谓RPC(remote procedure call 远程过程调用)框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从server/client模型。使用的时候客户端调用server端提供的接口就像是调用本地的函数一样。 环境配置创建一个maven项目 引入依赖 &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- necessary for Java 9+ --&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;annotations-api&lt;/artifactId&gt; &lt;version&gt;6.0.53&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 引入protocol buffer转Java的Maven插件 &lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.6.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.12.0:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.33.1:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 项目结构","text":"简介所谓RPC(remote procedure call 远程过程调用)框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从server/client模型。使用的时候客户端调用server端提供的接口就像是调用本地的函数一样。 环境配置创建一个maven项目 引入依赖 &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;version&gt;1.33.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- necessary for Java 9+ --&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;annotations-api&lt;/artifactId&gt; &lt;version&gt;6.0.53&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 引入protocol buffer转Java的Maven插件 &lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.6.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.12.0:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.33.1:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 项目结构 proto文件编写syntax &#x3D; &quot;proto3&quot;; option java_multiple_files &#x3D; true; option java_package &#x3D; &quot;com.unclezs&quot;; option java_outer_classname &#x3D; &quot;MyGrpcService&quot;; option objc_class_prefix &#x3D; &quot;HLW&quot;; &#x2F;&#x2F; The greeting service definition. service MyGrpcServer &#123; &#x2F;&#x2F; Sends a greeting rpc handle (Request) returns (Response) &#123;&#125; &#125; &#x2F;&#x2F; The request message containing the user&#39;s name. message Request &#123; string name &#x3D; 1; &#125; &#x2F;&#x2F; The response message containing the greetings message Response &#123; string message &#x3D; 1; &#125; 生成代码 服务端代码package com.unclezs.grpc; import com.sun.xml.internal.ws.client.sei.ResponseBuilder; import com.unclezs.MyGrpcServerGrpc; import com.unclezs.Request; import com.unclezs.Response; import io.grpc.Server; import io.grpc.ServerBuilder; import io.grpc.stub.StreamObserver; import java.io.IOException; public class HelloWorldServer &#123; private int port = 50051; private Server server; /** * 启动服务 * @throws IOException */ private void start() throws IOException &#123; server = ServerBuilder.forPort(port) .addService(new MyGrpcServerGrpcImpl()) .build() .start(); System.out.println(&quot;service start...&quot;); Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; System.err.println(&quot;*** shutting down gRPC server since JVM is shutting down&quot;); HelloWorldServer.this.stop(); System.err.println(&quot;*** server shut down&quot;); &#125; &#125;); &#125; private void stop() &#123; if (server != null) &#123; server.shutdown(); &#125; &#125; // block 一直到退出程序 private void blockUntilShutdown() throws InterruptedException &#123; if (server != null) &#123; server.awaitTermination(); &#125; &#125; public static void main(String[] args) throws IOException, InterruptedException &#123; final HelloWorldServer server = new HelloWorldServer(); server.start(); server.blockUntilShutdown(); &#125; // 实现 定义一个实现服务接口的类 private class MyGrpcServerGrpcImpl extends MyGrpcServerGrpc.MyGrpcServerImplBase &#123; @Override public void handle(Request req, StreamObserver&lt;Response&gt; responseObserver) &#123; //获取参数 System.out.println(&quot;收到的信息:&quot;+req.getName()); //这里可以放置具体业务处理代码 start //这里可以放置具体业务处理代码 end Response response= Response.newBuilder().setMessage(&quot;我收到了&quot;+req.getName()).build(); responseObserver.onNext(response); responseObserver.onCompleted(); &#125; &#125; &#125; 客户端代码package com.unclezs.grpc; import com.unclezs.MyGrpcServerGrpc; import com.unclezs.Request; import com.unclezs.Response; import io.grpc.ManagedChannel; import io.grpc.ManagedChannelBuilder; import io.grpc.StatusRuntimeException; import java.util.concurrent.TimeUnit; public class HelloWorldClient &#123; private final ManagedChannel channel; //一个gRPC信道 private final MyGrpcServerGrpc.MyGrpcServerBlockingStub blockingStub;//阻塞/同步 存根 //初始化信道和存根 public HelloWorldClient(String host,int port)&#123; this(ManagedChannelBuilder.forAddress(host, port) // Channels are secure by default (via SSL/TLS). For the example we disable TLS to avoid // needing certificates. .usePlaintext()); &#125; /** Construct client for accessing RouteGuide server using the existing channel. */ private HelloWorldClient(ManagedChannelBuilder&lt;?&gt; channelBuilder) &#123; channel = channelBuilder.build(); blockingStub = MyGrpcServerGrpc.newBlockingStub(channel); &#125; public void shutdown() throws InterruptedException &#123; channel.shutdown().awaitTermination(5, TimeUnit.SECONDS); &#125; //客户端方法 public void greet(String name)&#123; Request request = Request.newBuilder().setName(name).build(); Response response; try &#123; response = blockingStub.handle(request); &#125; catch (StatusRuntimeException e) &#123; System.out.println(&quot;RPC调用失败:&quot;+e.getMessage()); return; &#125; System.out.println(&quot;服务器返回信息:&quot;+response.getMessage()); &#125; public static void main(String[] args) throws InterruptedException &#123; HelloWorldClient client = new HelloWorldClient(&quot;127.0.0.1&quot;,50051); try &#123; for(int i=0;i&lt;5;i++)&#123; client.greet(&quot;world:&quot;+i); &#125; &#125;finally &#123; client.shutdown(); &#125; &#125; &#125; 启动后测试 参考gRPC 官方文档中文版","categories":[{"name":"后端研发","slug":"后端研发","permalink":"https://blog.unclezs.com/categories/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/"}],"tags":[{"name":"grpc","slug":"grpc","permalink":"https://blog.unclezs.com/tags/grpc/"}],"author":"Unclezs"},{"title":"ProtocolBuffer基本语法","slug":"后端研发/RPC/ProtocolBuffer基本语法","date":"2020-11-20T09:04:59.000Z","updated":"2020-11-20T09:04:59.000Z","comments":true,"path":"后端研发/RPC/ProtocolBuffer基本语法.html","link":"","permalink":"https://blog.unclezs.com/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/RPC/ProtocolBuffer%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html","excerpt":"简介 习惯用 Json、XML 数据存储格式的你们，相信大多都没听过Protocol Buffer Protocol Buffer 其实 是 Google出品的一种轻量 &amp; 高效的结构化数据存储格式，性能比 Json、XML 真的强！太！多！ 应用场景：传输数据量大 &amp; 网络环境不稳定 的数据存储、RPC 数据交换 的需求场景 他可以生成多种语言，Java、C++、Go、Python、C#、Dart。 定义一个message这个message相当于是一个实体类型，可以假象为一个JavaBean一样的东西，但是不止于此。 syntax &#x3D; &quot;proto3&quot;; message SearchRequest &#123; string query &#x3D; 1; int32 page_number &#x3D; 2; int32 result_per_page &#x3D; 3; &#125; 在Java里面的体现 class SearchRequest &#123; private string query; private page_number; private result_per_page; &#125; 成员变量的介绍","text":"简介 习惯用 Json、XML 数据存储格式的你们，相信大多都没听过Protocol Buffer Protocol Buffer 其实 是 Google出品的一种轻量 &amp; 高效的结构化数据存储格式，性能比 Json、XML 真的强！太！多！ 应用场景：传输数据量大 &amp; 网络环境不稳定 的数据存储、RPC 数据交换 的需求场景 他可以生成多种语言，Java、C++、Go、Python、C#、Dart。 定义一个message这个message相当于是一个实体类型，可以假象为一个JavaBean一样的东西，但是不止于此。 syntax &#x3D; &quot;proto3&quot;; message SearchRequest &#123; string query &#x3D; 1; int32 page_number &#x3D; 2; int32 result_per_page &#x3D; 3; &#125; 在Java里面的体现 class SearchRequest &#123; private string query; private page_number; private result_per_page; &#125; 成员变量的介绍语法格式： [数量修饰符] 类型修饰符 变量名称 = 标记序号 message SearchRequest &#123; repeated string query &#x3D; 1; repeated int32 page_number &#x3D; 2; int32 result_per_page &#x3D; 3; enum Corpus &#123; UNIVERSAL &#x3D; 0; WEB &#x3D; 1; IMAGES &#x3D; 2; LOCAL &#x3D; 3; NEWS &#x3D; 4; PRODUCTS &#x3D; 5; VIDEO &#x3D; 6; &#125; Corpus corpus &#x3D; 4; &#125; 数量修饰符 required:必须填写的字段 repeated:可以重复出现的，也就是数组或List optional:可选值 支持的类型 默认值 For strings, the default value is the empty string. For bytes, the default value is empty bytes. For bools, the default value is false. For numeric types, the default value is zero. For enums, the default value is the first defined enum value, which must be 0. 标记序号如您所见，消息定义中的每个字段都有一个唯一的编号。这些字段号用于标识消息二进制格式的字段，一旦使用了消息类型，就不应更改它们。 定义Serviceservice SearchService &#123; rpc Search(SearchRequest) returns (SearchResponse); &#125; 可以将他看作一个rpc的接口，里面有一个名字为Search的方法，入参为SearchRequest，相应结果为SearchResponse。可以定义多个，格式相同，SearchRequest也就是message类型的 例子syntax &#x3D; &quot;proto3&quot;; option java_multiple_files &#x3D; true; option java_package &#x3D; &quot;com.unclezs&quot;; option java_outer_classname &#x3D; &quot;MyGrpcService&quot;; option objc_class_prefix &#x3D; &quot;HLW&quot;; &#x2F;&#x2F; The greeting service definition. service MyGrpcServer &#123; &#x2F;&#x2F; Sends a greeting rpc handle (Request) returns (Response) &#123;&#125; &#125; &#x2F;&#x2F; The request message containing the user&#39;s name. message Request &#123; string name &#x3D; 1; repeated string list &#x3D; 2; &#125; &#x2F;&#x2F; The response message containing the greetings message Response &#123; string message &#x3D; 1; string test&#x3D;2; &#125; 更多Language Guide (proto3)","categories":[{"name":"后端研发","slug":"后端研发","permalink":"https://blog.unclezs.com/categories/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/"}],"tags":[{"name":"grpc","slug":"grpc","permalink":"https://blog.unclezs.com/tags/grpc/"}],"author":"Unclezs"},{"title":"Zookeeper一文入门","slug":"中间件/Zookeeper/Zookeeper一文入门","date":"2020-11-17T10:39:45.000Z","updated":"2020-11-17T10:39:45.000Z","comments":true,"path":"中间件/Zookeeper/Zookeeper一文入门.html","link":"","permalink":"https://blog.unclezs.com/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/Zookeeper%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8.html","excerpt":"简介官方文档上这么解释zookeeper，它是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 上面的解释有点抽象，简单来说zookeeper=文件系统+监听通知机制。 文件系统Zookeeper维护一个类似文件系统的数据结构：每个子目录项如 NameService 都被称作为 znode(目录节点)，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 有四种类型的znode： PERSISTENT-持久化目录节点客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL-临时目录节点客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 监听通知机制客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。 就这么简单，下面我们看看Zookeeper能做点什么呢？","text":"简介官方文档上这么解释zookeeper，它是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 上面的解释有点抽象，简单来说zookeeper=文件系统+监听通知机制。 文件系统Zookeeper维护一个类似文件系统的数据结构：每个子目录项如 NameService 都被称作为 znode(目录节点)，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 有四种类型的znode： PERSISTENT-持久化目录节点客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL-临时目录节点客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 监听通知机制客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。 就这么简单，下面我们看看Zookeeper能做点什么呢？ Zookeeper能做什么zookeeper功能非常强大，可以实现诸如分布式应用配置管理、统一命名服务、状态同步服务、集群管理等功能，我们这里拿比较简单的分布式应用配置管理为例来说明。 假设我们的程序是分布式部署在多台机器上，如果我们要改变程序的配置文件，需要逐台机器去修改，非常麻烦，现在把这些配置全部放到zookeeper上去，保存在 zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 zookeeper 的通知，然后从 zookeeper 获取新的配置信息应用到系统中。 如上，你大致应该了解zookeeper是个什么东西，大概能做些什么了，我们马上来学习下zookeeper的安装及使用，并开发一个小程序来实现zookeeper这个分布式配置管理的功能。 Zookeeper单机模式安装 配置JAVA环境，检验环境：java -version 下载并解压zookeeper cd /usr/local wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gz tar -zxvf zookeeper-3.4.12.tar.gz cd zookeeper-3.4.12 重命名配置文件zoo_sample.cfg cp conf/zoo_sample.cfg conf/zoo.cfg 启动zookeeper bin/zkServer.sh start 检测是否成功启动，用zookeeper客户端连接下服务端 bin/zk-Cli.sh 安装完成，测试 Zookeeper使用使用客户端命令操作zookeeper 使用 ls 命令来查看当前 ZooKeeper 中所包含的内容 创建一个新的 znode ，使用 create /zkPro myData 再次使用 ls 命令来查看现在 zookeeper 中所包含的内容： 下面我们运行 get 命令来确认第二步中所创建的 znode 是否包含我们所创建的字符串： 下面我们通过 set 命令来对 zk 所关联的字符串进行设置： 下面我们将刚才创建的 znode 删除 Java客户端依赖&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; 例子/** * @author zhanghongguo@sensorsdata.cn * @since 2020/11/17 17:40 */ public class CrudTest &#123; static ZooKeeper zooKeeper = null; static Stat stat = new Stat(); public static void main(String[] args) throws IOException, InterruptedException, KeeperException &#123; CountDownLatch countDownLatch = new CountDownLatch(1); zooKeeper = new ZooKeeper(&quot;10.120.194.170:2181&quot;, 4000, event -&gt; &#123; try &#123; if (Watcher.Event.KeeperState.SyncConnected == event.getState()&amp;&amp;null==event.getPath()) &#123; //如果收到了服务端的响应事件，连接成功 System.out.println(zooKeeper.getState()); &#125; else if (event.getType() == Watcher.Event.EventType.NodeDataChanged) &#123; System.out.println(new String(zooKeeper.getData(event.getPath(), true, stat))); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(new String(zooKeeper.getData(&quot;/uncle&quot;, true, stat))); countDownLatch.await(); &#125; &#125; 参考 Zookeeper入门看这篇就够了","categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Zookeeper","slug":"中间件/Zookeeper","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.unclezs.com/tags/zookeeper/"}],"author":"Unclezs"},{"title":"nginx的日志模块","slug":"服务器/Nginx/nginx的日志模块","date":"2020-11-09T06:08:35.000Z","updated":"2020-11-09T06:08:35.000Z","comments":true,"path":"服务器/Nginx/nginx的日志模块.html","link":"","permalink":"https://blog.unclezs.com/%E6%9C%8D%E5%8A%A1%E5%99%A8/Nginx/nginx%E7%9A%84%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97.html","excerpt":"前言今天看到了我司用nginx日志来进行原始数据采集，感觉十分有趣，并且平时对这个模块了解不多。所以便了解了解。 nginx日志模块的作用就是存储访问日志，而且可以高度控制日志的格式、压缩类型等等 语法格式access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 格式化记录日志先给一个例子log_format custom &#39;$remote_addr - [$time_local] &#39; &#39;&quot;$request&quot; $status $bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&#39;; access_log &#x2F;logs&#x2F;custom-access.log custom; 这个例子就是定义了一个format custom记录了访问的IP及访问时间，状态码、防盗链、UA、及压缩格式等等，并且在访问日志出设置。 log_format","text":"前言今天看到了我司用nginx日志来进行原始数据采集，感觉十分有趣，并且平时对这个模块了解不多。所以便了解了解。 nginx日志模块的作用就是存储访问日志，而且可以高度控制日志的格式、压缩类型等等 语法格式access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 格式化记录日志先给一个例子log_format custom &#39;$remote_addr - [$time_local] &#39; &#39;&quot;$request&quot; $status $bytes_sent &#39; &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$gzip_ratio&quot;&#39;; access_log &#x2F;logs&#x2F;custom-access.log custom; 这个例子就是定义了一个format custom记录了访问的IP及访问时间，状态码、防盗链、UA、及压缩格式等等，并且在访问日志出设置。 log_formatlog_format的一些参数，具体可以查看文末官网链接 语法 Syntax: log_format name [escape=default|json|none] string ...; Default: log_format combined &quot;...&quot;; Context: http 按照条件打日志如果access_log设置了条件，则会在满足条件的请求才会打日志,当条件结果为0或者空字符串的时候则不会记录日志。 比如我们只记录状态码5xx的日志，可以这么做 map $status $loggable &#123; ~^[5] 1; default 0; &#125; access_log &#x2F;path&#x2F;to&#x2F;access.log combined if&#x3D;$loggable; 其中combinded为默认格式化格式 参考还有几个点没有说，比如日志用到的变量可以缓存，日志压缩，文件缓冲区，日志刷新间隔时间，更多内容参考 Module ngx_http_log_module","categories":[{"name":"服务器","slug":"服务器","permalink":"https://blog.unclezs.com/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Nginx","slug":"服务器/Nginx","permalink":"https://blog.unclezs.com/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/Nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.unclezs.com/tags/nginx/"}],"author":"Unclezs"},{"title":"SQL之组内排序","slug":"数据库/mysql/SQL之组内排序","date":"2020-11-05T03:05:56.000Z","updated":"2020-11-05T03:05:56.000Z","comments":true,"path":"数据库/mysql/SQL之组内排序.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/SQL%E4%B9%8B%E7%BB%84%E5%86%85%E6%8E%92%E5%BA%8F.html","excerpt":"rank() over(order by)建立表CREATE TABLE `players` ( `pid` int(2) NOT NULL AUTO_INCREMENT, `name` varchar(50) NOT NULL, `age` int(2) NOT NULL, PRIMARY KEY (`pid`), UNIQUE KEY `name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1; INSERT INTO `players` (`pid`, `name`, `age`) VALUES (1, &#x27;Samual&#x27;, 25), (2, &#x27;Vino&#x27;, 20), (3, &#x27;John&#x27;, 20), (4, &#x27;Andy&#x27;, 22), (5, &#x27;Brian&#x27;, 21), (6, &#x27;Dew&#x27;, 24), (7, &#x27;Kris&#x27;, 25), (8, &#x27;William&#x27;, 26), (9, &#x27;George&#x27;, 23), (10, &#x27;Peter&#x27;, 19), (11, &#x27;Tom&#x27;, 20), (12, &#x27;Andre&#x27;, 20); 按age升序给运动员排名?注意：rank的over子句中排序字段值相同的给的排名一样 select pid,name,age,rank() over(order by age) as rank_num from players; 可以看到有好几个age相同的运动员，他们并列排在第2。 查询排名为第10的学生的姓名，年龄?select name,age from (select pid,name,age,rank() over(order by age) as rank_num from players) as rank_table --临时表rank_table where rank_num= 10;","text":"rank() over(order by)建立表CREATE TABLE `players` ( `pid` int(2) NOT NULL AUTO_INCREMENT, `name` varchar(50) NOT NULL, `age` int(2) NOT NULL, PRIMARY KEY (`pid`), UNIQUE KEY `name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1; INSERT INTO `players` (`pid`, `name`, `age`) VALUES (1, &#x27;Samual&#x27;, 25), (2, &#x27;Vino&#x27;, 20), (3, &#x27;John&#x27;, 20), (4, &#x27;Andy&#x27;, 22), (5, &#x27;Brian&#x27;, 21), (6, &#x27;Dew&#x27;, 24), (7, &#x27;Kris&#x27;, 25), (8, &#x27;William&#x27;, 26), (9, &#x27;George&#x27;, 23), (10, &#x27;Peter&#x27;, 19), (11, &#x27;Tom&#x27;, 20), (12, &#x27;Andre&#x27;, 20); 按age升序给运动员排名?注意：rank的over子句中排序字段值相同的给的排名一样 select pid,name,age,rank() over(order by age) as rank_num from players; 可以看到有好几个age相同的运动员，他们并列排在第2。 查询排名为第10的学生的姓名，年龄?select name,age from (select pid,name,age,rank() over(order by age) as rank_num from players) as rank_table --临时表rank_table where rank_num= 10; rank over(partition by,order by)语法 rank over(partition by 列名,order by 列名) partition by用于给结果集分组。rank在每个分组内进行排名。 改一下表alter table players add score int; update players set score=98 where pid=1; update players set score=96 where pid=2; update players set score=92 where pid=3; update players set score=96 where pid=4; update players set score=97 where pid=5; update players set score=92 where pid=6; update players set score=88 where pid=7; update players set score=89 where pid=8; update players set score=88 where pid=9; update players set score=88 where pid=10; update players set score=92 where pid=11; update players set score=91 where pid=12; select * from players; 按年龄分组，组内按分数降序排名?select name,age,score,rank() over(partition by age order by score desc) as rank_num from players;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://blog.unclezs.com/tags/SQL/"}],"author":"Unclezs"},{"title":"LDAP概念和原理介绍","slug":"后端研发/一些概念/LDAP概念和原理介绍","date":"2020-11-04T04:09:25.000Z","updated":"2020-11-04T04:09:25.000Z","comments":true,"path":"后端研发/一些概念/LDAP概念和原理介绍.html","link":"","permalink":"https://blog.unclezs.com/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/LDAP%E6%A6%82%E5%BF%B5%E5%92%8C%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D.html","excerpt":"什么是LDAP？LDAP（Light Directory Access Portocol），它是基于X.500标准的轻量级目录访问协议。 目录是一个为查询、浏览和搜索而优化的数据库，它成树状结构组织数据，类似文件目录一样。 目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 LDAP目录服务是由目录数据库和一套访问协议组成的系统。 什么是目录服务？ 目录服务是一个特殊的数据库，用来保存描述性的、基于属性的详细信息，支持过滤功能。 是动态的，灵活的，易扩展的。如：人员组织管理，电话簿，地址簿。 LDAP的基本模型每一个系统、协议都会有属于自己的模型，LDAP也不例外，在了解LDAP的基本模型之前我们需要先了解几个LDAP的目录树概念： 目录树概念","text":"什么是LDAP？LDAP（Light Directory Access Portocol），它是基于X.500标准的轻量级目录访问协议。 目录是一个为查询、浏览和搜索而优化的数据库，它成树状结构组织数据，类似文件目录一样。 目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 LDAP目录服务是由目录数据库和一套访问协议组成的系统。 什么是目录服务？ 目录服务是一个特殊的数据库，用来保存描述性的、基于属性的详细信息，支持过滤功能。 是动态的，灵活的，易扩展的。如：人员组织管理，电话簿，地址簿。 LDAP的基本模型每一个系统、协议都会有属于自己的模型，LDAP也不例外，在了解LDAP的基本模型之前我们需要先了解几个LDAP的目录树概念： 目录树概念 目录树：在一个目录服务系统中，整个目录信息集可以表示为一个目录信息树，树中的每个节点是一个条目。 条目：每个条目就是一条记录，每个条目有自己的唯一可区别的名称（DN）。 对象类：与某个实体类型对应的一组属性，对象类是可以继承的，这样父类的必须属性也会被继承下来。 属性：描述条目的某个方面的信息，一个属性由一个属性类型和一个或多个属性值组成，属性有必须属性和非必须属性。 LDAP的特点 LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了 LDAP可以很快地得到查询结果，不过在写方面，就慢得多 LDAP提供了静态数据的快速查询方式 Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具 这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前 LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议 参考LDAP概念和原理介绍LDAP服务器的概念和原理简单介绍","categories":[{"name":"后端研发","slug":"后端研发","permalink":"https://blog.unclezs.com/categories/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/"}],"tags":[{"name":"单点登陆","slug":"单点登陆","permalink":"https://blog.unclezs.com/tags/%E5%8D%95%E7%82%B9%E7%99%BB%E9%99%86/"}],"author":"Unclezs"},{"title":"MySQL不同隔离级别下的加锁情况","slug":"数据库/mysql/MySQL不同隔离级别下的加锁情况","date":"2020-10-14T02:25:10.000Z","updated":"2020-10-14T02:25:10.000Z","comments":true,"path":"数据库/mysql/MySQL不同隔离级别下的加锁情况.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E4%B8%8D%E5%90%8C%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8B%E7%9A%84%E5%8A%A0%E9%94%81%E6%83%85%E5%86%B5.html","excerpt":"简介InnoDB的四个事务隔离级别：1992标准： READ UNCOMMITTED， READ COMMITTED， REPEATABLE READ，和 SERIALIZABLE。默认隔离级别InnoDB是 REPEATABLE READ。 那么在各个隔离级别的加锁情况也略有不同。 REPEATABLE READ这是的默认隔离级别 , 同一事务中的一致读取将读取第一次读取建立的快照。这意味着，如果您SELECT 在同一事务中发出多个普通（非锁定）语句，则这些 SELECT语句彼此之间也是一致的。 对于锁定读取 （SELECT使用FOR UPDATE或FOR SHARE）， UPDATE和 DELETE语句，锁定取决于该语句使用的是具有唯一搜索条件的唯一索引还是范围类型搜索条件。 对于具有等值查询的条件的唯一索引，InnoDB仅锁定找到的索引记录，而不锁定其前的间隙，也就行是只加行级锁不加间隙锁。 对于其他查询条件（不管索引类型），使用间隙锁和next-key lock来进行锁定。 READ COMMITTED因为READ COMMITTED在执行锁定读取（SELECT 使用FOR UPDATE或FOR SHARE），UPDATE 语句和DELETE 语句的时候，InnoDB仅锁定索引记录，而不锁定它们之间的间隙。所以可以在这条锁定记录旁边插入数据，导致幻读。 加锁情况：","text":"简介InnoDB的四个事务隔离级别：1992标准： READ UNCOMMITTED， READ COMMITTED， REPEATABLE READ，和 SERIALIZABLE。默认隔离级别InnoDB是 REPEATABLE READ。 那么在各个隔离级别的加锁情况也略有不同。 REPEATABLE READ这是的默认隔离级别 , 同一事务中的一致读取将读取第一次读取建立的快照。这意味着，如果您SELECT 在同一事务中发出多个普通（非锁定）语句，则这些 SELECT语句彼此之间也是一致的。 对于锁定读取 （SELECT使用FOR UPDATE或FOR SHARE）， UPDATE和 DELETE语句，锁定取决于该语句使用的是具有唯一搜索条件的唯一索引还是范围类型搜索条件。 对于具有等值查询的条件的唯一索引，InnoDB仅锁定找到的索引记录，而不锁定其前的间隙，也就行是只加行级锁不加间隙锁。 对于其他查询条件（不管索引类型），使用间隙锁和next-key lock来进行锁定。 READ COMMITTED因为READ COMMITTED在执行锁定读取（SELECT 使用FOR UPDATE或FOR SHARE），UPDATE 语句和DELETE 语句的时候，InnoDB仅锁定索引记录，而不锁定它们之间的间隙。所以可以在这条锁定记录旁边插入数据，导致幻读。 加锁情况： 对于UPDATE或 DELETE语句， InnoDB仅对其更新或删除的行加锁。MySQL评估WHERE条件后，将释放不匹配行的行级锁 。这大大降低了死锁的可能性，但是仍然可以发生。 对于UPDATE语句，如果某行已被锁定，则InnoDB 执行 “semi-consistent” 读取，也就是说将事务A中修改后提交的最新数据反馈给MySQL，让事务B拿到事务A一句提交的最新数据进行比较where匹配情况。也就是读已经提交的数据进行比较。而RR隔离级别就是会直接阻塞等待，不会拿最新提交的数据比较。CREATE TABLE t (a INT NOT NULL, b INT) ENGINE = InnoDB; INSERT INTO t VALUES (1,2),(2,3),(3,2),(4,3),(5,2); COMMIT; # Session A START TRANSACTION; UPDATE t SET b = 5 WHERE b = 3; # Session B UPDATE t SET b = 4 WHERE b = 2; 但是对于等值查询的唯一索引，即使有第二个update来之后，也不会进行semi-consistent读取，而是阻塞住，等待第一个update结束后才进行。CREATE TABLE t (a INT NOT NULL, b INT, c INT, INDEX (b)) ENGINE = InnoDB; INSERT INTO t VALUES (1,2,3),(2,2,4); COMMIT; # Session A START TRANSACTION; UPDATE t SET b = 3 WHERE b = 2 AND c = 3; # Session B UPDATE t SET b = 4 WHERE b = 2 AND c = 4; READ UNCOMMITTEDSELECT语句以非锁定方式执行，但可能使用行的早期版本。因此，使用这个隔离级别，这样的读取是不一致的。这也叫脏读。否则，此隔离级别的工作方式与READ COMMITTED类似。 SERIALIZABLE这个级别类似于RR，但是InnoDB隐式地将所有纯SELECT语句转换为SELECT … FOR SHARE 如果禁用自动提交，则为共享。如果启用了自动提交，则选择是它自己的事务。因此，已知它是只读的，如果作为一致（非锁定）读取执行，则可以序列化它，并且不需要阻塞其他事务。（若要强制普通选择阻止其他事务已修改选定行，请禁用自动提交。） 参考文档Transaction Isolation Levels Locks Set by Different SQL Statements in InnoDB","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"隔离级别","slug":"隔离级别","permalink":"https://blog.unclezs.com/tags/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"name":"锁","slug":"锁","permalink":"https://blog.unclezs.com/tags/%E9%94%81/"}],"author":"Unclezs"},{"title":"JUC工具类之CyclicBarrier","slug":"Java/并发编程/JUC工具类之CyclicBarrier","date":"2020-09-21T03:22:28.000Z","updated":"2020-09-21T03:22:28.000Z","comments":true,"path":"Java/并发编程/JUC工具类之CyclicBarrier.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JUC%E5%B7%A5%E5%85%B7%E7%B1%BB%E4%B9%8BCyclicBarrier.html","excerpt":"简介 对于CountDownLatch，其他线程为游戏玩家，比如英雄联盟，主线程为控制游戏开始的线程。在所有的玩家都准备好之前，主线程是处于等待状态的，也就是游戏不能开始。当所有的玩家准备好之后，下一步的动作实施者为主线程，即开始游戏。 对于CyclicBarrier，假设有一家公司要全体员工进行团建活动，活动内容为翻越三个障碍物，每一个人翻越障碍物所用的时间是不一样的。但是公司要求所有人在翻越当前障碍物之后再开始翻越下一个障碍物，也就是所有人翻越第一个障碍物之后，才开始翻越第二个，以此类推。类比地，每一个员工都是一个“其他线程”。当所有人都翻越的所有的障碍物之后，程序才结束。而主线程可能早就结束了，这里我们不用管主线程。 例子 import java.util.concurrent.CyclicBarrier; public class CyclicBarrierTest &#123; static class MyThread extends Thread &#123; private CyclicBarrier cb; public MyThread(String name, CyclicBarrier cb) &#123; super(name); this.cb = cb; &#125; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;第一步&quot;); cb.await(); System.out.println(Thread.currentThread().getName() + &quot;第二步&quot;); cb.await(); System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; CyclicBarrier cb = new CyclicBarrier(2, () -&gt; &#123; System.out.println(&quot;进入下一阶段&quot;); &#125;); for (int i = 0; i &lt; 2; i++) &#123; new MyThread(&quot;thread-&quot; + i, cb).start(); &#125; &#125; &#125; 其中一次输出： thread-0第一步 thread-1第一步 进入下一阶段 thread-1第二步 thread-0第二步 进入下一阶段 thread-0结束 thread-1结束 和CountDonwLatch对比 CountDownLatch减计数，CyclicBarrier加计数。 CountDownLatch是一次性的，CyclicBarrier可以重用。 CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是Coun tDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。","text":"简介 对于CountDownLatch，其他线程为游戏玩家，比如英雄联盟，主线程为控制游戏开始的线程。在所有的玩家都准备好之前，主线程是处于等待状态的，也就是游戏不能开始。当所有的玩家准备好之后，下一步的动作实施者为主线程，即开始游戏。 对于CyclicBarrier，假设有一家公司要全体员工进行团建活动，活动内容为翻越三个障碍物，每一个人翻越障碍物所用的时间是不一样的。但是公司要求所有人在翻越当前障碍物之后再开始翻越下一个障碍物，也就是所有人翻越第一个障碍物之后，才开始翻越第二个，以此类推。类比地，每一个员工都是一个“其他线程”。当所有人都翻越的所有的障碍物之后，程序才结束。而主线程可能早就结束了，这里我们不用管主线程。 例子 import java.util.concurrent.CyclicBarrier; public class CyclicBarrierTest &#123; static class MyThread extends Thread &#123; private CyclicBarrier cb; public MyThread(String name, CyclicBarrier cb) &#123; super(name); this.cb = cb; &#125; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;第一步&quot;); cb.await(); System.out.println(Thread.currentThread().getName() + &quot;第二步&quot;); cb.await(); System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; CyclicBarrier cb = new CyclicBarrier(2, () -&gt; &#123; System.out.println(&quot;进入下一阶段&quot;); &#125;); for (int i = 0; i &lt; 2; i++) &#123; new MyThread(&quot;thread-&quot; + i, cb).start(); &#125; &#125; &#125; 其中一次输出： thread-0第一步 thread-1第一步 进入下一阶段 thread-1第二步 thread-0第二步 进入下一阶段 thread-0结束 thread-1结束 和CountDonwLatch对比 CountDownLatch减计数，CyclicBarrier加计数。 CountDownLatch是一次性的，CyclicBarrier可以重用。 CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是Coun tDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://blog.unclezs.com/tags/JUC/"}],"author":"Unclezs"},{"title":"JUC工具类之CountDownLatch","slug":"Java/并发编程/JUC工具类之CountDownLatch","date":"2020-09-21T03:10:10.000Z","updated":"2020-09-21T03:10:10.000Z","comments":true,"path":"Java/并发编程/JUC工具类之CountDownLatch.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JUC%E5%B7%A5%E5%85%B7%E7%B1%BB%E4%B9%8BCountDownLatch.html","excerpt":"简介CountDownLatch底层也是由AQS，用来同步一个或多个任务的常用并发工具类，强制它们等待由其他任务执行的一组操作完成。 从源码可知，其底层是由AQS提供支持，所以其数据结构可以参考AQS的数据结构，而AQS的数据结构核心就是两个虚拟队列: 同步队列sync queue 和条件队列condition queue，不同的条件会有不同的条件队列。CountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。 用法示例import java.util.concurrent.CountDownLatch; class MyThread extends Thread &#123; private CountDownLatch countDownLatch; public MyThread(String name, CountDownLatch countDownLatch) &#123; super(name); this.countDownLatch = countDownLatch; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; doing something&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; finish&quot;); countDownLatch.countDown(); &#125; &#125; public class CountDownLatchDemo &#123; public static void main(String[] args) &#123; CountDownLatch countDownLatch = new CountDownLatch(2); MyThread t1 = new MyThread(&quot;t1&quot;, countDownLatch); MyThread t2 = new MyThread(&quot;t2&quot;, countDownLatch); t1.start(); t2.start(); System.out.println(&quot;Waiting for t1 thread and t2 thread to finish&quot;); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; continue&quot;); &#125; &#125;","text":"简介CountDownLatch底层也是由AQS，用来同步一个或多个任务的常用并发工具类，强制它们等待由其他任务执行的一组操作完成。 从源码可知，其底层是由AQS提供支持，所以其数据结构可以参考AQS的数据结构，而AQS的数据结构核心就是两个虚拟队列: 同步队列sync queue 和条件队列condition queue，不同的条件会有不同的条件队列。CountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。 用法示例import java.util.concurrent.CountDownLatch; class MyThread extends Thread &#123; private CountDownLatch countDownLatch; public MyThread(String name, CountDownLatch countDownLatch) &#123; super(name); this.countDownLatch = countDownLatch; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; doing something&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; finish&quot;); countDownLatch.countDown(); &#125; &#125; public class CountDownLatchDemo &#123; public static void main(String[] args) &#123; CountDownLatch countDownLatch = new CountDownLatch(2); MyThread t1 = new MyThread(&quot;t1&quot;, countDownLatch); MyThread t2 = new MyThread(&quot;t2&quot;, countDownLatch); t1.start(); t2.start(); System.out.println(&quot;Waiting for t1 thread and t2 thread to finish&quot;); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; continue&quot;); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://blog.unclezs.com/tags/JUC/"}],"author":"Unclezs"},{"title":"IO多路复用","slug":"操作系统/IO多路复用","date":"2020-09-20T12:18:08.000Z","updated":"2020-09-20T12:18:08.000Z","comments":true,"path":"操作系统/IO多路复用.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.html","excerpt":"举例现实场景来理解我们试想一下这样的现实场景: 一个餐厅同时有100位客人到店，当然到店后第一件要做的事情就是点菜。但是问题来了，餐厅老板为了节约人力成本目前只有一位大堂服务员拿着唯一的一本菜单等待客人进行服务。 方法A.无论有多少客人等待点餐，服务员都把仅有的一份菜单递给其中一位客人，然后站在客人身旁等待这个客人完成点菜过程。在记录客人点菜内容后，把点菜记录交给后堂厨师。然后是第二位客人。。。。然后是第三位客人。很明显，只有脑袋被门夹过的老板，才会这样设置服务流程。因为随后的80位客人，再等待超时后就会离店(还会给差评)。 方法B.老板马上新雇佣99名服务员，同时印制99本新的菜单。每一名服务员手持一本菜单负责一位客人(关键不只在于服务员，还在于菜单。因为没有菜单客人也无法点菜)。在客人点完菜后，记录点菜内容交给后堂厨师(当然为了更高效，后堂厨师最好也有100名)。这样每一位客人享受的就是VIP服务咯，当然客人不会走，但是人力成本可是一个大头哦(亏死你)。 方法C.当客人到店后，自己申请一本菜单。想好自己要点的才后，就呼叫服务员。服务员站在自己身边后记录客人的菜单内容。将菜单递给厨师的过程也要进行改进，并不是每一份菜单记录好以后，都要交给后堂厨师。服务员可以记录号多份菜单后，同时交给厨师就行了。那么这种方式，对于老板来说人力成本是最低的；对于客人来说，虽然不再享受VIP服务并且要进行一定的等待，但是这些都是可接受的；对于服务员来说，基本上她的时间都没有浪费，基本上被老板压杆了最后一滴油水。 到店情况: 并发量。到店情况不理想时，一个服务员一本菜单，当然是足够了。所以不同的老板在不同的场合下，将会灵活选择服务员和菜单的配置。 客人: 客户端请求 点餐内容: 客户端发送的实际数据 老板: 操作系统 人力成本: 系统资源 菜单: 文件状态描述符。操作系统对于一个进程能够同时持有的文件状态描述符的个数是有限制的，在linux系统中$ulimit -n查看这个限制值，当然也是可以(并且应该)进行内核参数调整的。 服务员: 操作系统内核用于IO操作的线程(内核线程) 厨师: 应用程序线程(当然厨房就是应用程序进程咯) 餐单传递方式: 包括了阻塞式和非阻塞式两种。 方法A: 阻塞式/非阻塞式 同步IO 方法B: 使用线程进行处理的 阻塞式/非阻塞式 同步IO 方法C: 阻塞式/非阻塞式 多路复用IO 多路复用IO实现目前流程的多路复用IO实现主要包括四种: select、poll、epoll、kqueue。下表是他们的一些重要特性的比较: IO模型 相对性能 关键思路 操作系统 JAVA支持情况 select 较高 Reactor windows/Linux 支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型 poll 较高 Reactor Linux Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式 epoll 高 Reactor/Proactor Linux Linux kernels 2.6内核版本及以后使用epoll进行支持；Linux kernels 2.6内核版本之前使用poll进行支持；另外一定注意，由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO kqueue 高 Proactor Linux 目前JAVA的版本不支持 多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势。另一方面，使用JAVA NIO进行功能实现，相对于传统的Socket套接字实现要复杂一些，所以实际应用中，需要根据自己的业务需求进行技术选择。","text":"举例现实场景来理解我们试想一下这样的现实场景: 一个餐厅同时有100位客人到店，当然到店后第一件要做的事情就是点菜。但是问题来了，餐厅老板为了节约人力成本目前只有一位大堂服务员拿着唯一的一本菜单等待客人进行服务。 方法A.无论有多少客人等待点餐，服务员都把仅有的一份菜单递给其中一位客人，然后站在客人身旁等待这个客人完成点菜过程。在记录客人点菜内容后，把点菜记录交给后堂厨师。然后是第二位客人。。。。然后是第三位客人。很明显，只有脑袋被门夹过的老板，才会这样设置服务流程。因为随后的80位客人，再等待超时后就会离店(还会给差评)。 方法B.老板马上新雇佣99名服务员，同时印制99本新的菜单。每一名服务员手持一本菜单负责一位客人(关键不只在于服务员，还在于菜单。因为没有菜单客人也无法点菜)。在客人点完菜后，记录点菜内容交给后堂厨师(当然为了更高效，后堂厨师最好也有100名)。这样每一位客人享受的就是VIP服务咯，当然客人不会走，但是人力成本可是一个大头哦(亏死你)。 方法C.当客人到店后，自己申请一本菜单。想好自己要点的才后，就呼叫服务员。服务员站在自己身边后记录客人的菜单内容。将菜单递给厨师的过程也要进行改进，并不是每一份菜单记录好以后，都要交给后堂厨师。服务员可以记录号多份菜单后，同时交给厨师就行了。那么这种方式，对于老板来说人力成本是最低的；对于客人来说，虽然不再享受VIP服务并且要进行一定的等待，但是这些都是可接受的；对于服务员来说，基本上她的时间都没有浪费，基本上被老板压杆了最后一滴油水。 到店情况: 并发量。到店情况不理想时，一个服务员一本菜单，当然是足够了。所以不同的老板在不同的场合下，将会灵活选择服务员和菜单的配置。 客人: 客户端请求 点餐内容: 客户端发送的实际数据 老板: 操作系统 人力成本: 系统资源 菜单: 文件状态描述符。操作系统对于一个进程能够同时持有的文件状态描述符的个数是有限制的，在linux系统中$ulimit -n查看这个限制值，当然也是可以(并且应该)进行内核参数调整的。 服务员: 操作系统内核用于IO操作的线程(内核线程) 厨师: 应用程序线程(当然厨房就是应用程序进程咯) 餐单传递方式: 包括了阻塞式和非阻塞式两种。 方法A: 阻塞式/非阻塞式 同步IO 方法B: 使用线程进行处理的 阻塞式/非阻塞式 同步IO 方法C: 阻塞式/非阻塞式 多路复用IO 多路复用IO实现目前流程的多路复用IO实现主要包括四种: select、poll、epoll、kqueue。下表是他们的一些重要特性的比较: IO模型 相对性能 关键思路 操作系统 JAVA支持情况 select 较高 Reactor windows/Linux 支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型 poll 较高 Reactor Linux Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式 epoll 高 Reactor/Proactor Linux Linux kernels 2.6内核版本及以后使用epoll进行支持；Linux kernels 2.6内核版本之前使用poll进行支持；另外一定注意，由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO kqueue 高 Proactor Linux 目前JAVA的版本不支持 多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势。另一方面，使用JAVA NIO进行功能实现，相对于传统的Socket套接字实现要复杂一些，所以实际应用中，需要根据自己的业务需求进行技术选择。 IO多路复用工作模式epoll 的描述符事件有两种触发模式: LT(level trigger)和 ET(edge trigger)。 LT 模式当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 ET 模式和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 select 应用场景select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 poll 应用场景poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。 epoll 应用场景只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://blog.unclezs.com/tags/NIO/"}],"author":"Unclezs"},{"title":"Java并发之Unsafe类","slug":"Java/并发编程/Java并发之Unsafe类","date":"2020-09-19T12:11:54.000Z","updated":"2020-09-19T12:11:54.000Z","comments":true,"path":"Java/并发编程/Java并发之Unsafe类.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Java%E5%B9%B6%E5%8F%91%E4%B9%8BUnsafe%E7%B1%BB.html","excerpt":"Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 这个类尽管里面的方法都是 public 的，但是并没有办法使用它们，JDK API 文档也没有提供任何关于这个类的方法的解释。总而言之，对于 Unsafe 类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然 JDK 库里面的类是可以随意使用的。","text":"Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 这个类尽管里面的方法都是 public 的，但是并没有办法使用它们，JDK API 文档也没有提供任何关于这个类的方法的解释。总而言之，对于 Unsafe 类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然 JDK 库里面的类是可以随意使用的。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://blog.unclezs.com/tags/%E5%B9%B6%E5%8F%91/"}],"author":"Unclezs"},{"title":"JUC核心之AQS原理","slug":"Java/并发编程/JUC核心之AQS原理","date":"2020-09-18T05:32:04.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/并发编程/JUC核心之AQS原理.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JUC%E6%A0%B8%E5%BF%83%E4%B9%8BAQS%E5%8E%9F%E7%90%86.html","excerpt":"简介AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 private volatile int state;//共享变量，使用volatile修饰保证线程可见性 //返回同步状态的当前值 protected final int getState() &#123; return state; &#125; // 设置同步状态的值 protected final void setState(int newState) &#123; state = newState; &#125; //原子地(CAS操作)将同步状态值设置为给定值update如果当前同步状态的值等于expect(期望值) protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; AQS 对资源的共享方式AQS定义两种资源共享方式Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share(共享)：多个线程可同时执行 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。","text":"简介AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 private volatile int state;//共享变量，使用volatile修饰保证线程可见性 //返回同步状态的当前值 protected final int getState() &#123; return state; &#125; // 设置同步状态的值 protected final void setState(int newState) &#123; state = newState; &#125; //原子地(CAS操作)将同步状态值设置为给定值update如果当前同步状态的值等于expect(期望值) protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; AQS 对资源的共享方式AQS定义两种资源共享方式Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share(共享)：多个线程可同时执行 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。 自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。 AQS底层使用了模板方法模式isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0(即释放锁)为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的(state会累加)，这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 底层数据结构AbstractQueuedSynchronizer类底层的数据结构是使用CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。 AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。其中Sync queue，即同步队列，是双向链表，包括head结点和tail结点，head结点主要用作后续的调度。 而Condition queue不是必须的，其是一个单向链表，只有当使用Condition时，才会存在此单向链表。并且可能会有多个Condition queue。 AbstractQueuedSynchronizer源码分析类的继承关系AbstractQueuedSynchronizer继承自AbstractOwnableSynchronizer抽象类，并且实现了Serializable接口，可以进行序列化。 public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable 其中AbstractOwnableSynchronizer抽象类主要用于存储独占模式下当前的线程是哪一个，源码如下: public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = 3737899427754241961L; // 构造方法 protected AbstractOwnableSynchronizer() &#123; &#125; // 独占模式下的线程 private transient Thread exclusiveOwnerThread; // 设置独占线程 protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; // 获取独占线程 protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125; &#125; AbstractQueuedSynchronizer有两个内部类，Node和ConditionObject Node static final class Node &#123; // 模式，分为共享与独占 // 共享模式 static final Node SHARED = new Node(); // 独占模式 static final Node EXCLUSIVE = null; // 结点状态 // CANCELLED，值为1，表示当前的线程被取消 // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中 // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行 // 值为0，表示当前节点在sync队列中，等待着获取锁 static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 结点状态 volatile int waitStatus; // 前驱结点 volatile Node prev; // 后继结点 volatile Node next; // 结点所对应的线程 volatile Thread thread; // 下一个等待者 Node nextWaiter; // 结点是否在共享模式下等待 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取前驱结点，若前驱结点为空，抛出异常 final Node predecessor() throws NullPointerException &#123; // 保存前驱结点 Node p = prev; if (p == null) // 前驱结点为空，抛出异常 throw new NullPointerException(); else // 前驱结点不为空，返回 return p; &#125; // 无参构造方法 Node() &#123; // Used to establish initial head or SHARED marker &#125; // 构造方法 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 构造方法 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; ConditionObjectpublic class ConditionObject implements Condition, java.io.Serializable &#123; // 版本号 private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ // condition队列的头结点 private transient Node firstWaiter; /** Last node of condition queue. */ // condition队列的尾结点 private transient Node lastWaiter; // 构造方法 public ConditionObject() &#123; &#125; // 添加新的waiter到wait队列 private Node addConditionWaiter() &#123; // 保存尾结点 Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 尾结点不为空，并且尾结点的状态不为CONDITION // 清除状态为CONDITION的结点 unlinkCancelledWaiters(); // 将最后一个结点重新赋值给t t = lastWaiter; &#125; // 新建一个结点 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) // 尾结点为空 // 设置condition队列的头结点 firstWaiter = node; else // 尾结点不为空 // 设置为节点的nextWaiter域为node结点 t.nextWaiter = node; // 更新condition队列的尾结点 lastWaiter = node; return node; &#125; private void doSignal(Node first) &#123; // 循环 do &#123; if ( (firstWaiter = first.nextWaiter) == null) // 该节点的nextWaiter为空 // 设置尾结点为空 lastWaiter = null; // 设置first结点的nextWaiter域 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); // 将结点从condition队列转移到sync队列失败并且condition队列中的头结点不为空，一直循环 &#125; private void doSignalAll(Node first) &#123; // condition队列的头结点尾结点都设置为空 lastWaiter = firstWaiter = null; // 循环 do &#123; // 获取first结点的nextWaiter域结点 Node next = first.nextWaiter; // 设置first结点的nextWaiter域为空 first.nextWaiter = null; // 将first结点从condition队列转移到sync队列 transferForSignal(first); // 重新设置first first = next; &#125; while (first != null); &#125; // 从condition队列中清除状态为CANCEL的结点 private void unlinkCancelledWaiters() &#123; // 保存condition队列头结点 Node t = firstWaiter; Node trail = null; while (t != null) &#123; // t不为空 // 下一个结点 Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; // t结点的状态不为CONDTION状态 // 设置t节点的额nextWaiter域为空 t.nextWaiter = null; if (trail == null) // trail为空 // 重新设置condition队列的头结点 firstWaiter = next; else // trail不为空 // 设置trail结点的nextWaiter域为next结点 trail.nextWaiter = next; if (next == null) // next结点为空 // 设置condition队列的尾结点 lastWaiter = trail; &#125; else // t结点的状态为CONDTION状态 // 设置trail结点 trail = t; // 设置t结点 t = next; &#125; &#125; // 唤醒一个等待线程。如果所有的线程都在等待此条件，则选择其中的一个唤醒。在从 await 返回之前，该线程必须重新获取锁。 public final void signal() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头结点 Node first = firstWaiter; if (first != null) // 头结点不为空 // 唤醒一个等待线程 doSignal(first); &#125; // 唤醒所有等待线程。如果所有的线程都在等待此条件，则唤醒所有线程。在从 await 返回之前，每个线程都必须重新获取锁。 public final void signalAll() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头结点 Node first = firstWaiter; if (first != null) // 头结点不为空 // 唤醒所有等待线程 doSignalAll(first); &#125; // 等待，当前线程在接到信号之前一直处于等待状态，不响应中断 public final void awaitUninterruptibly() &#123; // 添加一个结点到等待队列 Node node = addConditionWaiter(); // 获取释放的状态 int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; // // 阻塞当前线程 LockSupport.park(this); if (Thread.interrupted()) // 当前线程被中断 // 设置interrupted状态 interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) // selfInterrupt(); &#125; /** Mode meaning to reinterrupt on exit from wait */ private static final int REINTERRUPT = 1; /** Mode meaning to throw InterruptedException on exit from wait */ private static final int THROW_IE = -1; private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); &#125; // 等待，当前线程在接到信号或被中断之前一直处于等待状态 public final void await() throws InterruptedException &#123; if (Thread.interrupted()) // 当前线程被中断，抛出异常 throw new InterruptedException(); // 在wait队列上添加一个结点 Node node = addConditionWaiter(); // int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 阻塞当前线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) // 检查结点等待时的中断类型 break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; // 等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态 public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime(); &#125; // 等待，当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态 public final boolean awaitUntil(Date deadline) throws InterruptedException &#123; long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (System.currentTimeMillis() &gt; abstime) &#123; timedout = transferAfterCancelledWait(node); break; &#125; LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; // 等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。此方法在行为上等效于: awaitNanos(unit.toNanos(time)) &gt; 0 public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; timedout = transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; final boolean isOwnedBy(AbstractQueuedSynchronizer sync) &#123; return sync == AbstractQueuedSynchronizer.this; &#125; // 查询是否有正在等待此条件的任何线程 protected final boolean hasWaiters() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) return true; &#125; return false; &#125; // 返回正在等待此条件的线程数估计值 protected final int getWaitQueueLength() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) ++n; &#125; return n; &#125; // 返回包含那些可能正在等待此条件的线程集合 protected final Collection&lt;Thread&gt; getWaitingThreads() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) &#123; Thread t = w.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125; &#125; 总结AQS底层是通过一个状态量State记录当前同步器的状态，这个状态量的更改是通过CAS方式更新，同时维护了一个等待队列，如果新的任务进来的时候发现AQS是独占模式并且状态为0，则表示可以直接执行，如果状态为1则加入等待队列（双向链表），当调用unlock的时候唤醒等待队列中没有被取消的线程。 如果为非公平模式，当AQS已经被使用完成，从等待队列中唤醒一个任务的时候同时有一个任务也正加入进来，则两个任务直接竞争。如果是公平模式则直接将新加的任务放入队尾。 而AQS中还有Condition，也就是一个锁可以有多个条件来保证并发 推荐阅读：JUC：AQS详解","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://blog.unclezs.com/tags/AQS/"}]},{"title":"HTTP与HTTPS详解","slug":"计算机网络/HTTP与HTTPS详解","date":"2020-09-17T02:05:53.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/HTTP与HTTPS详解.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP%E4%B8%8EHTTPS%E8%AF%A6%E8%A7%A3.html","excerpt":"前言超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。 为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全 HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 HTTPS和HTTP的主要区别 https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 HTTPS的传输过程 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。 Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。 客户端拿到证书，证书校验通过后，用系统内置的CA证书，进行对证书解密，拿到公钥。 客户端的浏览器与Web服务器开始协商SSL/TLS连接的安全等级，也就是信息加密的等级。 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 Web服务器利用自己的私钥解密出会话密钥。 Web服务器利用会话密钥对数据进行对称加密，再与客户端进程通讯。","text":"前言超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。 为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全 HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 HTTPS和HTTP的主要区别 https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 HTTPS的传输过程 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。 Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。 客户端拿到证书，证书校验通过后，用系统内置的CA证书，进行对证书解密，拿到公钥。 客户端的浏览器与Web服务器开始协商SSL/TLS连接的安全等级，也就是信息加密的等级。 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 Web服务器利用自己的私钥解密出会话密钥。 Web服务器利用会话密钥对数据进行对称加密，再与客户端进程通讯。 CA证书作用CA证书就是服务端自己有一份公钥私钥，把公钥给CA证书，获得一份数字证书，当客户端来请求时，就拿这个数字证书给客户端，客户端再通过CA认证算法拿到公钥，再进行后续操作。 SSL与TLS的区别？SSL：（Secure Socket Layer，安全套接字层），位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以实现客户端和服务器之间的安全通讯。该协议由两层组成：SSL记录协议和SSL握手协议。 TLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。 SSL/TLS协议的基本过程客户端发出请求（ClientHello） 支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数，稍后用于生成”对话密钥”。 支持的加密方法，比如RSA公钥加密。 支持的压缩方法。 服务器回应（SeverHello） 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数，稍后用于生成”对话密钥”。 确认使用的加密方法，比如RSA公钥加密，此时带有公钥信息。 服务器证书。 客户端回应 一个随机数pre-master key。该随机数用服务器公钥加密，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。 上面客户端回应中第一项的随机数，是整个握手阶段出现的第三个随机数，又称”pre-master key”。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把”会话密钥”。 一些问题那么为什么一定要用三个随机数，来生成”会话密钥”呢？为了保证绝对随机，不相信服务器或者客户端的随机数，而是才用三个随机数再进行一定算法计算出真正的 会话密钥(对称加密) 为什么不都使用对称加密而是才有非对称与对称加密组合？因为非对称加密比较耗费性能，比对称加密慢了几倍甚至几百倍，所以才有了对称加密进行最终的数据加密。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://blog.unclezs.com/tags/HTTP/"}]},{"title":"一致性哈希算法","slug":"算法/一致性哈希算法","date":"2020-09-15T01:45:29.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"算法/一致性哈希算法.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95.html","excerpt":"简介常见的负载均衡方法有很多，但是它们的优缺点也都很明显： 随机访问策略。系统随机访问，缺点：可能造成服务器负载压力不均衡，俗话讲就是撑的撑死，饿的饿死。 轮询策略。请求均匀分配，如果服务器有性能差异，则无法实现性能好的服务器能够多承担一部分。 权重轮询策略。权值需要静态配置，无法自动调节，不适合对长连接和命中率有要求的场景。 Hash取模策略。不稳定，如果列表中某台服务器宕机，则会导致路由算法产生变化，由此导致命中率的急剧下降。 一致性哈希策略。 以上几个策略，排除本篇介绍的一致性哈希，可能使用最多的就是 Hash取模策略了。Hash取模策略的缺点也是很明显的，这种缺点也许在负载均衡的时候不是很明显，但是在涉及数据访问的主从备份和分库分表中就体现明显了。 一致性Hash性质 考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面： 平衡性(Balance)平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。","text":"简介常见的负载均衡方法有很多，但是它们的优缺点也都很明显： 随机访问策略。系统随机访问，缺点：可能造成服务器负载压力不均衡，俗话讲就是撑的撑死，饿的饿死。 轮询策略。请求均匀分配，如果服务器有性能差异，则无法实现性能好的服务器能够多承担一部分。 权重轮询策略。权值需要静态配置，无法自动调节，不适合对长连接和命中率有要求的场景。 Hash取模策略。不稳定，如果列表中某台服务器宕机，则会导致路由算法产生变化，由此导致命中率的急剧下降。 一致性哈希策略。 以上几个策略，排除本篇介绍的一致性哈希，可能使用最多的就是 Hash取模策略了。Hash取模策略的缺点也是很明显的，这种缺点也许在负载均衡的时候不是很明显，但是在涉及数据访问的主从备份和分库分表中就体现明显了。 一致性Hash性质 考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面： 平衡性(Balance)平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。 分散性(Spread)在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load)负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 平滑性(Smoothness)平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。 算法思想 首先求出memcached服务器（节点）的哈希值，并将其配置到0～23^2的圆上。 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过23^2仍然找不到服务器，就会保存到第一台服务器上。 当我们添加一台机器的时候，只会将一部分节点分配到新加入的节点，如图所示，Node2-Node5之间的数据应该是存储在Node3上，加上新节点Node5之后，只需要将Node2-Node5之间的数据从Node3重分布到Node5就行了，不会全部重分布。 不过这个有一个问题，就是数据分布的不均匀了。 虚拟节点 为了解决节点过少数据分部不均匀的问题，引入了虚拟节点，增加hash分布的均匀性。hash环上不再存在物理节点，而是存虚拟节点，虚拟节点对应对应的物理机器。 总结一致性哈希解决了数据迁移的时候全量重新分布的问题，只用重新分布一部分。还有就是哈希冲突问题还是会有的，但是冲突的概率很低，而且就算冲突了也影响不大。","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"哈希","slug":"哈希","permalink":"https://blog.unclezs.com/tags/%E5%93%88%E5%B8%8C/"}]},{"title":"Java语法级常见面试题","slug":"Java/基础/Java语法级常见面试题","date":"2020-09-08T07:15:04.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/Java语法级常见面试题.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E8%AF%AD%E6%B3%95%E7%BA%A7%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98.html","excerpt":"重载和重写区别重写（Override）发生在运行时期。 存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。 为了满足里式替换原则，重写有以下三个限制： 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。 重载（Overload）发生在编译时期 存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。","text":"重载和重写区别重写（Override）发生在运行时期。 存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。 为了满足里式替换原则，重写有以下三个限制： 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。 重载（Overload）发生在编译时期 存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。 应该注意的是，返回值不同，其它都相同不算是重载。 抽象类和接口区别 一个子类只能继承一个抽象类,但能实现多个接口 抽象类可以有构造方法,接口没有构造方法 抽象类可以有普通成员变量,接口没有普通成员变量 抽象类和接口都可有静态成员变量,抽象类中静态成员变量访问类型任意，接口只能public static final(默认) 抽象类可以没有抽象方法,抽象类可以有普通方法,接口中都是抽象方法 抽象类可以有静态方法，接口不能有静态方法 （1.8中可以有静态方法，但是必须实现） 抽象类中的方法可以是public、protected;接口方法只有public abstract 重载的一些问题public class AppTest &#123; public static void main(String[] args) &#123; b(1,null); //A行 a(null); //B行 &#125; public static void a(Object a) &#123; &#125; public static void a(String a) &#123; &#125; public static void b(Integer ab,String a) &#123; &#125; public static void b(Integer ab,String... a) &#123; &#125; &#125; 其中A行报错，因为找到了两个方法。B行调用的是a(String a)方法，也就代表优先选择子类。 try_catch_finallypublic class FinallyTest &#123; public static void main(String[] args) &#123; System.out.println(test()); &#125; private static int test() &#123; try &#123; int a = 1 / 0; return 1; &#125; catch (Exception e) &#123; System.out.println(&quot;catch&quot;); return 2; &#125; finally &#123; System.out.println(&quot;finally&quot;); return 3; &#125; &#125; &#125; 运行打印 catch finally 3 finally不管有没有异常都要处理当try和catch中有return时，finally仍然会执行，finally比return先执行不管有木有异常抛出, finally在return返回前执行finally是在return后面的表达式运算后执行的(此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值)，所以函数返回值是在finally执行前确定的 注意: finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值 finally不执行的几种情况: 程序提前终止如调用了System.exit, 病毒，断电","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"ISP中的网络层","slug":"计算机网络/ISP中的网络层","date":"2020-09-05T11:16:52.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/ISP中的网络层.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ISP%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82.html","excerpt":"概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP地址编址方式IP 地址的编址方式经历了三个历史阶段：","text":"概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 IP地址编址方式IP 地址的编址方式经历了三个历史阶段： 分类 子网划分 无分类 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。 注意，外部网络看不到子网的存在。 无分类编址CIDR192.168.10.32/28前面的数字是我们的网络地址，后面的28表示用28位来表示网络位，用32-28=4位来表示主机位。通过这种记法，我们能明确两个信息：网络地址：192.168.10.32子网掩码：255.255.255.240 所以，/8-/15只能用于A类网络，/16-/23可用于A类和B类网络，而/24-/30可用于A类、B类和C类网络。这就是大多数公司都使用A类网络地址的一大原因，因为它们可使用所有的子网掩码，进行网络设计时的灵活性最大。 子网划分常见问题 选定的子网掩码将创建多少个子网? 2^x个，其中x是子网掩码借用的主机位数，比如/28，主机位数为4. 比如/28，即为255.255.255.240 ，256 -192 = 64，所以子网的步长增量为64，因此子网为0、64、128和192； 每个子网可包含多少台主机? (2^y)-2台，其中y是没被借用的主机位的位数。-2是因为，主机位全为0的部分是这个子网的网段号（Net_id），全为1的部分是这个网段的广播地址。 每个子网的广播地址是什么? 主机位全为1就是该子网的广播地址。 每个子网可包含哪些主机地址? 合法的主机地址位于两个子网之间，但全为0和全为1的地址除外。例如，如果子网号（网段号）为64，而广播地址为127，则合法的主机地址范围为65-126，即子网地址和广播地址之间的数字。 地址解析协议ARP网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 网际控制报文协议ICMPICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。 ICMP 报文分为差错报告报文和询问报文。 ICMP的应用 PingPing 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 Traceroute Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"ISP","slug":"ISP","permalink":"https://blog.unclezs.com/tags/ISP/"}]},{"title":"浅谈DNS协议","slug":"计算机网络/浅谈DNS协议","date":"2020-09-05T10:39:45.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/浅谈DNS协议.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E6%B5%85%E8%B0%88DNS%E5%8D%8F%E8%AE%AE.html","excerpt":"简介DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住IP。通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 DNS查找过程 浏览器访问 www.baidu.com 查找浏览器缓存 查找dns解析器缓存host 查找本地dns服务器缓存 查找根dns服务器缓存，找到了返回对应后缀的dns服务器地址ip（比如com DNS服务器） 查找com dns服务器，返回baidu.com的dns服务器ip 查找baidu.com dns服务器ip 得到baidu.com服务器ip，写入缓存。 浏览器拿到ip进行访问。 DNS的记录类型 其中CNAME解析就是将域名解析到另一个域名。 DNS劫持与污染","text":"简介DNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住IP。通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 DNS查找过程 浏览器访问 www.baidu.com 查找浏览器缓存 查找dns解析器缓存host 查找本地dns服务器缓存 查找根dns服务器缓存，找到了返回对应后缀的dns服务器地址ip（比如com DNS服务器） 查找com dns服务器，返回baidu.com的dns服务器ip 查找baidu.com dns服务器ip 得到baidu.com服务器ip，写入缓存。 浏览器拿到ip进行访问。 DNS的记录类型 其中CNAME解析就是将域名解析到另一个域名。 DNS劫持与污染DNS劫持DNS决定的是我们的域名将解析到哪一个IP地址的记录，是基于UDP协议的一种应用层协议。这种攻击的前提是攻击者掌控了你的本地DNS服务器 攻击者劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致用户对该域名地址进行访问的时候，由原来的IP地址转入到修改后的IP地址。结果就是让正确的网址不能解析或者是被解析到另一个网址的IP，实现获取用户资料或者破坏原有网址正常服务的目的。 简单来说就是就是ip解析请求发送到了其他DNS服务器了，给你返回了一个错误的ip DNS污染又称域名服务器缓存投毒（DNS cache poisoning），它和DNS劫持的不同之处，在于污染针对的是DNS缓存，是在查询信息到达目标DNS服务器前，经过的节点上做手脚，而劫持是DNS服务器中记录的是错误的内容。 参考一篇你看了就懂的DNS详解","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://blog.unclezs.com/tags/DNS/"}]},{"title":"五大I/O模型","slug":"操作系统/五大I-O模型","date":"2020-08-29T09:34:22.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"操作系统/五大I-O模型.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%94%E5%A4%A7I-O%E6%A8%A1%E5%9E%8B.html","excerpt":"简介一个输入操作通常包括两个阶段： 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 Unix 有五种 I/O 模型： 阻塞式 I/O非阻塞式 I/OI/O 复用（select 和 poll）信号驱动式 I/O（SIGIO）异步 I/O（AIO） 阻塞式 I/O应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。","text":"简介一个输入操作通常包括两个阶段： 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 Unix 有五种 I/O 模型： 阻塞式 I/O非阻塞式 I/OI/O 复用（select 和 poll）信号驱动式 I/O（SIGIO）异步 I/O（AIO） 阻塞式 I/O应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。 非阻塞 I/O应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。 I/O 复用简介使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 详解基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 强调： 如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 结论: select的优势在于可以处理多个连接，不适用于单个连接 信号驱动 I/O应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。 异步 I/O应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 五大 I/O 模型比较 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段，应用进程会阻塞。 异步 I/O：不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用、信号驱动 I/O 都是同步 I/O，它们的主要区别在第一个阶段。 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。 同步异步与阻塞与非阻塞阻塞IO 和 非阻塞IO这两个概念是程序级别的。主要描述的是程序请求操作系统IO操作后，如果IO资源没有准备好，那么程序该如何处理的问题: 前者等待；后者继续执行(并且使用线程一直轮询，直到有IO资源准备好了) 同步IO 和 非同步IO这两个概念是操作系统级别的。主要描述的是操作系统在收到程序请求IO操作后，如果IO资源没有准备好，该如何相应程序的问题: 前者不响应，直到IO资源准备好以后；后者返回一个标记(好让程序和自己知道以后的数据往哪里通知)，当IO资源准备好以后，再用事件机制返回给程序。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"IO模型","slug":"IO模型","permalink":"https://blog.unclezs.com/tags/IO%E6%A8%A1%E5%9E%8B/"}]},{"title":"Redis的哨兵","slug":"数据库/redis/Redis的哨兵","date":"2020-08-22T09:02:12.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/Redis的哨兵.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/Redis%E7%9A%84%E5%93%A8%E5%85%B5.html","excerpt":"哨兵介绍sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能： 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。 参考转自：Redis 哨兵集群实现高可用","text":"哨兵介绍sentinel，中文名是哨兵。哨兵是 Redis 集群架构中非常重要的一个组件，主要有以下功能： 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。哨兵用于实现 Redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。 参考转自：Redis 哨兵集群实现高可用","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"哨兵","slug":"哨兵","permalink":"https://blog.unclezs.com/tags/%E5%93%A8%E5%85%B5/"}]},{"title":"Redis的主从架构","slug":"数据库/redis/Redis的主从架构","date":"2020-08-22T05:31:03.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/Redis的主从架构.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/Redis%E7%9A%84%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.html","excerpt":"介绍单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 Redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 Redis replication 的核心机制 Redis 采用异步方式复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量； 一个 master node 是可以配置多个 slave node 的； slave node 也可以连接其他的 slave node； slave node 做复制的时候，不会 block master node 的正常工作； slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了； slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。 注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。 另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。 Redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。","text":"介绍单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 Redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 Redis replication 的核心机制 Redis 采用异步方式复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量； 一个 master node 是可以配置多个 slave node 的； slave node 也可以连接其他的 slave node； slave node 做复制的时候，不会 block master node 的正常工作； slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了； slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。 注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。 另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。 Redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 主从复制的断点续传从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 resynchronization 。 如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。 无磁盘化复制master 在内存中直接创建 RDB ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 repl-diskless-sync yes 即可。 repl-diskless-sync yes # 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来 repl-diskless-sync-delay 5 过期 key 处理slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。 复制的完整流程slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 host 和 ip ，但是复制流程没开始。 slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 ping 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node 第一次执行全量复制，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。 全量复制 master 执行 bgsave ，在本地生成一份 rdb 快照文件。 master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s) master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。client-output-buffer-limit slave 256MB 64MB 60 slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时基于旧的数据版本对外提供服务。 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。 增量复制 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。 master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。 master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。 心跳机制主从节点互相都会发送 heartbeat 信息。 master 默认每隔 10秒 发送一次 heartbeat，slave node 每隔 1秒 发送一个 heartbeat。 异步复制master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。 转自：Redis 主从架构","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"高可用","slug":"高可用","permalink":"https://blog.unclezs.com/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"}]},{"title":"Redis的数据类型详解","slug":"数据库/redis/Redis的数据类型详解","date":"2020-08-21T08:17:47.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/Redis的数据类型详解.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3.html","excerpt":"Strings介绍这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。 set key sth 底层Redis中为了实现方便的扩展、安全和性能，自己定义了一个结构用来存储字符串。我们叫它SDS（simple dynamic string） 推荐阅读 Redis底层之String Hashes","text":"Strings介绍这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。 set key sth 底层Redis中为了实现方便的扩展、安全和性能，自己定义了一个结构用来存储字符串。我们叫它SDS（simple dynamic string） 推荐阅读 Redis底层之String Hashes介绍这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。 hset person name bingo hset person age 20 hset person id 1 hget person name person &#x3D; &#123; &quot;name&quot;: &quot;bingo&quot;, &quot;age&quot;: 20, &quot;id&quot;: 1 &#125; 底层源码typedef struct dictht &#123; dictEntry **table; // 哈希表数组 unsigned long size; // 哈希表数组的大小 unsigned long sizemask; // 用于映射位置的掩码，值永远等于(size-1) unsigned long used; // 哈希表已有节点的数量 &#125; dictht; typedef struct dictEntry &#123; void *key; // 键 union &#123; // 值 void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next; // 指向下一个哈希表节点，形成单向链表 &#125; dictEntry; 总体结构图 是不是很眼熟，就是Java的HashMap一样的，使用的拉链法解决冲突。 补充hash类型是一个dict，一个dict有两张hash表，其中一张表是用来做rehash的 与Java的HashMap不同的是: Redis的字典只能是字符串， rehash的方式不一样：Java是一次性rehash全部；Redis为了追求高性能，不能堵塞服务，所以采用了渐进式rehash策略。 Lists介绍Lists 是有序列表，这个可以玩儿出很多花样。 比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。 # 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。 lrange mylist 0 -1 #比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。 lpush mylist 1 lpush mylist 2 lpush mylist 3 4 5 # 1 rpop mylist 底层3.2版本之前3.2版本之前的 使用压缩列表（zipList）和双向链表（linkedlist） 初始为zipList，当链表entry数据超过512、或单个value 长度超过64，底层就会转化成linkedlist编码 优缺点： 双向链表linkedlist便于在表的两端进行push和pop操作，在插入节点上复杂度很低，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。ziplist存储在一段连续的内存上，所以存储效率很高。但是，它不利于修改操作，插入和删除操作需要频繁的申请和释放内存。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝。 3.2版本之后使用quickList实现。可以认为quickList，是ziplist和linkedlist二者的结合；quickList将二者的优点结合起来。 quickList是一个ziplist组成的双向链表。每个节点使用ziplist来保存数据。本质上来说，quicklist里面保存着一个一个小的ziplist。结构如下： 推荐阅读 Redis列表list底层原理 Sets介绍Sets 是无序集合，自动去重。 直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。 可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。 把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。 #-------操作一个set------- # 添加元素 sadd mySet 1 # 查看全部元素 smembers mySet # 判断是否包含某个值 sismember mySet 3 # 删除某个&#x2F;些元素 srem mySet 1 srem mySet 2 4 # 查看元素个数 scard mySet # 随机删除一个元素 spop mySet #-------操作多个set------- # 将一个set的元素移动到另外一个set smove yourSet mySet 2 # 求两set的交集 sinter yourSet mySet # 求两set的并集 sunion yourSet mySet # 求在yourSet中而不在mySet中的元素 sdiff yourSet mySet 底层与Java中的HashSet一样，无序且存储元素不重复。其底层有两种实现方式，当value是整数值时，且数据量不大时使用inset来存储，其他情况都是用字典dict来存储。 typedf struct inset&#123; uint32_t encoding;//编码方式 有三种 默认 INSET_ENC_INT16 uint32_t length;//集合元素个数 int8_t contents[];//实际存储元素的数组 //元素类型并不一定是ini8_t类型，柔性数组不占intset结构体大小，并且数组中的元 //素从小到大排列 &#125;inset; //16位，2个字节，表示范围-32,768~32,767 #define INTSET_ENC_INT16 (sizeof(int16_t)) //32位，4个字节，表示范围-2,147,483,648~2,147,483,647 #define INTSET_ENC_INT32 (sizeof(int32_t)) //64位，8个字节，表示范围-9,223,372,036,854,775,808~9,223,372,036,854,775,807 #define INTSET_ENC_INT64 (sizeof(int64_t)) 推荐阅读：Redis底层数据结构之set Sorted Sets介绍Sorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。 zadd board 85 zhangsan zadd board 72 lisi zadd board 96 wangwu zadd board 63 zhaoliu # 获取排名前三的用户（默认是升序，所以需要 rev 改为降序） zrevrange board 0 3 # 获取某用户的排名 zrank board zhaoliu 实现sortedset同时会由两种数据结构支持,ziplist和skiplist. 只有同时满足如下条件是,使用的是ziplist,其他时候则是使用skiplist 有序集合保存的元素数量小于128个 有序集合保存的所有元素的长度小于64字节 当ziplist作为存储结构时候,每个集合元素使用两个紧挨在一起的压缩列表结点来保存,第一个节点保存元素的成员,第二个元素保存元素的分值. 当使用skiplist作为存储结构时,使用skiplist按序保存元素分值,使用dict来保存元素和分值的对应关系","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"数据类型","slug":"数据类型","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"Redis","slug":"Redis","permalink":"https://blog.unclezs.com/tags/Redis/"}]},{"title":"关于Redis的一些面试题","slug":"数据库/redis/关于Redis的一些面试题","date":"2020-08-20T10:25:36.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/关于Redis的一些面试题.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%85%B3%E4%BA%8ERedis%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9D%A2%E8%AF%95%E9%A2%98.html","excerpt":"Redis为什么这么快？ 纯内存操作。 核心是基于非阻塞的 IO 多路复用机制。 C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。","text":"Redis为什么这么快？ 纯内存操作。 核心是基于非阻塞的 IO 多路复用机制。 C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"面经","slug":"面经","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E7%BB%8F/"}]},{"title":"关于MySQL的一些面试题","slug":"数据库/mysql/关于MySQL的一些面试题","date":"2020-08-20T08:56:39.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/关于MySQL的一些面试题.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E5%85%B3%E4%BA%8EMySQL%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9D%A2%E8%AF%95%E9%A2%98.html","excerpt":"索引为什么说B+树比B树更合适做索引？ 单一结点存储更多的关键字，使得查询的IO次数减少； 所有查询都要查找到叶子节点，查询性能稳定； 所有叶子节点形成有序链表，便于区间查询以及全结点遍历更快。 支持范围查询 什么是索引覆盖？索引覆盖就是查询的字段都是索引字段。 实现索引覆盖：将被查询的字段，建立到联合索引里去。 事务数据库事务隔离级别及实现？隔离级别：读未提交，读已提交，可重复读，串行化。 实现：","text":"索引为什么说B+树比B树更合适做索引？ 单一结点存储更多的关键字，使得查询的IO次数减少； 所有查询都要查找到叶子节点，查询性能稳定； 所有叶子节点形成有序链表，便于区间查询以及全结点遍历更快。 支持范围查询 什么是索引覆盖？索引覆盖就是查询的字段都是索引字段。 实现索引覆盖：将被查询的字段，建立到联合索引里去。 事务数据库事务隔离级别及实现？隔离级别：读未提交，读已提交，可重复读，串行化。 实现： 读未提交：不加锁的方式。 读已提交：只加记录锁，不加 gap locks 。 可重复度：对于唯一索引，只加记录锁。对于其他搜索，gap locks 或者 next-key locks 串行化：InnoDB 默默的把所有纯 SELECT 语句都转成了 SELECT … FOR SHARE 参考Transaction Isolation Levels","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"面经","slug":"面经","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E7%BB%8F/"}]},{"title":"设计模式-责任链","slug":"Java/设计模式/设计模式-责任链","date":"2020-08-19T02:25:20.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-责任链.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%B4%A3%E4%BB%BB%E9%93%BE.html","excerpt":"介绍使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 JDK中的责链接： java.util.logging.Logger#log() Apache Commons Chain javax.servlet.Filter#doFilter() 优缺点及应用场景优点 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 增加新的请求处理类很方便。 缺点 不能保证请求一定被接收。 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 可能不容易观察运行时的特征，有碍于除错。","text":"介绍使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 JDK中的责链接： java.util.logging.Logger#log() Apache Commons Chain javax.servlet.Filter#doFilter() 优缺点及应用场景优点 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 增加新的请求处理类很方便。 缺点 不能保证请求一定被接收。 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 可能不容易观察运行时的特征，有碍于除错。 场景 JS 中的事件冒泡。 AVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 代码实现public abstract class Handler &#123; protected Handler successor; public Handler(Handler successor) &#123; this.successor = successor; &#125; protected abstract void handleRequest(Request request); &#125; public class ConcreteHandler1 extends Handler &#123; public ConcreteHandler1(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE1) &#123; System.out.println(request.getName() + &quot; is handle by ConcreteHandler1&quot;); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125; &#125; public class ConcreteHandler2 extends Handler &#123; public ConcreteHandler2(Handler successor) &#123; super(successor); &#125; @Override protected void handleRequest(Request request) &#123; if (request.getType() == RequestType.TYPE2) &#123; System.out.println(request.getName() + &quot; is handle by ConcreteHandler2&quot;); return; &#125; if (successor != null) &#123; successor.handleRequest(request); &#125; &#125; &#125; public class Request &#123; private RequestType type; private String name; public Request(RequestType type, String name) &#123; this.type = type; this.name = name; &#125; public RequestType getType() &#123; return type; &#125; public String getName() &#123; return name; &#125; &#125; public enum RequestType &#123; TYPE1, TYPE2 &#125; public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.TYPE1, &quot;request1&quot;); handler2.handleRequest(request1); Request request2 = new Request(RequestType.TYPE2, &quot;request2&quot;); handler2.handleRequest(request2); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"责任链","slug":"责任链","permalink":"https://blog.unclezs.com/tags/%E8%B4%A3%E4%BB%BB%E9%93%BE/"}]},{"title":"MySQL死锁的调试","slug":"数据库/mysql/MySQL死锁的调试","date":"2020-08-18T02:43:00.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySQL死锁的调试.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E6%AD%BB%E9%94%81%E7%9A%84%E8%B0%83%E8%AF%95.html","excerpt":"什么是死锁？死锁是指由于每个事务都持有对方需要的锁而无法进行其他事务的情况。因为这两个事务都在等待资源变得可用，所以两个都不会释放它持有的锁。 数据库死锁，是最难调试与追踪的。所以本文记录一些死锁调试的思路。 死锁例子以下示例说明了锁定请求将导致死锁时如何发生错误。该示例涉及两个事务A和B。 首先，创建一个包含一行的表，然后开始事务A。在事务中，A事务中对i=1的行加上S锁： CREATE TABLE t (i INT) ENGINE = InnoDB; INSERT INTO t (i) VALUES(1); #A事务 START TRANSACTION; SELECT * FROM t WHERE i = 1 FOR SHARE; B事务删除 i=1 的行，删除操作需要一个X锁。无法授予该行的S锁，因为它与事务A持有的锁不兼容 ，因此事务B阻塞 #B事务 DELETE FROM t WHERE i = 1; 最后，事务A还尝试从表中删除该行：","text":"什么是死锁？死锁是指由于每个事务都持有对方需要的锁而无法进行其他事务的情况。因为这两个事务都在等待资源变得可用，所以两个都不会释放它持有的锁。 数据库死锁，是最难调试与追踪的。所以本文记录一些死锁调试的思路。 死锁例子以下示例说明了锁定请求将导致死锁时如何发生错误。该示例涉及两个事务A和B。 首先，创建一个包含一行的表，然后开始事务A。在事务中，A事务中对i=1的行加上S锁： CREATE TABLE t (i INT) ENGINE = InnoDB; INSERT INTO t (i) VALUES(1); #A事务 START TRANSACTION; SELECT * FROM t WHERE i = 1 FOR SHARE; B事务删除 i=1 的行，删除操作需要一个X锁。无法授予该行的S锁，因为它与事务A持有的锁不兼容 ，因此事务B阻塞 #B事务 DELETE FROM t WHERE i = 1; 最后，事务A还尝试从表中删除该行： #A事务 DELETE FROM t WHERE i = 1; 此处发生死锁，因为事务A需要 X锁才能删除该行。但是事务B已经有一个X锁定请求，并且正在等待客户端A释放其S锁定。所以进入了互相等待的死锁结果， InnoDB为其中一个客户端生成错误并释放其锁。客户端返回此错误： ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 因为MySQL的死锁检查机制，自动回滚影响最小的事务（事务中插入、更新或删除的行数确定），解除死锁。 死锁检测机制 InnoDB自动检测事务的死锁和回退事务解决死锁问题。 InnoDB尝试选择要回滚的小事务，其中事务的大小由插入，更新或删除的行数确定。 #查看事务阻塞时间 show VARIABLES like &#x27;innodb_lock_wait_timeout&#x27; #设置等待锁时间 SET innodb_lock_wait_timeout= some_number #查看死锁是否自动回滚 show VARIABLES like &#x27;innodb_deadlock_detect&#x27; # 启动关闭死锁检测 SET innodb_deadlock_detect=0/1 处理死锁查找死锁 最近一次死锁在任何时候，发出以下命令以确定最近死锁的原因。然后调整代码以避免死锁。 SHOW ENGINE INNODB STATUS 所有死锁通过启用innodb_print_all_deadlocks 配置选项来收集更广泛的调试信息 。有关每个死锁的信息，而不仅仅是最新的死锁，都记录在MySQL 错误日志中。完成调试后，请应该禁用此选项。 #查询是否启用所有死锁信息保存到日志 show variables like &#x27;innodb_print_all_deadlocks&#x27;; set innodb_print_all_deadlocks=0/1; 定位死锁比如上面那个死锁例子，通过SHOW ENGINE INNODB STATUS命令拿到最近的死锁信息得到以下结果。 ------------------------ LATEST DETECTED DEADLOCK ------------------------ 2020-08-19 18:46:57 0x1ee0 *** (1) TRANSACTION: TRANSACTION 87305, ACTIVE 3 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 9, OS thread handle 15096, query id 154 localhost ::1 root updating DELETE FROM t WHERE i = 1 *** (1) HOLDS THE LOCK(S): RECORD LOCKS space id 163 page no 4 n bits 72 index GEN_CLUST_INDEX of table `area_data`.`t` trx id 87305 lock_mode X waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 000000000200; asc ;; 1: len 6; hex 000000015348; asc SH;; 2: len 7; hex 820000008b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 163 page no 4 n bits 72 index GEN_CLUST_INDEX of table `area_data`.`t` trx id 87305 lock_mode X waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 000000000200; asc ;; 1: len 6; hex 000000015348; asc SH;; 2: len 7; hex 820000008b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** (2) TRANSACTION: TRANSACTION 87306, ACTIVE 6 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 4 lock struct(s), heap size 1136, 3 row lock(s) MySQL thread id 8, OS thread handle 6104, query id 158 localhost ::1 root updating DELETE FROM t WHERE i = 1 *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 163 page no 4 n bits 72 index GEN_CLUST_INDEX of table `area_data`.`t` trx id 87306 lock mode S Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 000000000200; asc ;; 1: len 6; hex 000000015348; asc SH;; 2: len 7; hex 820000008b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 163 page no 4 n bits 72 index GEN_CLUST_INDEX of table `area_data`.`t` trx id 87306 lock_mode X waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 6; hex 000000000200; asc ;; 1: len 6; hex 000000015348; asc SH;; 2: len 7; hex 820000008b0110; asc ;; 3: len 4; hex 80000001; asc ;; *** WE ROLL BACK TRANSACTION (1) 主题流程可以看到，事务2持有S锁，然后事务1请求X锁，然后事务2也去请求X锁，结果失败了执行回滚了 参考官方文档-Deadlocks in InnoDB","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"死锁","slug":"死锁","permalink":"https://blog.unclezs.com/tags/%E6%AD%BB%E9%94%81/"}]},{"title":"MySQL调优利器Explain","slug":"数据库/mysql/MySQL调优利器Explain","date":"2020-08-17T03:13:24.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySQL调优利器Explain.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E8%B0%83%E4%BC%98%E5%88%A9%E5%99%A8Explain.html","excerpt":"介绍Expalin是用于获取SQL语句的执行计划的一个指令，比如是否走的索引，走的哪个索引之类的。 语法官方定义语法： &#123;EXPLAIN | DESCRIBE | DESC&#125; 表名 [col_name | wild] &#123;EXPLAIN | DESCRIBE | DESC&#125; [explain_type] &#123;explainable_stmt | FOR CONNECTION connection_id&#125; &#123;EXPLAIN | DESCRIBE | DESC&#125; ANALYZE [FORMAT = TREE] select_statement explain_type: &#123; FORMAT = format_name &#125; format_name: &#123; TRADITIONAL | JSON | TREE &#125; explainable_stmt: &#123; SELECT statement | TABLE statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement &#125; 可以看出来，explain/desc/describe 三个有同样的功能，MySQL也把他们当作同义词，但是describe通常用来查询表结构，explain通常用来查询SQL执行的计划。 比如 # 表格形式显示结果 explain select * from xxxTable; # json格式显示结果 explain FORMAT = JSON SELECT * FROM xxxTable; # 分析SQL的执行时间与实际耗时 EXPLAIN ANALYZE SELECT * FROM xxxTable; 输出格式的解释输出列的解释","text":"介绍Expalin是用于获取SQL语句的执行计划的一个指令，比如是否走的索引，走的哪个索引之类的。 语法官方定义语法： &#123;EXPLAIN | DESCRIBE | DESC&#125; 表名 [col_name | wild] &#123;EXPLAIN | DESCRIBE | DESC&#125; [explain_type] &#123;explainable_stmt | FOR CONNECTION connection_id&#125; &#123;EXPLAIN | DESCRIBE | DESC&#125; ANALYZE [FORMAT = TREE] select_statement explain_type: &#123; FORMAT = format_name &#125; format_name: &#123; TRADITIONAL | JSON | TREE &#125; explainable_stmt: &#123; SELECT statement | TABLE statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement &#125; 可以看出来，explain/desc/describe 三个有同样的功能，MySQL也把他们当作同义词，但是describe通常用来查询表结构，explain通常用来查询SQL执行的计划。 比如 # 表格形式显示结果 explain select * from xxxTable; # json格式显示结果 explain FORMAT = JSON SELECT * FROM xxxTable; # 分析SQL的执行时间与实际耗时 EXPLAIN ANALYZE SELECT * FROM xxxTable; 输出格式的解释输出列的解释 行 JSON Name 含义 id select_id 该SELECT标识符 select_type None 该SELECT类型 table table_name 操作的表 partitions partitions 匹配的分区 type access_type 联接类型 possible_keys possible_keys 可能的索引选择 key key 实际选择的索引 key_len key_length 所选键的长度 ref ref 与索引比较的列 rows rows 估计要检查的行数 filtered filtered 按表条件过滤的行百分比 Extra None 附加信息 注意：如果Format格式为JSON，那么不会显示为NULL的行 select_type select_type JSON名称 含义 simple 没有 简单select（不使用 union或子查询） primary 没有 最外层 select union 没有 第二个或之后的select陈述 union dependent union dependent（true） union RESULT union_result 的结果union。 subquery 没有 首先select在子查询 dependent subquery dependent（true） 首先select在子查询中，取决于外部查询 derived 没有 派生表 dependent derived dependent（true） 派生表依赖于另一个表 materialized materialized_from_subquery 物化子查询 uncacheable subquery cacheable（false） 子查询，其结果无法缓存，必须针对外部查询的每一行重新进行评估 uncacheable union cacheable（false） union 属于不可缓存子查询的中的第二个或更高版本的选择（请参阅uncacheable subquery type system：该表只有一行（=系统表）。这是const联接类型的特例 。 const：该表最多具有一个匹配行，该行在查询开始时读取。因为只有一行，所以优化器的其余部分可以将这一行中列的值视为常量。 const表非常快，因为它们只能读取一次。比如我们通过唯一索引等值查询的时候就是const eq_ref：唯一索引单值扫描； ref：非唯一索引单值扫描； fulltext：使用FULLTEXT 索引执行联接。 ref_or_null：这种连接类型类似于 ref，但是MySQL会额外搜索包含NULL值的行。此联接类型优化最常用于解析子查询。 index_merge：此联接类型指示使用索引合并优化。在这种情况下，key输出行中的列包含使用的索引列表，并key_len包含使用的索引 的最长键部分的列表。 unique_subquery：只是一个索引查找函数，它完全替代了子查询以提高效率，此类型替换以下形式的eq_ref某些IN子查询：value IN (SELECT primary_key FROM single_table WHERE some_expr) index_subquery：此连接类型类似于 unique_subquery。它替代IN子查询，但适用于以下形式的子查询中的非唯一索引：value IN (SELECT key_column FROM single_table WHERE some_expr) range：命中where子句的范围索引扫描； index：走索引的全表扫描，当查询仅使用属于单个索引一部分的列时，MySQL可以使用此联接类型。两种方式： 如果索引是查询的覆盖索引，并且可用于满足表中所需的所有数据，则仅扫描索引树。在这种情况下，Extra列显示为 Using index。仅索引扫描通常比索引扫描更快， ALL因为索引的大小通常小于表数据。 使用对索引的读取执行全表扫描，以按索引顺序查找数据行。 Uses index没有出现在 Extra列中。 all：全表扫描 possible_keys可能在哪个索引找到记录。 要查看表具有哪些索引，请使用。 SHOW INDEX FROM table_name 要强制MySQL使用或忽略列出的索引possible_keys列，使用 FORCE INDEX，USE INDEX或IGNORE INDEX在查询里。 SELECT * FROM table1 USE INDEX (col1_index,col2_index) WHERE col1=1 AND col2=2 AND col3=3; SELECT * FROM table1 IGNORE INDEX (col3_index) WHERE col1=1 AND col2=2 AND col3=3; key该key列指示MySQL实际决定使用的键（索引）。如果MySQL决定使用possible_keys 索引之一来查找行，则将该索引列为键值。 key中的值不一定会出现在possible_keys中，这个情况出现在查询的所有列都是其他索引的列。 select id from table; 比如这个情况下，即使没有使用索引当作查询条件，也会走索引。 参考官方文档 - EXPLAIN Statement","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"}]},{"title":"Class类字节码详解","slug":"Java/Jvm/Class类字节码详解","date":"2020-08-16T13:50:33.000Z","updated":"2020-08-16T13:50:33.000Z","comments":true,"path":"Java/Jvm/Class类字节码详解.html","link":"","permalink":"https://blog.unclezs.com/Java/Jvm/Class%E7%B1%BB%E5%AD%97%E8%8A%82%E7%A0%81%E8%AF%A6%E8%A7%A3.html","excerpt":"简介为什么jvm不能直接运行java代码呢，这是因为在cpu层面看来计算机中所有的操作都是一个个指令的运行汇集而成的，java是高级语言，只有人类才能理解其逻辑，计算机是无法识别的，所以java代码必须要先编译成字节码文件，jvm才能正确识别代码转换后的指令并将其运行。 Java代码间接翻译成字节码，储存字节码的文件再交由运行于不同平台上的JVM虚拟机去读取执行，从而实现一次编写，到处运行的目的。 Jvm也不再只支持Java，由此衍生出了许多基于JVM的编程语言，如Groovy, Scala, Koltin等等。 Java字节码文件class文件本质上是一个以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在class文件中。jvm根据其特定的规则解析该二进制数据，从而得到相关信息。 class文件采用一种伪结构来存储数据，它有两种类型：无符号数和表。这里暂不详细的讲。 本文将通过简单的java例子编译后的文件来理解。 Class文件的结构属性在理解之前先从整体看下java字节码文件包含了哪些类型的数据：","text":"简介为什么jvm不能直接运行java代码呢，这是因为在cpu层面看来计算机中所有的操作都是一个个指令的运行汇集而成的，java是高级语言，只有人类才能理解其逻辑，计算机是无法识别的，所以java代码必须要先编译成字节码文件，jvm才能正确识别代码转换后的指令并将其运行。 Java代码间接翻译成字节码，储存字节码的文件再交由运行于不同平台上的JVM虚拟机去读取执行，从而实现一次编写，到处运行的目的。 Jvm也不再只支持Java，由此衍生出了许多基于JVM的编程语言，如Groovy, Scala, Koltin等等。 Java字节码文件class文件本质上是一个以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在class文件中。jvm根据其特定的规则解析该二进制数据，从而得到相关信息。 class文件采用一种伪结构来存储数据，它有两种类型：无符号数和表。这里暂不详细的讲。 本文将通过简单的java例子编译后的文件来理解。 Class文件的结构属性在理解之前先从整体看下java字节码文件包含了哪些类型的数据： 反编译一个Demopublic class Main &#123; private int m; public int inc() &#123; return m + 1; &#125; &#125; 用WinHex查看Main.class 16进制文件 cafe babe 0000 0034 0013 0a00 0400 0f09 0003 0010 0700 1107 0012 0100 016d 0100 0149 0100 063c 696e 6974 3e01 0003 2829 5601 0004 436f 6465 0100 0f4c 696e 654e 756d 6265 7254 6162 6c65 0100 0369 6e63 0100 0328 2949 0100 0a53 6f75 7263 6546 696c 6501 0009 4d61 696e 2e6a 6176 610c 0007 0008 0c00 0500 0601 0010 636f 6d2f 7268 7974 686d 372f 4d61 696e 0100 106a 6176 612f 6c61 6e67 2f4f 626a 6563 7400 2100 0300 0400 0000 0100 0200 0500 0600 0000 0200 0100 0700 0800 0100 0900 0000 1d00 0100 0100 0000 052a b700 01b1 0000 0001 000a 0000 0006 0001 0000 0003 0001 000b 000c 0001 0009 0000 001f 0002 0001 0000 0007 2ab4 0002 0460 ac00 0000 0100 0a00 0000 0600 0100 0000 0800 0100 0d00 0000 0200 0e 文件开头的4个字节(“cafe babe”)称之为 魔数，唯有以”cafe babe”开头的class文件方可被虚拟机所接受，这4个字节就是字节码文件的身份识别。 0000是编译器jdk版本的次版本号0，0034转化为十进制是52,是主版本号，java的版本号从45开始，除1.0和1.1都是使用45.x外,以后每升一个大版本，版本号加一。也就是说，编译生成该class文件的jdk版本为1.8.0。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Jvm","slug":"Java/Jvm","permalink":"https://blog.unclezs.com/categories/Java/Jvm/"}],"tags":[{"name":"字节码","slug":"字节码","permalink":"https://blog.unclezs.com/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}],"author":"Unclezs"},{"title":"Redis中的跳越表","slug":"数据库/redis/Redis中的跳越表","date":"2020-08-16T12:26:37.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/Redis中的跳越表.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/Redis%E4%B8%AD%E7%9A%84%E8%B7%B3%E8%B6%8A%E8%A1%A8.html","excerpt":"介绍跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表什么是跳跃表对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。 如果我们想要提高其查找效率，可以考虑在链表上建索引的方式。每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作索引。 这个时候，我们假设要查找节点8，我们可以先在索引层遍历，当遍历到索引层中值为 7 的结点时，发现下一个节点是9，那么要查找的节点8肯定就在这两个节点之间。我们下降到链表层继续遍历就找到了8这个节点。原先我们在单链表中找到8这个节点要遍历8个节点，而现在有了一级索引后只需要遍历五个节点。 从这个例子里，我们看出，加来一层索引之后，查找一个结点需要遍的结点个数减少了，也就是说查找效率提高了，同理再加一级索引。","text":"介绍跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表什么是跳跃表对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。 如果我们想要提高其查找效率，可以考虑在链表上建索引的方式。每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作索引。 这个时候，我们假设要查找节点8，我们可以先在索引层遍历，当遍历到索引层中值为 7 的结点时，发现下一个节点是9，那么要查找的节点8肯定就在这两个节点之间。我们下降到链表层继续遍历就找到了8这个节点。原先我们在单链表中找到8这个节点要遍历8个节点，而现在有了一级索引后只需要遍历五个节点。 从这个例子里，我们看出，加来一层索引之后，查找一个结点需要遍的结点个数减少了，也就是说查找效率提高了，同理再加一级索引。 这次次数更少了，只需要3次即可查找到数字8，可以看出来，增加更多的索引可以增加查找速度。 上面就是跳跃表了。 时间复杂度O(logn)有n个结点的链表，假设每两个链表构建一个索引，那么：第一级索引个数为：n/2；第二级索引个数为：n/4；···第h级索引个数为：n/2^h；现在假设最后一级索引的个数为2 ，则h +1 = logn，算上最底下的一层链表，那么这个跳表的高度H= logn。 在图里，我们想查找x，在第k级，遍历到y结点，发现x大于y，但x小于y后面的结点z，所以先顺着y往下到第k-1级，发现y，z之间有三个节点，所以我们在k-1级索引中，遍历3个节点找到x，以此类推，在每一层需要通过3个节点找目标数，那么总的时间复杂度就为O(3logn)，因为3是常数，所以最后的时间复杂度为*O(logn)**。这一结构相当于让跳表实现了二分查找，只是建立这么多的索引是否会浪费空间呢？我们来看一下跳表的空间复杂度。 跳表的空间复杂度O(n)还是回到刚刚的例子，我们可以发现，链表上的索引数目按第一层，第二层，···，倒数第二层，最后一层的顺序排列下来分别为：n/2，n/4，···，4，2，观察到了吗？就是一个等比数列，计算该跳表的空间复杂度，相当于给等比数列求和，等比数列求和公式： 顺着公式依次带入：a1=n/2，an= 2，q=1/2，求得Sn= n-2，所以空间复杂度为O(n)，与此同时，我们顺便考虑一下每三个节点抽取一个索引的情况，还是依据刚刚的思路，发现Sn= n-1/2，空间复杂度将近缩减了一半。总之，跳表就是空间换时间的那个思路，但如果链表中存储的对象很大时，其实索引占用的这些空间对整个来说是可以忽略不计的。 跳表的高效插入和删除插入单链表在知道删除的节点是谁时，时间复杂度为O(1)，因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。 删除删除的节点要分两种情况： 删除的节点还在索引中，那删除时不仅要删除单链表中的节点，还要删除索引中的节点； 删除的节点只在链表中，不在索引中，那只需要删除链表中的节点即可。 特点 时间换空间 基于单链表加索引方式提升查找性能 Redis中的跳跃表Redis使用跳跃表作为有序集合键的底层实现之一,如果一个有序集合包含的元素数量比较多,又或者有序集合中元素的成员是比较长的字符串时, Redis就会使用跳跃表来作为有序集合健的底层实现。 这里我们需要思考一个问题——为什么元素数量比较多或者成员是比较长的字符串的时候Redis要使用跳跃表来实现？ 从上面我们可以知道，跳跃表在链表的基础上增加了多级索引以提升查找的效率，但其是一个空间换时间的方案，必然会带来一个问题——索引是占内存的。原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值值和几个指针，并不需要存储对象，因此当节点本身比较大或者元素数量比较多的时候，其优势必然会被放大，而缺点则可以忽略。 Redis中跳跃表的实现 Redis的跳跃表由zskiplistNode和skiplist两个结构定义,其中 zskiplistNode结构用于表示跳跃表节点,而 zskiplist结构则用于保存跳跃表节点的相关信息,比如节点的数量,以及指向表头节点和表尾节点的指针等等。 skiplist结构图左边第一个就是。 header:指向跳跃表的表头节点，通过这个指针程序定位表头节点的时间复杂度就为O(1) tail:指向跳跃表的表尾节点,通过这个指针程序定位表尾节点的时间复杂度就为O(1) level:记录目前跳跃表内,层数最大的那个节点的层数(表头节点的层数不计算在内)，通过这个属性可以再O(1)的时间复杂度内获取层高最好的节点的层数。 length:记录跳跃表的长度,也即是,跳跃表目前包含节点的数量(表头节点不计算在内)，通过这个属性，程序可以再O(1)的时间复杂度内返回跳跃表的长度。 zskiplistNode结构图右边四个 层(level):节点中用L1、L2、L3等字样标记节点的各个层,L1代表第一层,L代表第二层,以此类推。每个层都带有两个属性:前进指针和跨度。前进指针用于访问位于表尾方向的其他节点,而跨度则记录了前进指针所指向节点和当前节点的距离(跨度越大、距离越远)。在上图中,连线上带有数字的箭头就代表前进指针,而那个数字就是跨度。当程序从表头向表尾进行遍历时,访问会沿着层的前进指针进行。每次创建一个新跳跃表节点的时候,程序都根据幂次定律(powerlaw,越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小,这个大小就是层的“高度”。 后退(backward)指针：节点中用BW字样标记节点的后退指针,它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。与前进指针所不同的是每个节点只有一个后退指针，因此每次只能后退一个节点。 分值(score):各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中,节点按各自所保存的分值从小到大排列。 成员对象(oj):各个节点中的o1、o2和o3是节点所保存的成员对象。在同一个跳跃表中,各个节点保存的成员对象必须是唯一的,但是多个节点保存的分值却可以是相同的:分值相同的节点将按照成员对象在字典序中的大小来进行排序,成员对象较小的节点会排在前面(靠近表头的方向),而成员对象较大的节点则会排在后面(靠近表尾的方向)。 与红黑树对比 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性 更容易实现 支持范围查找 跳表更加灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。 总结跳跃表就是一个单链表存储数据，多个链表当作索引，不断进行2分建立索引，这样有点类似二分查找的样子。效率比较高。 推荐阅读: 漫画：什么是跳表？","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"跳跃表","slug":"跳跃表","permalink":"https://blog.unclezs.com/tags/%E8%B7%B3%E8%B7%83%E8%A1%A8/"}]},{"title":"Java内存模型JMM","slug":"Java/Jvm/Java内存模型JMM","date":"2020-08-15T07:55:34.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/Jvm/Java内存模型JMM.html","link":"","permalink":"https://blog.unclezs.com/Java/Jvm/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8BJMM.html","excerpt":"介绍Java内存模型（Java Memery Model）用来屏蔽掉各种硬件和操作系统的内存访问差异。以至于让Java在各中平台下都能达到一致的内存访问效果。 简单的说，JMM 定义了一套在多线程读写共享数据时（成员变量、数组）时，对数据的可见性、有序性、和原子性的规则和保障. 从硬件角度来看。因为处理器的运算速度很快，比如做一个递增操作，就需要从内存中拿值，操作后再放回内存。这样的I/O是无法避免的，但这I/O速度和处理器的运算速度就不是一个数量级，所以为了解决这个问题，就对每个处理器加一个高速缓存（Cache）来作为处理器与内存之间的缓冲。把需要使用的数据复制到缓存中，运算完成之后在从缓存同步到内存。这样处理器就不用等待缓慢的内存读写了。 Java内存模型图 主存与工作内存的一些交互指令 操作 作用对象 解释 lock 主内存 把一个变量标识为一条线程独占的状态 unlock 主内存 把一个处于锁定状态的变量释放出来，释放后才可被其他线程锁定 read 主内存 把一个变量的值从主内存传输到线程工作内存中，以便 load 操作使用 load 工作内存 把 read 操作从主内存中得到的变量值放入工作内存中 use 工作内存 把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量值的字节码指令时将会执行这个操作 assign 工作内存 把一个从执行引擎接收到的值赋接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作 store 工作内存 把工作内存中的一个变量的值传送到主内存中，以便 write 操作 write 工作内存 把 store 操作从工作内存中得到的变量的值放入主内存的变量中 例子：","text":"介绍Java内存模型（Java Memery Model）用来屏蔽掉各种硬件和操作系统的内存访问差异。以至于让Java在各中平台下都能达到一致的内存访问效果。 简单的说，JMM 定义了一套在多线程读写共享数据时（成员变量、数组）时，对数据的可见性、有序性、和原子性的规则和保障. 从硬件角度来看。因为处理器的运算速度很快，比如做一个递增操作，就需要从内存中拿值，操作后再放回内存。这样的I/O是无法避免的，但这I/O速度和处理器的运算速度就不是一个数量级，所以为了解决这个问题，就对每个处理器加一个高速缓存（Cache）来作为处理器与内存之间的缓冲。把需要使用的数据复制到缓存中，运算完成之后在从缓存同步到内存。这样处理器就不用等待缓慢的内存读写了。 Java内存模型图 主存与工作内存的一些交互指令 操作 作用对象 解释 lock 主内存 把一个变量标识为一条线程独占的状态 unlock 主内存 把一个处于锁定状态的变量释放出来，释放后才可被其他线程锁定 read 主内存 把一个变量的值从主内存传输到线程工作内存中，以便 load 操作使用 load 工作内存 把 read 操作从主内存中得到的变量值放入工作内存中 use 工作内存 把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量值的字节码指令时将会执行这个操作 assign 工作内存 把一个从执行引擎接收到的值赋接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作 store 工作内存 把工作内存中的一个变量的值传送到主内存中，以便 write 操作 write 工作内存 把 store 操作从工作内存中得到的变量的值放入主内存的变量中 例子： 对于volatile型变量的特殊规则关键字 volatile 是 Java 虚拟机提供的最轻量级的同步机制。保存了线程可见性与防止指令重排。 一个变量被定义为volatile的特性1.保证此变量对所有线程的可见性。但是对变量的操作如果不是原子操作，那么并发情况下不安全。如果不满足以下条件就，需要加锁保证并发安全。 运算结果并不依赖变量当前值 能够确保只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 2.禁止指令重排序优化。通过插入内存屏障保证一致性。 对于long和double型变量的特殊规则Java 要求对于主内存和工作内存之间的八个操作都是原子性的，但是对于 64 位的数据类型，有一条宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这 4 个操作的原子性。这就是 long 和 double 的非原子性协定。 原子性、可见性与有序性原子性(Atomicity)由 Java 内存模型来直接保证的原子性变量操作包括 read、load、assign、use、store 和 write。大致可以认为基本数据类型的操作是原子性的。同时 lock 和 unlock 可以保证更大范围操作的原子性。而 synchronize 同步块操作的原子性是用更高层次的字节码指令 monitorenter 和 monitorexit 来隐式操作的。 可见性(Visibility)是指当一个线程修改了共享变量的值，其他线程也能够立即得知这个通知。主要操作细节就是修改值后将值同步至主内存(volatile 值使用前都会从主内存刷新)，除了 volatile 还有 synchronize 和 final 可以保证可见性。同步块的可见性是由“对一个变量执行unlock 操作之前，必须先把此变量同步会主内存中( store、write 操作)”这条规则获得。而 final 可见性是指：被 final 修饰的字段在构造器中一旦完成，并且构造器没有把 “this” 的引用传递出去( this 引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象)，那在其他线程中就能看见 final 字段的值。 有序性(Ordering)如果在被线程内观察，所有操作都是有序的；如果在一个线程中观察另一个线程，所有操作都是无序的。前半句指“线程内表现为串行的语义”，后半句是指“指令重排”现象和“工作内存与主内存同步延迟”现象。Java 语言通过 volatile 和 synchronize 两个关键字来保证线程之间操作的有序性。volatile 自身就禁止指令重排，而 synchronize 则是由“一个变量在同一时刻指允许一条线程对其进行 lock 操作”这条规则获得，这条规则决定了持有同一个锁的两个同步块只能串行的进入。 先行发生原则也就是 happens-before 原则。这个原则是判断数据是否存在竞争、线程是否安全的主要依据。先行发生是 Java 内存模型中定义的两项操作之间的偏序关系。 天然的先行发生关系 规则 解释 程序次序规则 在一个线程内，代码按照书写的控制流顺序执行 管程锁定规则 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作 volatile 变量规则 volatile 变量的写操作先行发生于后面对这个变量的读操作 线程启动规则 Thread 对象的 start() 方法先行发生于此线程的每一个动作 线程终止规则 线程中所有的操作都先行发生于对此线程的终止检测(通过 Thread.join() 方法结束、 Thread.isAlive() 的返回值检测) 线程中断规则 对线程 interrupt() 方法调用优先发生于被中断线程的代码检测到中断事件的发生 (通过 Thread.interrupted() 方法检测) 对象终结规则 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始 传递性 如果操作 A 先于 操作 B 发生，操作 B 先于 操作 C 发生，那么操作 A 先于 操作 C","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Jvm","slug":"Java/Jvm","permalink":"https://blog.unclezs.com/categories/Java/Jvm/"}],"tags":[{"name":"JMM","slug":"JMM","permalink":"https://blog.unclezs.com/tags/JMM/"},{"name":"内存模型","slug":"内存模型","permalink":"https://blog.unclezs.com/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}]},{"title":"Redis数据持久化的两种方式","slug":"数据库/redis/Redis数据持久化的两种方式","date":"2020-08-14T13:42:40.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/Redis数据持久化的两种方式.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/Redis%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html","excerpt":"介绍Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(AOF)里面(这称为“全持久化模式”)。 由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化， 一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化）， 一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。 RDB使用RDB1.自动RDB快照备份，在配置文件中编辑 #指定保存备份周期下面这个就是 60秒之后至少有10000个key发生改变则执行bgsave进行快照保存 save 60 10000 #启用RDB文件压缩 rdbcompression yes #指定文件名称 dbfilename dump.rdb #指定文件存储位置 dir ./ 2.手动保存快照 #异步保存数据 bgsave #同步保存数据，不常用，多用于redis收到shutdown、term命令后执行这个指令保存后进行快照备份,然后关闭服务器 save","text":"介绍Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(AOF)里面(这称为“全持久化模式”)。 由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化， 一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化）， 一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。 RDB使用RDB1.自动RDB快照备份，在配置文件中编辑 #指定保存备份周期下面这个就是 60秒之后至少有10000个key发生改变则执行bgsave进行快照保存 save 60 10000 #启用RDB文件压缩 rdbcompression yes #指定文件名称 dbfilename dump.rdb #指定文件存储位置 dir ./ 2.手动保存快照 #异步保存数据 bgsave #同步保存数据，不常用，多用于redis收到shutdown、term命令后执行这个指令保存后进行快照备份,然后关闭服务器 save 优点 RDB就是一个二进制的单文件，非常适合备份，比如24小时保存一次RDB文件，这样如果想回滚到某天的数据也是很轻松。 与AOF相比，RDB允许大型数据集更快地重启。 RDB最大限度地提高了Redis的性能，因为Redis父进程为了持久化所需要做的唯一工作就是fork一个子进程，后子进程负责将快照写入硬盘，而父进程则继续处理命令请求。 缺点 可能会丢失数据，如果保存时间间隔设置的比较长，如果出现服务崩溃，那么最近的数据还没有保存快照则丢失了。 如果数据量很大，并且CPU性能不佳，那fork出一个子进程可能会很耗时，则可能导致父进程暂停几毫米甚至一秒钟。 AOF简单来说，AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行一次AOF文件包含的所有写命令，就可以恢复AOF文件所记录的数据集。 使用AOF配置文件中编辑 #启用AOF appendonly yes #设置文件名称，文件夹同RDB的一样，也是dir指定 appendfilename appendonly.aof #执行同步到文件的三种频率，如果不知道就使用erverysec # appendfsync always appendfsync everysec # appendfsync no #当AOF文件的体积大于64MB，并且AOF文件的体积比上一次重写之后的体积大了至少一倍（100%）的时候，Redis将执行bgrewriteaof命令。 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 注意： 如果使用了 appendfsync always，那么每次执行指令都会写入文件，这样可能照成大量的磁盘IO。 如果使用了appendfsync no，那么Redis将不对AOF文件执行任何显式的同步操作，而是由操作系统来决定应该在何时对AOF文件进行同步。这个选项在一般情况下不会对Redis的性能带来影响，但系统崩溃将导致使用这种选项的Redis服务器丢失不定数量的数据。另外，如果用户的硬盘处理写入操作的速度不够快的话，那么当缓冲区被等待写入硬盘的数据填满时，Redis的写入操作将被阻塞，并导致Redis处理命令请求的速度变慢。因为这个原因，一般来说并不推荐使用。 手动重写AOF，会删除冗余命令，减少文件大小。 bgrewriteaof 优点 服务崩溃时候数据丢失比较小，只丢失1秒钟。 AOF日志是仅追加的日志，因此，如果断电，则不会出现寻道或损坏问题。即使由于某种原因（磁盘已满或其他原因）以半写命令结束日志，redis-check-aof工具也可以轻松修复它。 AOF以易于理解和解析的格式包含所有操作的日志。您甚至可以轻松导出AOF文件。 误删恢复，比如执行了flushall命令则可以用这个aof文件恢复 缺点 文件体积比RDB大。也会导致数据还原时间会很长。 因为AOF重写也会fork子进程，那么耗时问题还是存在，这个时候如果去rewrite一个很大的AOF文件，那么删除文件可能就会导致操作系统挂起数秒。 根据确切的fsync策略，AOF可能比RDB慢。 总结 RDB持久性按指定的时间间隔保存内存中这个时间点的数据快照 AOF就是记录每次写命令到文件，下次启动的时候从文件中读取再重新执行一次。 RDB和AOF可以同时工作，但是启动的时候会使用AOF文件来重建数据集。根据特性选择合适的策略。 参考官方文档","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"数据持久化","slug":"数据持久化","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"redis","slug":"redis","permalink":"https://blog.unclezs.com/tags/redis/"}]},{"title":"设计模式-代理","slug":"Java/设计模式/设计模式-代理","date":"2020-08-13T02:59:35.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-代理.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86.html","excerpt":"介绍在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 使用场景：按职责来划分，通常有以下使用场景： 远程代理。 虚拟代理。 Copy-on-Write 代理。 保护（Protect or Access）代理。 Cache代理。 防火墙（Firewall）代理。 同步化（Synchronization）代理。 智能引用（Smart Reference）代理。 JDK中的代理模式 java.lang.reflect.Proxy RMI 优缺点及注意优点 职责清晰。 高扩展性。 智能化。","text":"介绍在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 使用场景：按职责来划分，通常有以下使用场景： 远程代理。 虚拟代理。 Copy-on-Write 代理。 保护（Protect or Access）代理。 Cache代理。 防火墙（Firewall）代理。 同步化（Synchronization）代理。 智能引用（Smart Reference）代理。 JDK中的代理模式 java.lang.reflect.Proxy RMI 优缺点及注意优点 职责清晰。 高扩展性。 智能化。 缺点 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 注意事项 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 实现一个Cache代理的实现 public interface Image &#123; void display(); &#125; public class RealImage implements Image &#123; private String fileName; public RealImage(String fileName)&#123; this.fileName = fileName; loadFromDisk(fileName); &#125; @Override public void display() &#123; System.out.println(&quot;Displaying &quot; + fileName); &#125; private void loadFromDisk(String fileName)&#123; System.out.println(&quot;Loading &quot; + fileName); &#125; &#125; public class ProxyImage implements Image&#123; private RealImage realImage; private String fileName; public ProxyImage(String fileName)&#123; this.fileName = fileName; &#125; @Override public void display() &#123; if(realImage == null)&#123; realImage = new RealImage(fileName); &#125; realImage.display(); &#125; &#125; public class ProxyPatternDemo &#123; public static void main(String[] args) &#123; Image image = new ProxyImage(&quot;test_10mb.jpg&quot;); // 图像将从磁盘加载 image.display(); System.out.println(&quot;&quot;); // 图像不需要从磁盘加载 image.display(); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"代理","slug":"代理","permalink":"https://blog.unclezs.com/tags/%E4%BB%A3%E7%90%86/"}]},{"title":"设计模式-装饰器","slug":"Java/设计模式/设计模式-装饰器","date":"2020-08-13T02:30:28.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-装饰器.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E5%99%A8.html","excerpt":"介绍装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component），具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 使用场景： 扩展一个类的功能。 动态增加功能，动态撤销。 JDK中的装饰模式： java.io.BufferedInputStream(InputStream) java.io.DataInputStream(InputStream) java.io.BufferedOutputStream(OutputStream) java.util.zip.ZipOutputStream(OutputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 优缺点及注意优点装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点","text":"介绍装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component），具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 使用场景： 扩展一个类的功能。 动态增加功能，动态撤销。 JDK中的装饰模式： java.io.BufferedInputStream(InputStream) java.io.DataInputStream(InputStream) java.io.BufferedOutputStream(OutputStream) java.util.zip.ZipOutputStream(OutputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 优缺点及注意优点装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点多层装饰比较复杂。 注意可代替继承。 实现public class Person &#123; public void playGame() &#123; System.out.println(&quot;打LOL了&quot;); &#125; &#125; public class PlayGameDecorator &#123; Person person; public void playGame() &#123; System.out.println(&quot;用顶配外星人&quot;); person.playGame(); &#125; public PlayGameDecorator(Person person) &#123; this.person = person; &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; PlayGameDecorator decorator = new PlayGameDecorator(new Person()); decorator.playGame(); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"装饰器","slug":"装饰器","permalink":"https://blog.unclezs.com/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"}]},{"title":"设计模式-适配器","slug":"Java/设计模式/设计模式-适配器","date":"2020-08-13T01:53:29.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-适配器.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8.html","excerpt":"介绍适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 JDK中的适配器模式： java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 优缺点及注意优点 可以让任何两个没有关联的类一起运行。 提高了类的复用。 增加了类的透明度。 灵活性好。 缺点","text":"介绍适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 JDK中的适配器模式： java.util.Arrays#asList() java.util.Collections#list() java.util.Collections#enumeration() javax.xml.bind.annotation.adapters.XMLAdapter 优缺点及注意优点 可以让任何两个没有关联的类一起运行。 提高了类的复用。 增加了类的透明度。 灵活性好。 缺点 过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。 注意事项适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 实现public interface MediaPlayer &#123; public void play(String audioType, String fileName); &#125; public interface AdvancedMediaPlayer &#123; public void playVlc(String fileName); public void playMp4(String fileName); &#125; public class VlcPlayer implements AdvancedMediaPlayer&#123; @Override public void playVlc(String fileName) &#123; System.out.println(&quot;Playing vlc file. Name: &quot;+ fileName); &#125; @Override public void playMp4(String fileName) &#123; //什么也不做 &#125; &#125; public class Mp4Player implements AdvancedMediaPlayer&#123; @Override public void playVlc(String fileName) &#123; //什么也不做 &#125; @Override public void playMp4(String fileName) &#123; System.out.println(&quot;Playing mp4 file. Name: &quot;+ fileName); &#125; &#125; public class MediaAdapter implements MediaPlayer &#123; AdvancedMediaPlayer advancedMusicPlayer; public MediaAdapter(String audioType)&#123; if(audioType.equalsIgnoreCase(&quot;vlc&quot;) )&#123; advancedMusicPlayer = new VlcPlayer(); &#125; else if (audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; advancedMusicPlayer = new Mp4Player(); &#125; &#125; @Override public void play(String audioType, String fileName) &#123; if(audioType.equalsIgnoreCase(&quot;vlc&quot;))&#123; advancedMusicPlayer.playVlc(fileName); &#125;else if(audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; advancedMusicPlayer.playMp4(fileName); &#125; &#125; &#125; public class AudioPlayer implements MediaPlayer &#123; MediaAdapter mediaAdapter; @Override public void play(String audioType, String fileName) &#123; //播放 mp3 音乐文件的内置支持 if(audioType.equalsIgnoreCase(&quot;mp3&quot;))&#123; System.out.println(&quot;Playing mp3 file. Name: &quot;+ fileName); &#125; //mediaAdapter 提供了播放其他文件格式的支持 else if(audioType.equalsIgnoreCase(&quot;vlc&quot;) || audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; mediaAdapter = new MediaAdapter(audioType); mediaAdapter.play(audioType, fileName); &#125; else&#123; System.out.println(&quot;Invalid media. &quot;+ audioType + &quot; format not supported&quot;); &#125; &#125; &#125; public class AdapterPatternDemo &#123; public static void main(String[] args) &#123; AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play(&quot;mp3&quot;, &quot;beyond the horizon.mp3&quot;); audioPlayer.play(&quot;mp4&quot;, &quot;alone.mp4&quot;); audioPlayer.play(&quot;vlc&quot;, &quot;far far away.vlc&quot;); audioPlayer.play(&quot;avi&quot;, &quot;mind me.avi&quot;); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"适配器","slug":"适配器","permalink":"https://blog.unclezs.com/tags/%E9%80%82%E9%85%8D%E5%99%A8/"}]},{"title":"设计模式-观察者","slug":"Java/设计模式/设计模式-观察者","date":"2020-08-12T15:26:36.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-观察者.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%82%E5%AF%9F%E8%80%85.html","excerpt":"介绍当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。 在GUI编程中这个模式很常见，数据更新后视图也会跟着改变比如JavaFX里面的 javafx.collections.ObservableList 优缺点优点： 观察者和被观察者是抽象耦合的。 建立一套触发机制。 缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 注意事项： JAVA 中已经有了对观察者模式的支持类。 避免循环引用。 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。","text":"介绍当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。观察者模式属于行为型模式。 在GUI编程中这个模式很常见，数据更新后视图也会跟着改变比如JavaFX里面的 javafx.collections.ObservableList 优缺点优点： 观察者和被观察者是抽象耦合的。 建立一套触发机制。 缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 注意事项： JAVA 中已经有了对观察者模式的支持类。 避免循环引用。 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。 使用场景 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 实现public interface Observer &#123; void onPriceUpdate(int price); &#125; public class Subject &#123; int price = 10; List&lt;Observer&gt; list = new ArrayList&lt;&gt;(); public int getPrice() &#123; return price; &#125; public void setPrice(int price) &#123; this.price = price; notifyAllObserver(); &#125; private void notifyAllObserver() &#123; for (Observer observer : list) &#123; observer.onPriceUpdate(price); &#125; &#125; public void registerPriceObserver(Observer observer) &#123; list.add(observer); &#125; public void removePriceObserver(Observer o) &#123; list.remove(o); &#125; &#125; public class AppTest &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); subject.registerPriceObserver(System.out::println); subject.registerPriceObserver(o -&gt; System.out.println(&quot;我是2：&quot; + o)); subject.setPrice(3); subject.setPrice(4); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"观察者","slug":"观察者","permalink":"https://blog.unclezs.com/tags/%E8%A7%82%E5%AF%9F%E8%80%85/"}]},{"title":"设计模式-迭代器","slug":"Java/设计模式/设计模式-迭代器","date":"2020-08-12T05:49:59.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-迭代器.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%BF%AD%E4%BB%A3%E5%99%A8.html","excerpt":"介绍迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 迭代器模式属于行为型模式。 在JDK的集合类中都实现了迭代器Iterable接口。java.util.Iteratorjava.util.Enumeration 实现public interface Aggregate &#123; Iterator createIterator(); &#125; public class ConcreteAggregate implements Aggregate &#123; private Integer[] items; public ConcreteAggregate() &#123; items = new Integer[10]; for (int i = 0; i &lt; items.length; i++) &#123; items[i] = i; &#125; &#125; @Override public Iterator createIterator() &#123; return new ConcreteIterator&lt;Integer&gt;(items); &#125; &#125; public interface Iterator&lt;Item&gt; &#123; Item next(); boolean hasNext(); &#125; public class ConcreteIterator&lt;Item&gt; implements Iterator &#123; private Item[] items; private int position = 0; public ConcreteIterator(Item[] items) &#123; this.items = items; &#125; @Override public Object next() &#123; return items[position++]; &#125; @Override public boolean hasNext() &#123; return position &lt; items.length; &#125; &#125; public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new ConcreteAggregate(); Iterator&lt;Integer&gt; iterator = aggregate.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125; &#125;","text":"介绍迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 迭代器模式属于行为型模式。 在JDK的集合类中都实现了迭代器Iterable接口。java.util.Iteratorjava.util.Enumeration 实现public interface Aggregate &#123; Iterator createIterator(); &#125; public class ConcreteAggregate implements Aggregate &#123; private Integer[] items; public ConcreteAggregate() &#123; items = new Integer[10]; for (int i = 0; i &lt; items.length; i++) &#123; items[i] = i; &#125; &#125; @Override public Iterator createIterator() &#123; return new ConcreteIterator&lt;Integer&gt;(items); &#125; &#125; public interface Iterator&lt;Item&gt; &#123; Item next(); boolean hasNext(); &#125; public class ConcreteIterator&lt;Item&gt; implements Iterator &#123; private Item[] items; private int position = 0; public ConcreteIterator(Item[] items) &#123; this.items = items; &#125; @Override public Object next() &#123; return items[position++]; &#125; @Override public boolean hasNext() &#123; return position &lt; items.length; &#125; &#125; public class Client &#123; public static void main(String[] args) &#123; Aggregate aggregate = new ConcreteAggregate(); Iterator&lt;Integer&gt; iterator = aggregate.createIterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"迭代器","slug":"迭代器","permalink":"https://blog.unclezs.com/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"}]},{"title":"设计模式-模板方法","slug":"Java/设计模式/设计模式-模板方法","date":"2020-08-12T01:35:02.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-模板方法.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95.html","excerpt":"介绍在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 主要解决一些方法通用，却在每一个子类都重新写了这一方法。 jdk中使用模板方法的： java.util.Collections#sort() java.io.InputStream#skip() java.io.InputStream#read() java.util.AbstractList#indexOf() 使用场景： 有多个子类共有的方法，且逻辑相同。 重要的、复杂的方法，可以考虑作为模板方法。 优缺点及注意优点 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 3、行为由父类控制，子类实现。","text":"介绍在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 主要解决一些方法通用，却在每一个子类都重新写了这一方法。 jdk中使用模板方法的： java.util.Collections#sort() java.io.InputStream#skip() java.io.InputStream#read() java.util.AbstractList#indexOf() 使用场景： 有多个子类共有的方法，且逻辑相同。 重要的、复杂的方法，可以考虑作为模板方法。 优缺点及注意优点 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 3、行为由父类控制，子类实现。 缺点每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 注意事项为防止恶意操作，一般模板方法都加上 final 关键词。 实现public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125; &#125; public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(&quot;Cricket Game Finished!&quot;); &#125; @Override void initialize() &#123; System.out.println(&quot;Cricket Game Initialized! Start playing.&quot;); &#125; @Override void startPlay() &#123; System.out.println(&quot;Cricket Game Started. Enjoy the game!&quot;); &#125; &#125; public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println(&quot;Football Game Finished!&quot;); &#125; @Override void initialize() &#123; System.out.println(&quot;Football Game Initialized! Start playing.&quot;); &#125; @Override void startPlay() &#123; System.out.println(&quot;Football Game Started. Enjoy the game!&quot;); &#125; &#125; public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"模板方法","slug":"模板方法","permalink":"https://blog.unclezs.com/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/"}]},{"title":"设计模式-原型","slug":"Java/设计模式/设计模式-原型","date":"2020-08-11T05:41:35.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-原型.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%9E%8B.html","excerpt":"介绍原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 JDK的Object.clone()是一实例。 实现public interface ProtoType &#123; ProtoType clone(); &#125; public class ComputerProtoType implements ProtoType &#123; int bigData; public ComputerProtoType(int bigData) &#123; this.bigData = bigData; &#125; @Override public ProtoType clone() &#123; return new ComputerProtoType(bigData); &#125; &#125; public class ProtoTypeTest &#123; public static void main(String[] args) &#123; ComputerProtoType protoType = new ComputerProtoType(1 &lt;&lt; 31); ProtoType clone = protoType.clone(); &#125; &#125;","text":"介绍原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 JDK的Object.clone()是一实例。 实现public interface ProtoType &#123; ProtoType clone(); &#125; public class ComputerProtoType implements ProtoType &#123; int bigData; public ComputerProtoType(int bigData) &#123; this.bigData = bigData; &#125; @Override public ProtoType clone() &#123; return new ComputerProtoType(bigData); &#125; &#125; public class ProtoTypeTest &#123; public static void main(String[] args) &#123; ComputerProtoType protoType = new ComputerProtoType(1 &lt;&lt; 31); ProtoType clone = protoType.clone(); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"原型","slug":"原型","permalink":"https://blog.unclezs.com/tags/%E5%8E%9F%E5%9E%8B/"}]},{"title":"设计模式-生成器","slug":"Java/设计模式/设计模式-生成器","date":"2020-08-11T03:46:18.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-生成器.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%94%9F%E6%88%90%E5%99%A8.html","excerpt":"介绍一个对象的构建和它的表示分离，使得同样的构建过程可以创建不同的表示。 可以用于编译器词法分析器指导生成抽象语法树、构造迷宫等。 和工厂模式不同的是，Builder模式需要详细的指导产品的生产。指导者（Director）使用Construct方法构造产品BuilderProduct，但是它不直接参与构造过程，而是把构造的任务交给生成器（Builder）。Builder提供了产品每一个部件构造的实现方法（可以是默认实现），但是如果要获得最终的产品，需要派生Builder的子类，添加getResult方法返回最终的产品对象。BuildPart方法正是被指导者调用指挥产品生产流程的接口。 在JDK中StringBuilder就是用法的生成器模式。 应用场景 当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时。 当构造过程必须允许被构造的对象有不同的表示时。 生成器模式优点： 优点 将一个复杂对象的创建过程封装起来。这里我们将每一个对象“可能”的创建过程封装在具体生成器实现类中。 允许对象通过多个步骤来创建，并且可以改变过程。这里我们可以通过Client来改变（自由搭配）对象的创建步骤，而不是像其它工厂模式一样只有一个步骤。这也就是定义中提到的同样的创建过程可以创建不同的表示。 向客户隐藏产品的内部实现。（这一点是所有创建型模式都有的） 产品的实现可以被替换，因为客户（注意这里的客户是指调用者）只看到一个抽象的接口。（所有的抽象都是用来干这个事的，呵呵）","text":"介绍一个对象的构建和它的表示分离，使得同样的构建过程可以创建不同的表示。 可以用于编译器词法分析器指导生成抽象语法树、构造迷宫等。 和工厂模式不同的是，Builder模式需要详细的指导产品的生产。指导者（Director）使用Construct方法构造产品BuilderProduct，但是它不直接参与构造过程，而是把构造的任务交给生成器（Builder）。Builder提供了产品每一个部件构造的实现方法（可以是默认实现），但是如果要获得最终的产品，需要派生Builder的子类，添加getResult方法返回最终的产品对象。BuildPart方法正是被指导者调用指挥产品生产流程的接口。 在JDK中StringBuilder就是用法的生成器模式。 应用场景 当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时。 当构造过程必须允许被构造的对象有不同的表示时。 生成器模式优点： 优点 将一个复杂对象的创建过程封装起来。这里我们将每一个对象“可能”的创建过程封装在具体生成器实现类中。 允许对象通过多个步骤来创建，并且可以改变过程。这里我们可以通过Client来改变（自由搭配）对象的创建步骤，而不是像其它工厂模式一样只有一个步骤。这也就是定义中提到的同样的创建过程可以创建不同的表示。 向客户隐藏产品的内部实现。（这一点是所有创建型模式都有的） 产品的实现可以被替换，因为客户（注意这里的客户是指调用者）只看到一个抽象的接口。（所有的抽象都是用来干这个事的，呵呵） 实现public interface Builder &#123; Builder buildBody(String s); Builder buildHead(String s); Builder buildTail(String s); &#125; public class HtmlBuilder implements Builder &#123; @Override public Builder buildBody(String s) &#123; return this; &#125; @Override public Builder buildHead(String s) &#123; return this; &#125; @Override public Builder buildTail(String s) &#123; return this; &#125; &#125; public class TxtBuilder implements Builder &#123; @Override public Builder buildBody(String s) &#123; return this; &#125; @Override public Builder buildHead(String s) &#123; return this; &#125; @Override public Builder buildTail(String s) &#123; return this; &#125; &#125; public class Editer &#123; private Builder builder; public Editer(Builder builder) &#123; this.builder = builder; //do something &#125; &#125; public class BuilderTest &#123; public static void main(String[] args) &#123; new Editer(new TxtBuilder()); new Editer(new HtmlBuilder()); &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"生成器","slug":"生成器","permalink":"https://blog.unclezs.com/tags/%E7%94%9F%E6%88%90%E5%99%A8/"},{"name":"Builder","slug":"Builder","permalink":"https://blog.unclezs.com/tags/Builder/"}]},{"title":"设计模式-工厂","slug":"Java/设计模式/设计模式-工厂","date":"2020-08-11T02:45:19.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-工厂.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82.html","excerpt":"简单工厂(Simple Factory)在创建一个对象时不向客户暴露内部细节，并提供一个创建对象的通用接口。 简单工厂把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化。 这样做能把客户类和具体子类的实现解耦，客户类不再需要知道有哪些子类以及应当实例化哪个子类。客户类往往有多个，如果不使用简单工厂，那么所有的客户类都要知道所有子类的细节。而且一旦子类发生改变，例如增加子类，那么所有的客户类都要进行修改。 public interface Computer &#123; &#125; public class MacComputer implements Computer&#123; &#125; public class WindowsComputer implements Computer&#123; &#125; public class ComputerFactory &#123; public static Computer createComputer(int type) &#123; switch (type) &#123; case 1: return new WindowsComputer(); case 2: return new MacComputer(); default: throw new IllegalArgumentException(&quot;Not Support Type &quot; + type); &#125; &#125; &#125; 工厂方法(Factory Method）定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化操作推迟到子类。 在简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 Calendar类就是采用这种。 public interface Computer &#123; int getSystemType(); &#125; public class MacComputer implements Computer &#123; @Override public int getSystemType() &#123; return 2; &#125; &#125; public class WindowsComputer implements Computer &#123; @Override public int getSystemType() &#123; return 1; &#125; &#125; public abstract class ComputerFactory &#123; public abstract Computer getComputer(); public void printSystemType() &#123; System.out.println(getComputer().getSystemType()); &#125; &#125; public class MacComputerFactory extends ComputerFactory &#123; @Override public Computer getComputer() &#123; return new MacComputer(); &#125; &#125; public class WindowsComputerFactory extends ComputerFactory &#123; @Override public Computer getComputer() &#123; return new WindowsComputer(); &#125; &#125; public class FactoryTest &#123; public static void main(String[] args) &#123; new WindowsComputerFactory().printSystemType(); &#125; &#125;","text":"简单工厂(Simple Factory)在创建一个对象时不向客户暴露内部细节，并提供一个创建对象的通用接口。 简单工厂把实例化的操作单独放到一个类中，这个类就成为简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化。 这样做能把客户类和具体子类的实现解耦，客户类不再需要知道有哪些子类以及应当实例化哪个子类。客户类往往有多个，如果不使用简单工厂，那么所有的客户类都要知道所有子类的细节。而且一旦子类发生改变，例如增加子类，那么所有的客户类都要进行修改。 public interface Computer &#123; &#125; public class MacComputer implements Computer&#123; &#125; public class WindowsComputer implements Computer&#123; &#125; public class ComputerFactory &#123; public static Computer createComputer(int type) &#123; switch (type) &#123; case 1: return new WindowsComputer(); case 2: return new MacComputer(); default: throw new IllegalArgumentException(&quot;Not Support Type &quot; + type); &#125; &#125; &#125; 工厂方法(Factory Method）定义了一个创建对象的接口，但由子类决定要实例化哪个类。工厂方法把实例化操作推迟到子类。 在简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 Calendar类就是采用这种。 public interface Computer &#123; int getSystemType(); &#125; public class MacComputer implements Computer &#123; @Override public int getSystemType() &#123; return 2; &#125; &#125; public class WindowsComputer implements Computer &#123; @Override public int getSystemType() &#123; return 1; &#125; &#125; public abstract class ComputerFactory &#123; public abstract Computer getComputer(); public void printSystemType() &#123; System.out.println(getComputer().getSystemType()); &#125; &#125; public class MacComputerFactory extends ComputerFactory &#123; @Override public Computer getComputer() &#123; return new MacComputer(); &#125; &#125; public class WindowsComputerFactory extends ComputerFactory &#123; @Override public Computer getComputer() &#123; return new WindowsComputer(); &#125; &#125; public class FactoryTest &#123; public static void main(String[] args) &#123; new WindowsComputerFactory().printSystemType(); &#125; &#125; 抽象工厂(Abstract Factory）提供一个接口，用于创建 相关的对象家族 。 抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象，这和抽象工厂模式有很大不同。 抽象工厂模式用到了工厂方法模式来创建单一对象，AbstractFactory 中的 createProductA() 和 createProductB() 方法都是让子类来实现，这两个方法单独来看就是在创建一个对象，这符合工厂方法模式的定义。 至于创建对象的家族这一概念是在 Client 体现，Client 要通过 AbstractFactory 同时调用两个方法来创建出两个对象，在这里这两个对象就有很大的相关性，Client 需要同时创建出这两个对象。 从高层次来看，抽象工厂使用了组合，即 Cilent 组合了 AbstractFactory，而工厂方法模式使用了继承。 public class AbstractProductA &#123; &#125; public class AbstractProductB &#123; &#125; public class ProductA1 extends AbstractProductA &#123; &#125; public class ProductA2 extends AbstractProductA &#123; &#125; public class ProductB1 extends AbstractProductB &#123; &#125; public class ProductB2 extends AbstractProductB &#123; &#125; public abstract class AbstractFactory &#123; abstract AbstractProductA createProductA(); abstract AbstractProductB createProductB(); &#125; public class ConcreteFactory1 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA1(); &#125; AbstractProductB createProductB() &#123; return new ProductB1(); &#125; &#125; public class ConcreteFactory2 extends AbstractFactory &#123; AbstractProductA createProductA() &#123; return new ProductA2(); &#125; AbstractProductB createProductB() &#123; return new ProductB2(); &#125; &#125; public class Client &#123; public static void main(String[] args) &#123; AbstractFactory abstractFactory = new ConcreteFactory1(); AbstractProductA productA = abstractFactory.createProductA(); AbstractProductB productB = abstractFactory.createProductB(); // do something with productA and productB &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"工厂","slug":"工厂","permalink":"https://blog.unclezs.com/tags/%E5%B7%A5%E5%8E%82/"}]},{"title":"LRU算法的Java实现","slug":"算法/LRU算法的Java实现","date":"2020-08-10T04:13:15.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"算法/LRU算法的Java实现.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/LRU%E7%AE%97%E6%B3%95%E7%9A%84Java%E5%AE%9E%E7%8E%B0.html","excerpt":"介绍LRU（Least Recently Used）最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 基于LinkedHashMap实现LinkedHashMap为LRU其实做了一些准备，在构造中提供了一个accessOrder变量，默认false，如果设置为true，get方法会有额外操作保证链表顺序按访问顺序逆序排列。再通过removeEldestEntry方法来限定链表长度，到了最大容量自动删除头部，而头部也是最少被访问的。 /** * @author blog.unclezs.com * @date 2020/8/14 12:16 */ public class LRU&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; int maxCapacity; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return super.size() &gt;= maxCapacity; &#125; public LRU(int maxCapacity) &#123; super(maxCapacity,0.75f,true) this.maxCapacity = maxCapacity; &#125; &#125; 链表+HashMap实现基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下： 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 public class LRU&lt;K, V&gt; implements Iterable&lt;K&gt; &#123; private Node head; private Node tail; private HashMap&lt;K, Node&gt; map; private int maxSize; private class Node &#123; Node pre; Node next; K k; V v; public Node(K k, V v) &#123; this.k = k; this.v = v; &#125; &#125; public LRU(int maxSize) &#123; this.maxSize = maxSize; this.map = new HashMap&lt;&gt;(maxSize * 4 / 3); head = new Node(null, null); tail = new Node(null, null); head.next = tail; tail.pre = head; &#125; public V get(K key) &#123; if (!map.containsKey(key)) &#123; return null; &#125; Node node = map.get(key); unlink(node); appendHead(node); return node.v; &#125; public void put(K key, V value) &#123; if (map.containsKey(key)) &#123; Node node = map.get(key); unlink(node); &#125; Node node = new Node(key, value); map.put(key, node); appendHead(node); if (map.size() &gt; maxSize) &#123; Node toRemove = removeTail(); map.remove(toRemove.k); &#125; &#125; private void unlink(Node node) &#123; Node pre = node.pre; Node next = node.next; pre.next = next; next.pre = pre; node.pre = null; node.next = null; &#125; private void appendHead(Node node) &#123; Node next = head.next; node.next = next; next.pre = node; node.pre = head; head.next = node; &#125; private Node removeTail() &#123; Node node = tail.pre; Node pre = node.pre; tail.pre = pre; pre.next = tail; node.pre = null; node.next = null; return node; &#125; @Override public Iterator&lt;K&gt; iterator() &#123; return new Iterator&lt;K&gt;() &#123; private Node cur = head.next; @Override public boolean hasNext() &#123; return cur != tail; &#125; @Override public K next() &#123; Node node = cur; cur = cur.next; return node.k; &#125; &#125;; &#125; &#125;","text":"介绍LRU（Least Recently Used）最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 基于LinkedHashMap实现LinkedHashMap为LRU其实做了一些准备，在构造中提供了一个accessOrder变量，默认false，如果设置为true，get方法会有额外操作保证链表顺序按访问顺序逆序排列。再通过removeEldestEntry方法来限定链表长度，到了最大容量自动删除头部，而头部也是最少被访问的。 /** * @author blog.unclezs.com * @date 2020/8/14 12:16 */ public class LRU&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; int maxCapacity; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return super.size() &gt;= maxCapacity; &#125; public LRU(int maxCapacity) &#123; super(maxCapacity,0.75f,true) this.maxCapacity = maxCapacity; &#125; &#125; 链表+HashMap实现基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下： 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 public class LRU&lt;K, V&gt; implements Iterable&lt;K&gt; &#123; private Node head; private Node tail; private HashMap&lt;K, Node&gt; map; private int maxSize; private class Node &#123; Node pre; Node next; K k; V v; public Node(K k, V v) &#123; this.k = k; this.v = v; &#125; &#125; public LRU(int maxSize) &#123; this.maxSize = maxSize; this.map = new HashMap&lt;&gt;(maxSize * 4 / 3); head = new Node(null, null); tail = new Node(null, null); head.next = tail; tail.pre = head; &#125; public V get(K key) &#123; if (!map.containsKey(key)) &#123; return null; &#125; Node node = map.get(key); unlink(node); appendHead(node); return node.v; &#125; public void put(K key, V value) &#123; if (map.containsKey(key)) &#123; Node node = map.get(key); unlink(node); &#125; Node node = new Node(key, value); map.put(key, node); appendHead(node); if (map.size() &gt; maxSize) &#123; Node toRemove = removeTail(); map.remove(toRemove.k); &#125; &#125; private void unlink(Node node) &#123; Node pre = node.pre; Node next = node.next; pre.next = next; next.pre = pre; node.pre = null; node.next = null; &#125; private void appendHead(Node node) &#123; Node next = head.next; node.next = next; next.pre = node; node.pre = head; head.next = node; &#125; private Node removeTail() &#123; Node node = tail.pre; Node pre = node.pre; tail.pre = pre; pre.next = tail; node.pre = null; node.next = null; return node; &#125; @Override public Iterator&lt;K&gt; iterator() &#123; return new Iterator&lt;K&gt;() &#123; private Node cur = head.next; @Override public boolean hasNext() &#123; return cur != tail; &#125; @Override public K next() &#123; Node node = cur; cur = cur.next; return node.k; &#125; &#125;; &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"缓存穿透、击穿、雪崩问题及解决方案","slug":"数据库/redis/缓存穿透、击穿、雪崩问题及解决方案","date":"2020-08-10T01:08:44.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/redis/缓存穿透、击穿、雪崩问题及解决方案.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html","excerpt":"缓存穿透介绍缓存穿透是指请求的数据在缓存中没有，并且数据库里面也没有。比如用户请求一个不存在的数据的时候，比如ID为-1之类的，这个时候就会直接访问数据库，如果用户是攻击者，这也就会导致数据库压力过大。 解决 存一个空值的缓存，比如-1，就存个（-1，NULL）到缓存，这样就不会到达数据库了，但是注意缓存时间不能太长，免得影响正常业务。 对这类请求进行过滤。比如对接口增加权限鉴定之类的。 缓存击穿介绍缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决 设置热点数据永远不过期。 加互斥锁，保证不会有多个请求去刷新缓存，保证缓存key只被一个请求更新","text":"缓存穿透介绍缓存穿透是指请求的数据在缓存中没有，并且数据库里面也没有。比如用户请求一个不存在的数据的时候，比如ID为-1之类的，这个时候就会直接访问数据库，如果用户是攻击者，这也就会导致数据库压力过大。 解决 存一个空值的缓存，比如-1，就存个（-1，NULL）到缓存，这样就不会到达数据库了，但是注意缓存时间不能太长，免得影响正常业务。 对这类请求进行过滤。比如对接口增加权限鉴定之类的。 缓存击穿介绍缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决 设置热点数据永远不过期。 加互斥锁，保证不会有多个请求去刷新缓存，保证缓存key只被一个请求更新 缓存雪崩介绍指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。 在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。 解决 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://blog.unclezs.com/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"MySQL之Gap Locks与Next-key Locks","slug":"数据库/mysql/MySQL之Gap-Locks与Next-key-Locks","date":"2020-08-09T12:29:48.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySQL之Gap-Locks与Next-key-Locks.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E4%B9%8BGap-Locks%E4%B8%8ENext-key-Locks.html","excerpt":"介绍Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。而Next-Key就是行锁+Gap锁的组合。 InnoBD的三种行级锁 Record Lock：锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks依然可以使用。 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock：1、2组合，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 Gap LockGap Lock，又称为间隙锁。存在的主要目的就是为了防止在可重复读的事务级别下，出现幻读问题。 在可重复读的事务级别下面，普通的select读的是快照，不存在幻读情况，但是如果加上for update的话，读取是已提交事务数据，gap锁保证for update情况下，不出现幻读。 以下都是在可重读隔离级别情况下。 test表如下：","text":"介绍Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。而Next-Key就是行锁+Gap锁的组合。 InnoBD的三种行级锁 Record Lock：锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks依然可以使用。 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock：1、2组合，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 Gap LockGap Lock，又称为间隙锁。存在的主要目的就是为了防止在可重复读的事务级别下，出现幻读问题。 在可重复读的事务级别下面，普通的select读的是快照，不存在幻读情况，但是如果加上for update的话，读取是已提交事务数据，gap锁保证for update情况下，不出现幻读。 以下都是在可重读隔离级别情况下。 test表如下： id value a 1 d 3 g 6 j 8 其中id是主键，value是非唯一索引 # T1 select * from test where num=6 for update; # T2 insert into test (id, value) VALUES (&#x27;a&#x27;, 3); T1这样的操作会锁定（3,6]，(6,8]，但是会发现插入操作依旧可以成功，因为虽然Value的区间是锁住了，但是根据id=‘a’这一条让排序在a前面去了 总的来说，锁的间隙是根据B+树排序后的叶子节点之间的区间，不但要看非索引，也会看主键。 假如是非索引列，那么将会全表间隙加上gap锁。 条件是唯一索引等值检索且记录不存在的情况，我们要考虑，gap lock是防止幻读，那么尝试思考，使用唯一索引所谓条件查找数据for update，如果对应的记录不存在的话，是无法使用行锁的。这时候，会使用gap lock来锁住区间，保证记录不会插入，防止出现幻读。 总结Next-Locks就是结合行锁和间隙锁进行的，主要是用于MVCC出现幻读的情况。 参考 深入了解mysql–gap locks,Next-Key Locks Innodb锁机制：Next-Key Lock 浅谈","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"Next-Key","slug":"Next-Key","permalink":"https://blog.unclezs.com/tags/Next-Key/"},{"name":"间隙锁","slug":"间隙锁","permalink":"https://blog.unclezs.com/tags/%E9%97%B4%E9%9A%99%E9%94%81/"},{"name":"幻读","slug":"幻读","permalink":"https://blog.unclezs.com/tags/%E5%B9%BB%E8%AF%BB/"}]},{"title":"数据库之事务与实现原理","slug":"数据库/mysql/数据库之事务与实现原理","date":"2020-08-08T10:53:23.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/数据库之事务与实现原理.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html","excerpt":"为什么需要事务典型的就是转账问题了，转账是生活中常见的操作，比如从A账户转账100元到B账号。站在用户角度而言,这是一个逻辑上的单一操作，然而在数据库系统中，至少会分成两个步骤来完成: 将A账户的金额减少100元 将B账户的金额增加100元。 这个时候可能会出现问题： 转账操作的第一步执行成功,A账户上的钱减少了100元,但是第二步执行失败或者未执行便发生系统崩溃,导致B账户并没有相应增加100元。 转账操作刚完成就发生系统崩溃,系统重启恢复时丢失了崩溃前的转账记录。 同时又另一个用户转账给B账户，由于同时对B账户进行操作，导致B账户金额出现异常。 什么是数据库事务事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 BEGIN TRANSACTION //事务开始 SQL1 SQL2 COMMIT/ROLLBACK //事务提交或回滚 ACID原子性（Atomicity）","text":"为什么需要事务典型的就是转账问题了，转账是生活中常见的操作，比如从A账户转账100元到B账号。站在用户角度而言,这是一个逻辑上的单一操作，然而在数据库系统中，至少会分成两个步骤来完成: 将A账户的金额减少100元 将B账户的金额增加100元。 这个时候可能会出现问题： 转账操作的第一步执行成功,A账户上的钱减少了100元,但是第二步执行失败或者未执行便发生系统崩溃,导致B账户并没有相应增加100元。 转账操作刚完成就发生系统崩溃,系统重启恢复时丢失了崩溃前的转账记录。 同时又另一个用户转账给B账户，由于同时对B账户进行操作，导致B账户金额出现异常。 什么是数据库事务事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 BEGIN TRANSACTION //事务开始 SQL1 SQL2 COMMIT/ROLLBACK //事务提交或回滚 ACID原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。并发执行的事务不会相互影响，其对数据库的影响和它们串行执行时一样。比如多个用户同时往一个账户转账，最后账户的结果应该和他们按先后次序转账的结果一样。 持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。使用重做日志来保证持久性。 事务中的ACID事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失更新丢失更新是指事务覆盖了其他事务对数据的已提交修改,导致这些修改好像丢失了一样。 T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。 脏读脏读是指一个事务读取了另一个事务未提交的数据，在事务1对A的处理过程中,事务2读取了A的值,但之后事务1回滚,导致事务2读取的A是未提交的脏数据。 脏写脏写是指事务回滚了其他事务对数据项的已提交修改,比如下面这种情况，在事务1对数据A的回滚,导致事务2对A的已提交修改也被回滚了。 不可重读读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。事务的隔离级别越低,可能出现的并发异常越多,但是通常而言系统能提供的并发能力越强。 事务的隔离级别事务具有隔离性，理论上来说事务之间的执行不应该相互产生影响,其对数据库的影响应该和它们串行执行时一样。然而完全的隔离性会导致系统并发性能很低，降低对资源的利用率，因而实际上对隔离性的要求会有所放宽，这也会一定程度造成对数据库一致性要求降低。 SQL标准为事务定义了不同的隔离级别,从低到高依次是： 读未提交(READ UNCOMMITTED) 读已提交(READ COMMITTED) 可重复读(REPEATABLE READ) 串行化(SERIALIZABLE) 读未提交(READ UNCOMMITTED)事务中的修改，即使没有提交，对其它事务也是可见的。 读已提交(READ COMMITTED)一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读(REPEATABLE READ)保证在同一个事务中多次读取同样数据的结果是一样的。 串行化(SERIALIZABLE)强制事务串行执行。需要加锁实现，而其它隔离级别通常不需要。 MySQL中的事务隔离级别的操作#查询隔离级别 SELECT @@transaction_isolation SHOW variables like &#x27;%transaction_isolation%&#x27;; #设置隔离级别 SET transaction_isolation=&#x27;READ-UNCOMMITTED&#x27;;#读未提交 SET transaction_isolation=&#x27;READ-COMMITTED&#x27;;#读已提交 SET transaction_isolation=&#x27;REPEATABLE-READ&#x27;;#可重复读 SET transaction_isolation=&#x27;SERIALIZABLE&#x27;;#串行化 事务隔离级别的实现-并发控制技术并发控制技术是实现事务隔离性的关键，实现方式有多种，并发控制策略可以分为两类： 乐观并发控制：对于并发执行可能冲突的操作，假定其不会真的冲突，允许并发执行，直到真正发生冲突时才去解决冲突，比如让事务回滚。 悲观并发控制：对于并发执行可能冲突的操作，假定其必定发生冲突，通过让事务等待(锁)或者中止(时间戳排序)的方式使并行的操作串行执行。 基于封锁的并发控制封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 锁的种类1.读写锁 排它锁（Exclusive），简写为 X 锁，又称写锁。加了X锁，其他事务什么锁都不能加。 共享锁（Shared），简写为 S 锁，又称读锁。加了S锁其他事务可以加S锁，不能加X锁。 2.意向锁（Intention Locks） 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 各种锁的兼容关系如下： - X IX S IS X × × × × IX × √ × √ S × √ √ √ IS × √ √ √ 解释如下： 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 三级锁与两段锁协议三级封锁协议三级封锁协议就是对锁使用的规定，来解决事务并发一致性问题。 a.一级封锁-解决丢失更新 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失更新问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 b.二级封锁-解决脏读 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 c.三级封锁-解决不可重复读 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 两段锁协议加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) MySQL隐式与显示锁定MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： SELECT ... LOCK In SHARE MODE; #S锁 SELECT ... FOR UPDATE; #X锁 基于时间戳的并发控制核心思想：对于并发可能冲突的操作，基于时间戳排序规则选定某事务继续执行,其他事务回滚。 系统会在每个事务开始时赋予其一个时间戳,这个时间戳可以是系统时钟也可以是一个不断累加的计数器值,当事务回滚时会为其赋予一个新的时间戳，先开始的事务时间戳小于后开始事务的时间戳。 每一个数据项Q有两个时间戳相关的字段:W-timestamp(Q):成功执行write(Q)的所有事务的最大时间戳R-timestamp(Q):成功执行read(Q)的所有事务的最大时间戳 具体排序方式就是： 假设事务T发出read(Q),T的时间戳为TS a. 若TS(T)&lt;W-timestamp(Q),则T需要读入的Q已被覆盖。此 read操作将被拒绝,T回滚。 b. 若TS(T)&gt;=W-timestamp(Q),则执行read操作,同时把 R-timestamp(Q)设置为TS(T)与R-timestamp(Q)中的最大值 假设事务T发出write(Q) a.若TS(T)&lt;R-timestamp(Q),write操作被拒绝,T回滚。 b.若TS(T)&lt;W-timestamp(Q),则write操作被拒绝,T回滚。 c.其他情况:系统执行write操作,将W-timestamp(Q)设置 为TS(T)。 基于时间戳排序和基于锁实现的本质一样:对于可能冲突的并发操作,以串行的方式取代并发执行,因而它也是一种悲观并发控制。它们的区别主要有两点: 基于锁是让冲突的事务进行等待，而基于时间戳排序是让冲突的事务回滚。 基于锁冲突事务的执行次序是根据它们申请锁的顺序,先申请的先执行;而基于时间戳排序是根据特定的时间戳排序规则。 基于有效性检查的并发控制核心思想：事务对数据的更新首先在自己的工作空间进行，等到要写回数据库时才进行有效性检查，对不符合要求的事务进行回滚。 基于有效性检查的事务执行过程会被分为三个阶段: 读阶段： 数据项被读入并保存在事务的局部变量中。所有write操作都是对局部变量进行，并不对数据库进行真正的更新。 有效性检查阶段： 对事务进行有效性检查，判断是否可以执行write操作而不违反可串行性。如果失败，则回滚该事务。 写阶段： 事务已通过有效性检查，则将临时变量中的结果更新到数据库中。 有效性检查通常也是通过对事务的时间戳进行比较完成的，不过和基于时间戳排序的规则不一样。 该方法允许可能冲突的操作并发执行,因为每个事务操作的都是自己工作空间的局部变量,直到有效性检查阶段发现了冲突才回滚。因而这是一种乐观的并发策略。 基于多版本并发控制（MVCC）与快照隔离什么是MVCC多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 可以认为MVCC是行级锁的一个变种，但是在很多情况下又避免了加锁，所以效率比较高。 MySQL的InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列实现： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 其中系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。事务版本号：事务开始时的系统版本号。 MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程以下实现过程针对可重复读隔离级别。 当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号，理解这一点很关键。数据行快照的创建版本号是创建数据行快照时的系统版本号，系统版本号随着创建事务而递增，因此新创建一个事务时，这个事务的系统版本号比之前的系统版本号都大，也就是比所有数据行快照的创建版本号都大。 1.SELECT ①只查找版本早于当前事务版本的数据行（行的系统版本号小于等于事务的系统版本号），这样可以保证要么数据行是之前存在的，要么就是自己这个事务自己修改的。 ②查找行的删除版本号要么大于当前事务版本号，要么未定义。这样可以保证这个数据行没有被删除的。 2.INSERT 将当前系统版本号作为数据行快照的创建版本号。 3.DELETE 将当前系统版本号作为数据行快照的删除版本号。 4.UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读1.快照读 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 select * from table ...; 2.当前读读取的是最新的数据，不去读快照，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert; update; delete; 参考 数据库系统原理 数据库事务的概念及其实现原理 MVCC多版本并发控制","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"锁","slug":"锁","permalink":"https://blog.unclezs.com/tags/%E9%94%81/"},{"name":"ACID","slug":"ACID","permalink":"https://blog.unclezs.com/tags/ACID/"},{"name":"MVCC","slug":"MVCC","permalink":"https://blog.unclezs.com/tags/MVCC/"},{"name":"事务","slug":"事务","permalink":"https://blog.unclezs.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"MySQL的字符集与校对规则","slug":"数据库/mysql/MySQL的字符集与校对规则","date":"2020-08-04T11:24:25.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySQL的字符集与校对规则.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E7%9A%84%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B8%8E%E6%A0%A1%E5%AF%B9%E8%A7%84%E5%88%99.html","excerpt":"什么是字符集与校对规则字符集指的是⼀种从⼆进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每⼀种字符集都会对应⼀系列的校对规则。 MySQL采⽤的是类似继承的⽅式指定字符集的默认值，每个数据库以及每张数据表都有⾃⼰的默认值，他们逐层继承。⽐如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采⽤默认字符集） 字符集(Character set)是多个字符(英文字符，汉字字符，或者其他国家语言字符)的集合，字符集种类较多，每个字符集包含的字符个数不同。 特点： 字符编码方式是用一个或多个字节表示字符集中的一个字符 每种字符集都有自己特有的编码方式，因此同一个字符，在不同字符集的编码方式下，会产生不同的二进制 常见字符集： ASCII字符集：基于罗马字母表的一套字符集，它采用1个字节的低7位表示字符，高位始终为0。 LATIN1字符集：相对于ASCII字符集做了扩展，仍然使用一个字节表示字符，但启用了高位，扩展了字符集的表示范围。 GBK字符集：支持中文，字符有一字节编码和两字节编码方式。 UTF8字符集：Unicode字符集的一种，是计算机科学领域里的一项业界标准，支持了所有国家的文字字符，utf8采用1-4个字节表示字符。 MySQL的字符集","text":"什么是字符集与校对规则字符集指的是⼀种从⼆进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每⼀种字符集都会对应⼀系列的校对规则。 MySQL采⽤的是类似继承的⽅式指定字符集的默认值，每个数据库以及每张数据表都有⾃⼰的默认值，他们逐层继承。⽐如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采⽤默认字符集） 字符集(Character set)是多个字符(英文字符，汉字字符，或者其他国家语言字符)的集合，字符集种类较多，每个字符集包含的字符个数不同。 特点： 字符编码方式是用一个或多个字节表示字符集中的一个字符 每种字符集都有自己特有的编码方式，因此同一个字符，在不同字符集的编码方式下，会产生不同的二进制 常见字符集： ASCII字符集：基于罗马字母表的一套字符集，它采用1个字节的低7位表示字符，高位始终为0。 LATIN1字符集：相对于ASCII字符集做了扩展，仍然使用一个字节表示字符，但启用了高位，扩展了字符集的表示范围。 GBK字符集：支持中文，字符有一字节编码和两字节编码方式。 UTF8字符集：Unicode字符集的一种，是计算机科学领域里的一项业界标准，支持了所有国家的文字字符，utf8采用1-4个字节表示字符。 MySQL的字符集查看字符编码支持 # 查看当前库 show variables like &quot;charcter_set%&quot;; # 查看所有支持的 show character set; 各种字符集的作用 字符编码转换原理问：若character_set_client为UTF8，而character_set_database为GBK，则会出现需要进行编码转换的情况，字符集转换的原理是什么？ 答：假设gbk字符集的字符串“你好”，需要转为utf8字符集存储，实际就是对于“你好”字符串中的每个汉字去utf8编码表里面查询对应的二进制，然后存储。 MySQL Server收到请求时将请求数据从character_set_client转换为character_set_connection; 进行内部操作前将请求数据从character_set_connection转换为内部操作字符集，确定内部操作字符集步骤： 使用每个数据字段的CHARACTER SET设定值； 若上述值不存在，则使用对应数据表的DEFAULT CHARACTER SET设定值； 若上述值不存在，则使用对应数据库的DEFAULT CHARACTER SET设定值； 若上述值不存在，则使用character_set_server设定值； 将操作结果从内部操作字符集转换为character_set_results。 正确使用字符集 对于insert来说，character_set_client、character_set_connection相同，而且正确反映客户端使用的字符集 对于select来说，character_set_results正确反映客户端字符集 数据库字符集取决于我们要存储的字符类型 字符集转换最多发生一次，这就要求character_set_client、character_set_connection相同 所有的字符集转换都发生在数据库端 修改MySQL的字符集#设置所有字符集 set names &#x27;utf8&#x27;; #修改数据库字符集 alter database database_name character set &quot;utf8&quot;; #只修改表的字符集，影响后续该表新增列的默认定义，已有列的字符集不受影响。 alter table table_name character set xxx； #同时修改表字符集和已有列字符集，并将已有数据进行字符集编码转换。 alter table table_name convert to character set xxx; #修改列字符集 alter table table_name modify col_name varchar(col_length) character set xxx; 总结 建立数据库的时候注意字符集（gbk、utf8）； 连接数据库以后，无论是执行dml还是select，只要涉及到varchar、char列，就需要设置正确的字符集参数。 校对规则collation校对概念校对规则是在字符集内用于字符比较和排序的一套规则，比如有的规则区分大小写，有的则无视。 校对规则特征： 两个不同的字符集不能有相同的校对规则； 每个字符集有一个默认校对规则； 存在校对规则命名约定：以其相关的字符集名开始，中间包括一个语言名，并且以_ci（大小写不敏感）、_cs（大小写敏感）或_bin（二元）结束。 查看MySQL的校对规则#查看支持的校对规则 show collation; # 查看当前的库校对规则 show variables like &#x27;collation_%&#x27;;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"},{"name":"字符集","slug":"字符集","permalink":"https://blog.unclezs.com/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"}]},{"title":"MySQL的索引","slug":"数据库/mysql/MySQL的索引","date":"2020-08-03T02:11:56.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySQL的索引.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95.html","excerpt":"索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 索引目的索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ 索引的优点： 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 各类索引B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 聚簇索引","text":"索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 索引目的索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？ 索引的优点： 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 各类索引B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 聚簇索引InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 非聚簇索引MyISAM索引文件和数据文件是分离的，索引文件的data域保存记录所在页的地址（物理存储位置），通过这些地址来读取页，进而读取被索引的行数据。 对于二级索引，在 MyISAM存储引擎中以与上图同样的方式实现，也就是主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 B+树介绍 浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 B+树查找过程如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 b+树性质1.通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 2.当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 哈希索引哈希索引的实现方式就是通过散列表的方式实现的，能以 O(1) 时间进行查找，但是失去了有序性： 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引，但是对中文支持不是很好。 空间数据索引MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 索引的优化独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引： SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 多列索引（联合索引）在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引（联合索引）。 SELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1; 索引列的顺序让选择性最强的索引列放在前面。 索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; # 查到 staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 前缀索引对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 前缀长度的选取需要根据索引选择性来确定。 覆盖索引索引包含所有需要查询的字段的值。即是查的字段全是索引。 具有以下优点： 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统 I/O 调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的正确使用方式 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://blog.unclezs.com/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"MyISAM和InnoDB引擎区别","slug":"数据库/mysql/MyISAM和InnoDB引擎区别","date":"2020-08-02T09:37:37.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MyISAM和InnoDB引擎区别.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MyISAM%E5%92%8CInnoDB%E5%BC%95%E6%93%8E%E5%8C%BA%E5%88%AB.html","excerpt":"MySql支持的引擎通过命令查看 show engines; 可以看到（8.0版本）是只有InnoDB 是事务性存储引擎，也就是说只有 InnoDB ⽀持事务。 MyISAM和InnoDB区别MySQL 5.5版之前，MyISAM是MySQL的默认数据库引擎。虽然性能极佳，⽽且提供了⼤量的特性，包括全⽂索引、压缩、空间函数等，但MyISAM不⽀持事务和⾏级锁，⽽且最⼤的缺陷就是崩溃后⽆法安全恢复。不过，5.5版本之后，MySQL引⼊了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。 ⼤多数时候我们使⽤的都是 InnoDB 存储引擎，但是在某些情况下使⽤ MyISAM 也是合适的⽐如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。 事务和外键 InnoDB具有事务，支持4个事务隔离级别，回滚，崩溃修复能力和多版本并发的事务安全，包括ACID。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能 MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择","text":"MySql支持的引擎通过命令查看 show engines; 可以看到（8.0版本）是只有InnoDB 是事务性存储引擎，也就是说只有 InnoDB ⽀持事务。 MyISAM和InnoDB区别MySQL 5.5版之前，MyISAM是MySQL的默认数据库引擎。虽然性能极佳，⽽且提供了⼤量的特性，包括全⽂索引、压缩、空间函数等，但MyISAM不⽀持事务和⾏级锁，⽽且最⼤的缺陷就是崩溃后⽆法安全恢复。不过，5.5版本之后，MySQL引⼊了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。 ⼤多数时候我们使⽤的都是 InnoDB 存储引擎，但是在某些情况下使⽤ MyISAM 也是合适的⽐如读密集的情况下。（如果你不介意 MyISAM 崩溃恢复问题的话）。 事务和外键 InnoDB具有事务，支持4个事务隔离级别，回滚，崩溃修复能力和多版本并发的事务安全，包括ACID。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能 MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的SELECT查询，那么MyISAM是更好的选择 全文索引Innodb不支持全文索引，如果一定要用的话，最好使用sphinx等搜索引擎。MyISAM对中文支持的不是很好，不过5.6.4版本以后的Innodb已经支持了 锁 MyISAM 只支持表级锁 Innodb 支持表级锁，行级锁（默认） 存储 InnoDB，基于磁盘的资源是InnoDB表空间数据文件和它的日志文件，InnoDB 表的大小只受限于操作系统文件的大小 MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型， .sdi文件存储表定义，数据文件的扩展名为.MYD， 索引文件的扩展名是.MYI 索引 MyISAM（堆组织表）使用的是非聚簇索引、索引和文件分开，随机存储，只能缓存索引 InnoDB（索引组织表）使用的聚簇索引、索引就是数据，顺序存储，因此能缓存索引，也能缓存数据 并发 MyISAM读写互相阻塞：不仅会在写入的时候阻塞读取，MyISAM还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读 InnoDB 读写阻塞与事务隔离级别相关 其他 是否⽀持事务和崩溃后的安全恢复： MyISAM 强调的是性能，每次查询具有原⼦性,其执⾏速度⽐InnoDB类型更快，但是不提供事务⽀持。但是InnoDB 提供事务⽀持事务，外部键等⾼级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能⼒(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。 是否⽀持外键： MyISAM不⽀持，⽽InnoDB⽀持。 是否⽀持MVCC ：仅 InnoDB ⽀持。应对⾼并发事务，MVCC ( Multi-Version Concurrency Control )（多版本并发控制）⽐单纯的加锁更⾼效；MVCC只在READ COMMITTED 和 REPEATABLE READ 两个隔离级别下⼯作；MVCC可以使⽤ 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现；各数据库中MVCC实现并不统⼀。 为什么MyISAM会比Innodb的查询速度快《MySQL⾼性能》上⾯有⼀句话这样写到: 不要轻易相信“MyISAM⽐InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是⽤到了聚簇索引，或者需要访问的数据都可以放⼊内存的应⽤。 InnoDB 在做SELECT的时候，要维护的东西比MYISAM引擎多很多； InnoDB 要缓存数据和索引，MyISAM只缓存索引块，这中间还有换进换出的减少 innodb寻址要映射到块，再到行，MyISAM记录的直接是文件的OFFSET，定位比INNODB要快 InnoDB 还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护 InnoDB ：通过为每一行记录添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。但是InnoDB并不存储这些事件发生时的实际时间，相反它只存储这些事件发生时的系统版本号。这是一个随着事务的创建而不断增长的数字。每个事务在事务开始时会记录它自己的系统版本号。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。让我们来看看当隔离级别是REPEATABLE READ时这种策略是如何应用到特定的操作的 SELECT InnoDB必须每行数据来保证它符合两个条件 InnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的时候，这行数据是存在的。 这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前这行数据没有被删除。 ⼀般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能⼒和并发能⼒，也不需要事务⽀持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是⼀个不错的选择。但是⼀般情况下，我们都是需要考虑到这些问题的。 参考mysql中innodb和myisam对比及索引原理区别","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"存储引擎","slug":"存储引擎","permalink":"https://blog.unclezs.com/tags/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"}]},{"title":"操作系统之虚拟内存","slug":"操作系统/操作系统之虚拟内存","date":"2020-08-02T07:55:39.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"操作系统/操作系统之虚拟内存.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98.html","excerpt":"概述为了更加有效地管理内存并减少出错，现代操作系统提供了一种对主存的抽象概念，即是虚拟内存（Virtual Memory）。虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间） 理解不深刻的人会认为虚拟内存只是“使用硬盘空间来扩展内存“的技术，这是不对的。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，使得程序的编写难度降低。并且，把内存扩展到硬盘空间只是使用虚拟内存的必然结果，虚拟内存空间会存在硬盘中，并且会被内存缓存（按需），有的操作系统还会在内存不够的情况下，将某一进程的内存全部放入硬盘空间中，并在切换到该进程时再从硬盘读取（这也是为什么Windows会经常假死的原因…）。 虚拟内存主要提供了如下三个重要的能力： 它把主存看作为一个存储在硬盘上的虚拟地址空间的高速缓存，并且只在主存中缓存活动区域（按需缓存）。 它为每个进程提供了一个一致的地址空间，从而降低了程序员对内存管理的复杂性。 它还保护了每个进程的地址空间不会被其他进程破坏。 局部性原理要想更好地理解虚拟内存技术，必须要知道计算机中著名的局部性原理。另外，局部性原理既适⽤于程序结构，也适⽤于数据结构，是⾮常重要的⼀个概念。 局部性原理是虚拟内存技术的基础，正是因为程序运⾏具有局部性原理，才可以只装⼊部分程序到内存就开始运⾏。 早在 1968 年的时候，就有⼈指出我们的程序在执⾏的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执⾏局限于某⼀⼩部分，程序访问的存储空间也局限于某个区域。 局部性原理表现在以下两个⽅⾯：","text":"概述为了更加有效地管理内存并减少出错，现代操作系统提供了一种对主存的抽象概念，即是虚拟内存（Virtual Memory）。虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间） 理解不深刻的人会认为虚拟内存只是“使用硬盘空间来扩展内存“的技术，这是不对的。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，使得程序的编写难度降低。并且，把内存扩展到硬盘空间只是使用虚拟内存的必然结果，虚拟内存空间会存在硬盘中，并且会被内存缓存（按需），有的操作系统还会在内存不够的情况下，将某一进程的内存全部放入硬盘空间中，并在切换到该进程时再从硬盘读取（这也是为什么Windows会经常假死的原因…）。 虚拟内存主要提供了如下三个重要的能力： 它把主存看作为一个存储在硬盘上的虚拟地址空间的高速缓存，并且只在主存中缓存活动区域（按需缓存）。 它为每个进程提供了一个一致的地址空间，从而降低了程序员对内存管理的复杂性。 它还保护了每个进程的地址空间不会被其他进程破坏。 局部性原理要想更好地理解虚拟内存技术，必须要知道计算机中著名的局部性原理。另外，局部性原理既适⽤于程序结构，也适⽤于数据结构，是⾮常重要的⼀个概念。 局部性原理是虚拟内存技术的基础，正是因为程序运⾏具有局部性原理，才可以只装⼊部分程序到内存就开始运⾏。 早在 1968 年的时候，就有⼈指出我们的程序在执⾏的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执⾏局限于某⼀⼩部分，程序访问的存储空间也局限于某个区域。 局部性原理表现在以下两个⽅⾯： 时间局部性 ：如果程序中的某条指令⼀旦执⾏，不久以后该指令可能再次执⾏；如果某数据被访问过，不久以后该数据可能再次被访问。产⽣时间局部性的典型原因，是由于在程序中存在着⼤量的循环操作。 空间局部性 ：⼀旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在⼀段时间内所访问的地址，可能集中在⼀定的范围之内，这是因为指令通常是顺序存放、顺序执⾏的，数据也⼀般是以向量、数组、表等形式簇聚存储的。时间局部性是通过将近来使⽤的指令和数据保存到⾼速缓存存储器中，并使⽤⾼速缓存的层次结构实现。空间局部性通常是使⽤较⼤的⾼速缓存，并将预取机制集成到⾼速缓存控制逻辑中实现。虚拟内存技术实际上就是建⽴了 “内存⼀外存”的两级存储器的结构，利⽤局部性原理实现髙速缓存。 虚拟存储器基于局部性原理，在程序装⼊时，可以将程序的⼀部分装⼊内存，⽽将其他部分留在外存，就可以启动程序执⾏。由于外存往往⽐内存⼤很多，所以我们运⾏的软件的内存⼤⼩实际上是可以⽐计算机系统实际的内存⼤⼩⼤的。在程序执⾏过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调⼊内存，然后继续执⾏程序。另⼀⽅⾯，操作系统将内存中暂时不使⽤的内容换到外存上，从⽽腾出空间存放将要调⼊内存的信息。这样，计算机好像为⽤户提供了⼀个⽐实际内存⼤的多的存储器——虚拟存储器。 实际上，我觉得虚拟内存同样是⼀种时间换空间的策略，你⽤ CPU 的计算时间，⻚的调⼊调出花费的时间，换来了⼀个虚拟的更⼤的空间来⽀持程序的运⾏。不得不感叹，程序世界⼏乎不是时间换空间就是空间换时间。 推荐阅读王道考研操作系统知识点整理 虚拟内存的技术实现虚拟内存的实现需要建⽴在离散分配的内存管理⽅式的基础上。 虚拟内存的实现有三种⽅式：请求分页储存管理，请求分段储存管理，请求段页式存储管理。 请求分页储存管理建⽴在分⻚管理之上，为了⽀持虚拟存储器功能⽽增加了请求调⻚功能和⻚⾯置换功能。请求分⻚是⽬前最常⽤的⼀种实现虚拟存储器的⽅法。请求分⻚存储管理系统中，在作业开始运⾏之前，仅装⼊当前要执⾏的部分段即可运⾏。假如在作业运⾏的过程中发现要访问的⻚⾯不在内存，则由处理器通知操作系统按照对应的⻚⾯置换算法将相应的⻚⾯调⼊到主存，同时操作系统也可以将暂时不⽤的⻚⾯置换到外存中。 请求分段储存管理建⽴在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理⽅式就如同请求分⻚储存管理⽅式⼀样，在作业开始运⾏之前，仅装⼊当前要执⾏的部分段即可运⾏；在执⾏过程中，可使⽤请求调⼊中断动态装⼊要访问但⼜不在内存的程序段；当内存空间已满，⽽⼜需要装⼊新的段时，根据置换功能适当调出某个段，以便腾出空间⽽装⼊新的段。 请求段页式存储管理请求段页式管理方式只要求将作业若干页或段装入内存就可以开始运行作业，作业的其他部分别放在外存中，等待运行需要的时候才被调入内存， 请求段页式管理方式要求相对程序按逻辑意义分段后再分页，所以相对于请求页式管理方式能够方便用户使用，便于共享、保护和动态链接。进程在启动的时候采取与装入模式，则可以根据段的意义装入某些进程运行开始阶段所需要的段。 ⻚⾯置换算法地址映射过程中，若在⻚⾯中发现所要访问的⻚⾯不在内存中，则发⽣缺⻚中断 。 缺⻚中断 就是要访问的⻚不在主存，需要操作系统将其调⼊主存后再进⾏访问。 在这个时候，被内存映射的⽂件实际上成了⼀个分⻚交换⽂件。 当发⽣缺⻚中断时，如果当前内存中并没有空闲的⻚⾯，操作系统就必须在内存选择⼀个⻚⾯将其移出内存，以便为即将调⼊的⻚⾯让出空间。⽤来选择淘汰哪⼀⻚的规则叫做⻚⾯置换算法，我们可以把⻚⾯置换算法看成是淘汰⻚⾯的规则。 OPT ⻚⾯置换算法（最佳⻚⾯置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰⻚⾯将是以后永不使⽤的，或者是在最⻓时间内不再被访问的⻚⾯,这样可以保证获得最低的缺⻚率。但由于⼈们⽬前⽆法预知进程在内存下的若千⻚⾯中哪个是未来最⻓时间内不再被访问的，因⽽该算法⽆法实现。⼀般作为衡量其他置换算法的⽅法。 FIFO（First In First Out） ⻚⾯置换算法（先进先出⻚⾯置换算法） : 总是淘汰最先进⼊内存的⻚⾯，即选择在内存中驻留时间最久的⻚⾯进⾏淘汰。 LRU （Least Rently Used）⻚⾯置换算法（最近最久未使⽤⻚⾯置换算法） ：LRU算法赋予每个⻚⾯⼀个访问字段，⽤来记录⼀个⻚⾯⾃上次被访问以来所经历的时间 T，当须淘汰⼀个⻚⾯时，选择现有⻚⾯中其 T 值最⼤的，即最近最久未使⽤的⻚⾯予以淘汰。 LFU （Least Frequently Used)(最少使⽤⻚⾯置换算法） : 该置换算法选择在之前时期使⽤最少的⻚⾯作为淘汰⻚。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://blog.unclezs.com/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"}]},{"title":"操作系统之内存管理","slug":"操作系统/操作系统之内存管理","date":"2020-08-02T06:28:29.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"操作系统/操作系统之内存管理.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.html","excerpt":"内存管理的概念操作系统作为系统资源的管理者，当然也需要对内存进行管理，要管些什么呢? 操作系统负责内存空间的分配与回收。 操作系统需要提供某种技术从逻辑.上对内存空间进行扩充。 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰 逻辑(虚拟)地址和物理地址我们编程⼀般只有可能和逻辑地址打交道，⽐如在 C 语⾔中，指针⾥⾯存储的数值就可以理解成为内存⾥的⼀个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体⼀点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。 连续分配的块式管理远古时代的计算机操系统的内存管理⽅式。将内存分为⼏个固定⼤⼩的块，每个块中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需要很⼩的空间的话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空间，我们称之为碎⽚。 连续分配内存有一下几种算法 算法 算法思想 分区排列顺序 优点 缺点 首次适应 从头到尾找适合的分区 空闲分区以地址递增次序排列 综合看性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排序 最佳适应 优先使用更小的分区，以保留更多大分区 空闲分区以容量递增次序排列 会有更多的大分区被保留下来，更能满足大进程需求 会产生很多太小的、难以利用的碎片;算法开销大，回收分区后可能需要对空闲分区队列重新排序 最坏适应 优先使用更大的分区，以防止产生太小的不可用的碎片 空闲分区以容量递减次序排列 可以减少难以利用的小碎片 大分区容易被用完，不利于大进程;算法开销大(原因同上) 邻近适应 由首次适应演变而来，每次从上次查找结束位置开始查找 空闲分区以地址递增次序排列(可排列成循环链表) 不用每次都从低地址的小分区开始检索。算法开销小(原因同首次适应算法) 会使高地址的大分区也被用完 ⻚式管理","text":"内存管理的概念操作系统作为系统资源的管理者，当然也需要对内存进行管理，要管些什么呢? 操作系统负责内存空间的分配与回收。 操作系统需要提供某种技术从逻辑.上对内存空间进行扩充。 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰 逻辑(虚拟)地址和物理地址我们编程⼀般只有可能和逻辑地址打交道，⽐如在 C 语⾔中，指针⾥⾯存储的数值就可以理解成为内存⾥的⼀个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体⼀点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。 连续分配的块式管理远古时代的计算机操系统的内存管理⽅式。将内存分为⼏个固定⼤⼩的块，每个块中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需要很⼩的空间的话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空间，我们称之为碎⽚。 连续分配内存有一下几种算法 算法 算法思想 分区排列顺序 优点 缺点 首次适应 从头到尾找适合的分区 空闲分区以地址递增次序排列 综合看性能最好。算法开销小，回收分区后一般不需要对空闲分区队列重新排序 最佳适应 优先使用更小的分区，以保留更多大分区 空闲分区以容量递增次序排列 会有更多的大分区被保留下来，更能满足大进程需求 会产生很多太小的、难以利用的碎片;算法开销大，回收分区后可能需要对空闲分区队列重新排序 最坏适应 优先使用更大的分区，以防止产生太小的不可用的碎片 空闲分区以容量递减次序排列 可以减少难以利用的小碎片 大分区容易被用完，不利于大进程;算法开销大(原因同上) 邻近适应 由首次适应演变而来，每次从上次查找结束位置开始查找 空闲分区以地址递增次序排列(可排列成循环链表) 不用每次都从低地址的小分区开始检索。算法开销小(原因同首次适应算法) 会使高地址的大分区也被用完 ⻚式管理如果允许将一个进程分散到许多不连续的空间，就可以避免内存紧缩，减少碎片。基于这一思想，通过引入进程的逻辑地址，把进程地址空间与实际存储空间分离，增加存储管理的灵活性。 把主存分为⼤⼩相等且固定的⼀⻚⼀⻚的形式，⻚较⼩，相对相⽐于块式管理的划分⼒度更⼤，提⾼了内存利⽤率，减少了碎⽚。⻚式管理通过⻚表对应逻辑地址和物理地址。 页表 快表和多级⻚表⻚表管理机制中有两个很重要的概念：快表和多级⻚表，这两个东⻄分别解决了⻚表管理中很重要的两个问题。 虚拟地址到物理地址的转换要快。 解决虚拟地址空间⼤，⻚表也会很⼤的问题。 快表为了解决虚拟地址到物理地址的转换速度，操作系统在⻚表⽅案基础之上引⼊了快表来加速虚拟地址到物理地址的转换。我们可以把块表理解为⼀种特殊的⾼速缓冲存储器（Cache），其中的内容是⻚表的⼀部分或者全部内容。作为⻚表的 Cache，它的作⽤与⻚表相似，但是提⾼了访问速率。由于采⽤⻚表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问⼀次⾼速缓冲存储器，⼀次主存，这样可加速查找并提⾼指令执⾏速度。 使⽤快表之后的地址转换流程是这样的： 根据虚拟地址中的⻚号查快表； 如果该⻚在快表中，直接从快表中读取相应的物理地址； 如果该⻚不在快表中，就访问内存中的⻚表，再从⻚表中得到物理地址，同时将⻚表中的该映射表项添加到快表中； 当快表填满后，⼜要登记新⻚时，就按照⼀定的淘汰策略淘汰掉快表中的⼀个⻚。 看完了之后你会发现快表和我们平时经常在我们开发的系统使⽤的缓存（⽐如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们⽇常开发使⽤的各种⼯具或者框架中找到它们的影⼦。 多级⻚表引⼊多级⻚表的主要⽬的是为了避免把全部⻚表⼀直放在内存中占⽤过多空间，特别是那些根本就不需要的⻚表就不需要保留在内存中。多，多级⻚表属于时间换空间的典型场景。 推荐阅读 多级页表如何节约内存 总结为了提⾼内存的空间性能，提出了多级⻚表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级⻚表实际上都利⽤到了程序的局部性原理。 段式管理⻚式管理虽然提⾼了内存利⽤率，但是⻚式管理其中的⻚实际并⽆任何实际意义。段式管理把主存分为⼀段段的，每⼀段的空间⼜要⽐⼀⻚的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了⼀组逻辑信息，例如,有主程序段 MAIN、⼦程序段 X、数据段 D及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。 分⻚机制和分段机制的共同点和区别共同点： 分⻚机制和分段机制都是为了提⾼内存利⽤率，较少内存碎⽚。 ⻚和段都是离散存储的，所以两者都是离散分配内存的⽅式。但是，每个⻚和段中的内存是连续的。 不同点： ⻚的⼤⼩是固定的，由操作系统决定；⽽段的⼤⼩不固定，取决于我们当前运⾏的程序。 分⻚仅仅是为了满⾜操作系统内存管理的需求，⽽段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满⾜⽤户的需要。 段⻚式管理段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说 段⻚式管理机制中段与段之间以及段的内部的都是离散的。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://blog.unclezs.com/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"迪杰斯特拉算法","slug":"算法/迪杰斯特拉算法","date":"2020-08-01T14:43:05.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"算法/迪杰斯特拉算法.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/%E8%BF%AA%E6%9D%B0%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95.html","excerpt":"介绍迪杰斯特拉算法是由荷兰计算机科学家狄克斯特拉于1959 年提出的，因此又叫狄克斯特拉算法。是从一个顶点到其余各顶点的最短路径算法，解决的是有权图中最短路径问题。迪杰斯特拉算法主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。迪杰斯特拉算法采用的是贪心策略，将Graph中的节点集分为最短路径计算完成的节点集S和未计算完成的节点集T，每次将从T中挑选V0-&gt;Vt最小的节点Vt加入S，并更新V0经由Vt到T中剩余节点的更短距离，直到T中的节点全部加入S中，它贪心就贪心在每次都选择一个距离源点最近的节点加入最短路径节点集合。迪杰斯特拉算法只支持非负权图，它计算的是单源最短路径，即单个源点到剩余节点的最短路径，时间复杂度为O(n²)。 算法流程本节将对算法流程进行模拟，设置Graph为包含7个顶点和9条边的有向无环图，源点为0，计算从源点0到剩余节点的最短路径，Graph如下： 每个节点将维护shortest和visited两个数据结构，shortest存储v0到该节点的最短路径，visited存储v0到该节点的最短路径是否求出。S为已求出最短路径的节点，T为未求出最短路径的节点。源节点只允许将S中的节点作为中间节点来计算到达其它节点的最短路径，不允许将T中的节点作为中间节点来计算到达其它节点的最短路径。随着S中节点的增加，源节点可达的节点才会增加。初始状态下，源节点只可达节点1和节点3。 算法步骤如下： 将源节点（即节点0）加入S中，对shortest和visited数组进行更新。 S中现有节点0，源节点可达T中的节点1和节点3，节点0-&gt;节点1距离为6，节点0-&gt;节点3距离为2，按距离从小到大排序，因此选择将节点3加入S中。更新源点将节点3作为中间节点到达其它节点的距离。 S中现有节点0和节点3，源节点可达T中的节点1和4，节点0-&gt;节点1距离为6，节点0-&gt;节点4距离为7，按距离从小到大排序，因此选择将节点1加入S中。更新源点将节点1作为中间节点到达其它节点的距离。 S中现有节点0、1、3，源节点可达T中的节点2、4、5，0-&gt;2距离为11，0-&gt;4距离为7，0-&gt;5距离为9，按距离从小到大排序，因此选择将节点4加入S中。更新源点将节点4作为中间节点到达其它节点的距离。 S中现有节点0、1、3、4，源节点可达T中的节点2、5、6，0-&gt;2距离为11，0-&gt;5距离为9，0-&gt;6距离为8，按距离从小到大排序，因此选择将节点6加入S中。更新源点将节点6作为中间节点到达其它节点的距离。 S中现有节点0、1、3、4、6，源节点可达T中的节点2、5，0-&gt;2距离为11，0-&gt;5距离为9，按距离从小到大排序，因此选择将节点5加入S中。更新源点将节点5作为中间节点到达其它节点的距离。 T中只剩下节点2，0-&gt;2距离为11，将节点2加入S中。 算法结束，源点到其它节点的最短路径都已依次求出。 Java实现public static void dijstra(int[][] matrix, int source) &#123; //最短路径长度 int[] shortest = new int[matrix.length]; //判断该点的最短路径是否求出 int[] visited = new int[matrix.length]; //存储输出路径 String[] path = new String[matrix.length]; //初始化输出路径 for (int i = 0; i &lt; matrix.length; i++) &#123; path[i] = new String(source + &quot;-&gt;&quot; + i); &#125; //初始化源节点 shortest[source] = 0; visited[source] = 1; for (int i = 1; i &lt; matrix.length; i++) &#123; int min = Integer.MAX_VALUE; int index = -1; for (int j = 0; j &lt; matrix.length; j++) &#123; //已经求出最短路径的节点不需要再加入计算并判断加入节点后是否存在更短路径 if (visited[j] == 0 &amp;&amp; matrix[source][j] &lt; min) &#123; min = matrix[source][j]; index = j; &#125; &#125; //更新最短路径 shortest[index] = min; visited[index] = 1; //更新从index跳到其它节点的较短路径 for (int m = 0; m &lt; matrix.length; m++) &#123; if (visited[m] == 0 &amp;&amp; matrix[source][index] + matrix[index][m] &lt; matrix[source][m]) &#123; matrix[source][m] = matrix[source][index] + matrix[index][m]; path[m] = path[index] + &quot;-&gt;&quot; + m; &#125; &#125; &#125; //打印最短路径 for (int i = 0; i &lt; matrix.length; i++) &#123; if (i != source) &#123; if (shortest[i] == MaxValue) &#123; System.out.println(source + &quot;到&quot; + i + &quot;不可达&quot;); &#125; else &#123; System.out.println(source + &quot;到&quot; + i + &quot;的最短路径为：&quot; + path[i] + &quot;，最短距离是：&quot; + shortest[i]); &#125; &#125; &#125; &#125;","text":"介绍迪杰斯特拉算法是由荷兰计算机科学家狄克斯特拉于1959 年提出的，因此又叫狄克斯特拉算法。是从一个顶点到其余各顶点的最短路径算法，解决的是有权图中最短路径问题。迪杰斯特拉算法主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。迪杰斯特拉算法采用的是贪心策略，将Graph中的节点集分为最短路径计算完成的节点集S和未计算完成的节点集T，每次将从T中挑选V0-&gt;Vt最小的节点Vt加入S，并更新V0经由Vt到T中剩余节点的更短距离，直到T中的节点全部加入S中，它贪心就贪心在每次都选择一个距离源点最近的节点加入最短路径节点集合。迪杰斯特拉算法只支持非负权图，它计算的是单源最短路径，即单个源点到剩余节点的最短路径，时间复杂度为O(n²)。 算法流程本节将对算法流程进行模拟，设置Graph为包含7个顶点和9条边的有向无环图，源点为0，计算从源点0到剩余节点的最短路径，Graph如下： 每个节点将维护shortest和visited两个数据结构，shortest存储v0到该节点的最短路径，visited存储v0到该节点的最短路径是否求出。S为已求出最短路径的节点，T为未求出最短路径的节点。源节点只允许将S中的节点作为中间节点来计算到达其它节点的最短路径，不允许将T中的节点作为中间节点来计算到达其它节点的最短路径。随着S中节点的增加，源节点可达的节点才会增加。初始状态下，源节点只可达节点1和节点3。 算法步骤如下： 将源节点（即节点0）加入S中，对shortest和visited数组进行更新。 S中现有节点0，源节点可达T中的节点1和节点3，节点0-&gt;节点1距离为6，节点0-&gt;节点3距离为2，按距离从小到大排序，因此选择将节点3加入S中。更新源点将节点3作为中间节点到达其它节点的距离。 S中现有节点0和节点3，源节点可达T中的节点1和4，节点0-&gt;节点1距离为6，节点0-&gt;节点4距离为7，按距离从小到大排序，因此选择将节点1加入S中。更新源点将节点1作为中间节点到达其它节点的距离。 S中现有节点0、1、3，源节点可达T中的节点2、4、5，0-&gt;2距离为11，0-&gt;4距离为7，0-&gt;5距离为9，按距离从小到大排序，因此选择将节点4加入S中。更新源点将节点4作为中间节点到达其它节点的距离。 S中现有节点0、1、3、4，源节点可达T中的节点2、5、6，0-&gt;2距离为11，0-&gt;5距离为9，0-&gt;6距离为8，按距离从小到大排序，因此选择将节点6加入S中。更新源点将节点6作为中间节点到达其它节点的距离。 S中现有节点0、1、3、4、6，源节点可达T中的节点2、5，0-&gt;2距离为11，0-&gt;5距离为9，按距离从小到大排序，因此选择将节点5加入S中。更新源点将节点5作为中间节点到达其它节点的距离。 T中只剩下节点2，0-&gt;2距离为11，将节点2加入S中。 算法结束，源点到其它节点的最短路径都已依次求出。 Java实现public static void dijstra(int[][] matrix, int source) &#123; //最短路径长度 int[] shortest = new int[matrix.length]; //判断该点的最短路径是否求出 int[] visited = new int[matrix.length]; //存储输出路径 String[] path = new String[matrix.length]; //初始化输出路径 for (int i = 0; i &lt; matrix.length; i++) &#123; path[i] = new String(source + &quot;-&gt;&quot; + i); &#125; //初始化源节点 shortest[source] = 0; visited[source] = 1; for (int i = 1; i &lt; matrix.length; i++) &#123; int min = Integer.MAX_VALUE; int index = -1; for (int j = 0; j &lt; matrix.length; j++) &#123; //已经求出最短路径的节点不需要再加入计算并判断加入节点后是否存在更短路径 if (visited[j] == 0 &amp;&amp; matrix[source][j] &lt; min) &#123; min = matrix[source][j]; index = j; &#125; &#125; //更新最短路径 shortest[index] = min; visited[index] = 1; //更新从index跳到其它节点的较短路径 for (int m = 0; m &lt; matrix.length; m++) &#123; if (visited[m] == 0 &amp;&amp; matrix[source][index] + matrix[index][m] &lt; matrix[source][m]) &#123; matrix[source][m] = matrix[source][index] + matrix[index][m]; path[m] = path[index] + &quot;-&gt;&quot; + m; &#125; &#125; &#125; //打印最短路径 for (int i = 0; i &lt; matrix.length; i++) &#123; if (i != source) &#123; if (shortest[i] == MaxValue) &#123; System.out.println(source + &quot;到&quot; + i + &quot;不可达&quot;); &#125; else &#123; System.out.println(source + &quot;到&quot; + i + &quot;的最短路径为：&quot; + path[i] + &quot;，最短距离是：&quot; + shortest[i]); &#125; &#125; &#125; &#125; 转自：图解最短路径之迪杰斯特拉算法（Java实现）","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Dijkstra","slug":"Dijkstra","permalink":"https://blog.unclezs.com/tags/Dijkstra/"}]},{"title":"常用查找算法及Java实现","slug":"算法/常用查找算法及Java实现","date":"2020-07-30T12:05:54.000Z","updated":"2021-01-02T08:43:30.000Z","comments":false,"path":"算法/常用查找算法及Java实现.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E5%8F%8AJava%E5%AE%9E%E7%8E%B0.html","excerpt":"常用算法顺序查找顺序查找也称为线形查找，属于无序查找算法。从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。 顺序查找的时间复杂度为O(n)。 public class Search &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; search(arr,3); &#125; /** * 顺序查找 */ public static int order(int[] arr, int target) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; if (arr[i] == target) &#123; return i; &#125; &#125; return -1; &#125; &#125; 二分查找也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。 最坏情况下，关键词比较次数为log2(n+1)，且期望时间复杂度为O(log2n)； /** * 常规二分查找 */ public static int half(int[] arr, int target) &#123; //使数组有序 Arrays.sort(arr); System.out.println(String.format(&quot;原数组%s中查找【%s】&quot;, Arrays.toString(arr), target)); int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; int mid = ((right - left) &gt;&gt; 1) + left; if (target &gt; arr[mid]) &#123; left = mid + 1; &#125; else if (target &lt; arr[mid]) &#123; right = mid - 1; &#125; else &#123; return mid; &#125; &#125; return -1; &#125; /** * 递归二分查找 * @param high len-1 */ public static int halfByRecurse(int[] arr, int target, int low, int high) &#123; int mid = ((high - low) &gt;&gt; 1) + low; if (low == high) &#123; return -1; &#125; if (target == arr[mid]) &#123; return mid; &#125; if (target &gt; arr[mid]) &#123; return halfByRecurse(arr, target, mid + 1, high); &#125; if (target &lt; arr[mid]) &#123; return halfByRecurse(arr, target, low, mid - 1); &#125; return -1; &#125; 插值查找","text":"常用算法顺序查找顺序查找也称为线形查找，属于无序查找算法。从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。 顺序查找的时间复杂度为O(n)。 public class Search &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; search(arr,3); &#125; /** * 顺序查找 */ public static int order(int[] arr, int target) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; if (arr[i] == target) &#123; return i; &#125; &#125; return -1; &#125; &#125; 二分查找也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。 最坏情况下，关键词比较次数为log2(n+1)，且期望时间复杂度为O(log2n)； /** * 常规二分查找 */ public static int half(int[] arr, int target) &#123; //使数组有序 Arrays.sort(arr); System.out.println(String.format(&quot;原数组%s中查找【%s】&quot;, Arrays.toString(arr), target)); int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; int mid = ((right - left) &gt;&gt; 1) + left; if (target &gt; arr[mid]) &#123; left = mid + 1; &#125; else if (target &lt; arr[mid]) &#123; right = mid - 1; &#125; else &#123; return mid; &#125; &#125; return -1; &#125; /** * 递归二分查找 * @param high len-1 */ public static int halfByRecurse(int[] arr, int target, int low, int high) &#123; int mid = ((high - low) &gt;&gt; 1) + low; if (low == high) &#123; return -1; &#125; if (target == arr[mid]) &#123; return mid; &#125; if (target &gt; arr[mid]) &#123; return halfByRecurse(arr, target, mid + 1, high); &#125; if (target &lt; arr[mid]) &#123; return halfByRecurse(arr, target, low, mid - 1); &#125; return -1; &#125; 插值查找基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找代码基本上和二分查找一样，有修改的地方就是mid的获取 在二分查找中$mid=$$low+high \\over {2}$ 可改写成 $mid =low + $ $ {high-low} \\over {2}$ 也就是说我们的mid每次都是折中的取，但是对于一些均匀分布的有序表，这样做感觉有些费时，比如找字典的时候，找a这个字母，我们肯定不会从中间开始，而是偏向于字典前面一些开始。 插值查找就是基于这样的思想我们对1/2进行改进: $mid=low+$$key-a[low] \\over a[high]=a[low]$$(high-low)$ key就是要查找的值，数组a是有序表 简单的理解就是计算出key所占比，然后更好地找到key所在的区间范围但是对于极端分布的数组，插值查找的效率就大打折扣了比如 int a[7]=&#123;0,1,2,100,102,1000,10000&#125; Java代码实现 /** * 插值查找 */ public static int insert(int[] arr, int target) &#123; //使数组有序 Arrays.sort(arr); System.out.println(String.format(&quot;原数组%s中进行插值查找【%s】&quot;, Arrays.toString(arr), target)); int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; int mid = left + (right - left) * ((target - arr[left]) / (arr[right] - arr[left])); if (target &gt; arr[mid]) &#123; left = mid + 1; &#125; else if (target &lt; arr[mid]) &#123; right = mid - 1; &#125; else &#123; return mid; &#125; &#125; return -1; &#125; /** * 递归插值查找 * * @param high len-1 */ public static int insertByRecurse(int[] arr, int target, int low, int high) &#123; int mid = low + (high - low) * ((target - arr[low]) / (arr[high] - arr[low])); if (low &lt;= high) &#123; if (target == arr[mid]) &#123; return mid; &#125; else if (target &gt; arr[mid]) &#123; return insertByRecurse(arr, target, mid + 1, high); &#125; else &#123; return insertByRecurse(arr, target, low, mid - 1); &#125; &#125; else &#123; return -1; &#125; &#125; 斐波那契查找斐波那契查找原理：该查找原理与二分查找和插值查找类似，仅仅改变中间节点middle位置，middle位置不再是中间或插值得到，而是位于黄金分割点附近，即mid = low + F(k - 1) - 1（F，斐波那契数列）。 F(k-1)-1的说明 由斐波那契数列F[k]=F[k-1] + F[k-2]，可以得到F[k]-1=(F[k-1]-1) + (F[k-2]-1)+1。说明只要顺序表的长度为F[k]-1，则可以-将顺序表分成长度为F[k-1]-1和F[k-2]-1的两段，即中间位置为：mid=low+F[k-1]-1。 类似的每个字段也可以用相同的方式进行分割。 可能顺序表长度n不一定等于F[k]-1，需要将原来的顺序表长度n增加至F[k]-1。（k值只要使得F[k]-1大于或等于n）。 /** * @author blog.unclezs.com * @date 2020/7/31 19:00 */ public class FibonacciSearch &#123; public static void main(String[] args) &#123; int[] array = &#123;1, 8, 10, 89, 1000, 1234&#125;; int index = fibonacciSearch(array, 1); if(-1 == index) &#123; System.err.println(&quot;没有找到&quot;); &#125; else &#123; System.out.println(&quot;找到，位置：&quot; + index); &#125; &#125; /** * 斐波那契查找 */ public static int fibonacciSearch(int[] array, int key) &#123; int length = array.length; int low = 0; int high = length - 1; // 斐波那契分割数的索引 int k = 0; int mid = 0; // 找到有序表元素个数在斐波那契数列中最接近的最大数列值 while(high &gt; (fibonacci(k) - 1)) &#123; k++; &#125; // 补齐有序表 int [] tmpArray = Arrays.copyOf(array, fibonacci(k)); for(int i = length; i &lt; tmpArray.length; i++) &#123; tmpArray[i] = array[high]; &#125; while(low &lt;= high) &#123; mid = low + fibonacci(k - 1) - 1; // 查找值小于中值，在小的那一部分继续查找 if(key &lt; tmpArray[mid]) &#123; high = mid - 1; k--; &#125; // 查找值大于中值，在大的那一部分继续查找 else if(key &gt; tmpArray[mid]) &#123; low = mid + 1; k -= 2; &#125; else &#123; // 可能存在补齐列表 return Math.min(mid, high); &#125; &#125; return -1; &#125; /** * 动态规划实现斐波那契数列 * * @param n / * @return / */ public static int fibonacci(int n) &#123; if (n &lt;= 1) &#123; return n; &#125; int pre1 = 0; int pre2 = 1; int total = pre1 + pre2; for (int i = 2; i &lt;= n; i++) &#123; total = pre1 + pre2; pre1 = pre2; pre2 = total; &#125; return total; &#125; &#125; 树表查找二叉查找树二叉查找树是先对待查找的数据进行生成树，确保树的左分支的值小于右分支的值，然后在就行和每个节点的父节点比较大小，查找最适合的范围。 这个算法的查找效率很高，但是如果使用这种查找方法要首先创建树。 对二叉查找树进行中序遍历即可得到一个有序的列表。 对这个方面还有升级版本的红黑树，来保证平衡 平衡查找树之2-3查找树（2-3 Tree）和二叉树不一样，2-3树运行每个节点保存1个或者两个的值。对于普通的2节点(2-node)，他保存1个key和左右两个自己点。对应3节点(3-node)，保存两个Key。 2-3查找树的定义如下： 要么为空，要么： 对于2节点，该节点保存一个key及对应value，以及两个指向左右节点的节点，左节点也是一个2-3节点，所有的值都比key要小，右节点也是一个2-3节点，所有的值比key要大。 对于3节点，该节点保存两个key及对应value，以及三个指向左中右的节点。左节点也是一个2-3节点，所有的值均比两个key中的最小的key还要小；中间节点也是一个2-3节点，中间节点的key值在两个跟节点key值之间；右节点也是一个2-3节点，节点的所有key值比两个key中的最大的key还要大。 分块查找分块查找又称索引顺序查找，它是顺序查找的一种改进方法。 算法思想：将n个数据元素”按块有序”划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须”按块有序”；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，…… 算法流程： 先选取各块中的最大关键字构成一个索引表； 查找分两个部分：先对索引表进行二分查找或顺序查找，以确定待查记录在哪一块中；然后，在已确定的块中用顺序法进行查找。 哈希查找我们使用一个下标范围比较大的数组来存储元素。可以设计一个函数（哈希函数， 也叫做散列函数），使得每个元素的关键字都与一个函数值（即数组下标）相对应，于是用这个数组单元来存储这个元素；也可以简单的理解为，按照关键字为每一个元素”分类”，然后将这个元素存储在相应”类”所对应的地方。但是，不能够保证每个元素的关键字与函数值是一一对应的，因此极有可能出现对于不同的元素，却计算出了相同的函数值，这样就产生了”冲突”，换句话说，就是把不同的元素分在了相同的”类”之中。后面我们将看到一种解决”冲突”的简便做法。 总的来说，”直接定址”与”解决冲突”是哈希表的两大特点。","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"查找算法","slug":"查找算法","permalink":"https://blog.unclezs.com/tags/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"}]},{"title":"常用排序算法及Java实现","slug":"算法/常用排序算法及Java实现","date":"2020-07-29T14:04:03.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"算法/常用排序算法及Java实现.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%8F%8AJava%E5%AE%9E%E7%8E%B0.html","excerpt":"排序算法选择排序算法思想从数组中选择最小元素，将它与数组的第一个元素交换位置。再从数组剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 选择排序需要 ~N2/2 次比较和 ~N 次交换，它的运行时间与输入无关，这个特点使得它对一个已经排序的数组也需要这么多的比较和交换操作。 代码实现/** * 选择排序 * * @param arr / */ public static void selection(int[] arr) &#123; int len = arr.length; for (int i = 0; i &lt; len; i++) &#123; int min = i; for (int j = i + 1; j &lt; len; j++) &#123; if (arr[min] &gt; arr[j]) &#123; min = j; &#125; &#125; if(i!=min)&#123; swap(arr, i, min); &#125; &#125; System.out.println(Arrays.toString(arr)); &#125; 冒泡排序算法思想从左到右不断交换相邻逆序的元素，在一轮的循环之后，可以让未排序的最大元素上浮到右侧。","text":"排序算法选择排序算法思想从数组中选择最小元素，将它与数组的第一个元素交换位置。再从数组剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 选择排序需要 ~N2/2 次比较和 ~N 次交换，它的运行时间与输入无关，这个特点使得它对一个已经排序的数组也需要这么多的比较和交换操作。 代码实现/** * 选择排序 * * @param arr / */ public static void selection(int[] arr) &#123; int len = arr.length; for (int i = 0; i &lt; len; i++) &#123; int min = i; for (int j = i + 1; j &lt; len; j++) &#123; if (arr[min] &gt; arr[j]) &#123; min = j; &#125; &#125; if(i!=min)&#123; swap(arr, i, min); &#125; &#125; System.out.println(Arrays.toString(arr)); &#125; 冒泡排序算法思想从左到右不断交换相邻逆序的元素，在一轮的循环之后，可以让未排序的最大元素上浮到右侧。 在一轮循环中，如果没有发生交换，那么说明数组已经是有序的，此时可以直接退出。 代码实现/** * 冒泡排序 */ public static void bubble(int[] arr) &#123; int len = arr.length; boolean sorted = false; //一轮下来都没有发生交换，则已经有序了 for (int i = len - 1; i &gt; 0 &amp;&amp; !sorted; i--) &#123; sorted = true; for (int j = 0; j &lt; i; j++) &#123; if (arr[j + 1] &lt; arr[j]) &#123; sorted = false; swap(arr, i, j); &#125; &#125; &#125; System.out.println(&quot;冒泡排序结果：&quot; + Arrays.toString(arr)); &#125; 插入排序算法思想每一步将一个待排序的数据插入到前面已经排好序的有序序列中，直到插完所有元素为止。 算法实现：直接插入排序是将无序序列中的数据插入到有序的序列中，在遍历无序序列时，首先拿无序序列中的首元素去与有序序列中的每一个元素比较并插入到合适的位置，一直到无序序列中的所有元素插完为止。对于一个无序序列arr{4，6，8，5，9}来说，我们首先先确定首元素4是有序的，然后在无序序列中向右遍历，6大于4则它插入到4的后面，再继续遍历到8，8大于6则插入到6的后面，这样继续直到得到有序序列{4，5，6，8，9}。 代码实现public static void insert(int[] arr) &#123; int len = arr.length; for (int i = 1; i &lt; len; i++) &#123; //arr[j] &lt; arr[j - 1] 如果比最后一个都大那就不用排了 for (int j = i; j &gt; 0 &amp;&amp; arr[j] &lt; arr[j - 1]; j--) &#123; swap(arr, j - 1, j); &#125; &#125; System.out.println(&quot;插入排序结果：&quot; + Arrays.toString(arr)); &#125; 希尔排序算法思想希尔排序是把序列按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量的逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个序列恰好被分为一组，算法便终止。 算法实现：希尔排序需要定义一个增量，这里选择增量为gap=length/2，缩小增量以gap=gap/2的方式，这个增量可以用一个序列来表示，{n/2,(n/2)/2….1}，称为增量序列，这个增量是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。 也可以采用一种更复杂的增量序列 // 1, 4, 13, 40, ... while (h &lt; lengh / 3) &#123; h = 3 * h + 1; &#125; 代码实现public static void shell(int[] arr) &#123; int len = arr.length; int gap = 1; //找到合适的间隙 while (gap &lt; len / 3) &#123; gap = gap * 3 + 1; &#125; while (gap &gt;= 1) &#123; for (int i = gap; i &lt; len; i++) &#123; for (int j = i; j &gt;= gap &amp;&amp; arr[j] &lt; arr[j - gap]; j -= gap) &#123; swap(arr, j - gap, j); &#125; &#125; gap /= 3; &#125; System.out.println(&quot;希尔排序结果：&quot; + Arrays.toString(arr)); &#125; 归并排序算法思想归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 算法步骤 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针，最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置； 重复步骤 3 直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾。 代码实现public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; mergeSort(arr, 0, arr.length - 1); System.out.println(&quot;归并排序结果：&quot; + Arrays.toString(arr)); &#125; /** * 归并排序(治) */ public static void merge(int[] arr, int low, int middle, int high) &#123; int[] tmpArray = new int[high - low + 1]; int left = low; int right = middle + 1; int index = 0; //左边或者右边的拷贝完了，则不再比较 while (left &lt;= middle &amp;&amp; right &lt;= high) &#123; if (arr[left] &lt; arr[right]) &#123; tmpArray[index++] = arr[left++]; &#125; else &#123; tmpArray[index++] = arr[right++]; &#125; &#125; //如果是左边的剩下了 if (left &lt;= middle) &#123; System.arraycopy(arr, left, tmpArray, index, middle - left + 1); &#125; //如果是右边的剩下了 if (right &lt;= high) &#123; System.arraycopy(arr, right, tmpArray, index, high - right + 1); &#125; if (tmpArray.length &gt;= 0) &#123; System.arraycopy(tmpArray, 0, arr, low, tmpArray.length); &#125; &#125; /** * 归并排序(分) 自顶向上 */ public static void mergeSort(int[] arr, int low, int high) &#123; //分 完成 if (low &gt;= high) &#123; return; &#125; int middle = ((high - low) &gt;&gt; 1) + low; mergeSort(arr, low, middle); mergeSort(arr, middle + 1, high); merge(arr, low, middle, high); &#125; /** * 归并排序(分) 自底向上 */ public static void mergeSort(int[] arr) &#123; int len = arr.length; for (int size = 1; size &lt; len; size += size) &#123; for (int i = 0; i &lt; len - size; i += size + size) &#123; merge(arr, i, i + size - 1, Math.min(i + size + size - 1, len-1)); &#125; &#125; &#125; 快速排序算法思想快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。 代码实现public static void sort(int[] arr, int low, int high) &#123; if (low &lt; high) &#123; int partition = partition(arr, low, high); sort(arr, low, partition); sort(arr, partition + 1, high); &#125; &#125; /** * 切分 */ private static int partition(int[] arr, int low, int high) &#123; int index = low + 1; for (int i = index; i &lt;= high; i++) &#123; if (arr[i] &lt; arr[low]) &#123; swap(arr, index++, i); &#125; &#125; swap(arr, --index, low); return index; &#125; 堆排序算法思想堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法： 大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；堆排序的平均时间复杂度为 Ο(nlogn)。 现代操作系统很少使用堆排序，因为它无法利用局部性原理进行缓存，也就是数组元素很少和相邻的元素进行比较和交换。 构建堆 无序数组建立堆最直接的方法是从左到右遍历数组进行上浮操作。一个更高效的方法是从右至左进行下沉操作，如果一个节点的两个节点都已经是堆有序，那么进行下沉操作可以使得这个节点为根节点的堆有序。叶子节点不需要进行下沉操作，可以忽略叶子节点的元素，因此只需要遍历一半的元素即可。 代码实现/** * @author blog.unclezs.com * @date 2020/7/30 18:19 */ public class HeapSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;88, 11, 22, 3, 5, 1, 19&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static void sort(int[] arr) &#123; int len = arr.length; buildHeap(arr, len); for (int i = len - 1; i &gt; 0; i--) &#123; //首尾交换 swap(arr, 0, i); //重新维护堆性质 heapify(arr, 0, --len); &#125; &#125; private static void buildHeap(int[] arr, int len) &#123; for (int i = 0; i &lt; len / 2; i++) &#123; heapify(arr, i, len); &#125; &#125; private static void heapify(int[] arr, int index, int len) &#123; int left = 2 * index + 1; int right = 2 * index + 2; int max = index; if (left &lt; len &amp;&amp; arr[left] &gt; arr[max]) &#123; max = left; &#125; if (right &lt; len &amp;&amp; arr[right] &gt; arr[max]) &#123; max = right; &#125; if (max != index) &#123; swap(arr, max, index); heapify(arr, max, len); &#125; &#125; /** * 交换 * * @param arr 数组 * @param self 自身 * @param other 另一个 */ private static void swap(int[] arr, int self, int other) &#123; int tmp = arr[self]; arr[self] = arr[other]; arr[other] = tmp; &#125; &#125; 计数排序算法思想计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 算法的步骤如下： 找出待排序的数组中最大和最小的元素 统计数组中每个值为i的元素出现的次数，存入数组C的第i项 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加） 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1 代码实现/** * 计数排序 * * @author blog.unclezs.com * @date 2020/7/30 19:01 */ public class CountSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; private static void sort(int[] arr) &#123; //找出最大值 OptionalInt optionalInt = Arrays.stream(arr).max(); if (optionalInt.isPresent()) &#123; int max = optionalInt.getAsInt(); int[] bucket = new int[max + 1]; for (int v : arr) &#123; bucket[v] += 1; &#125; int index = 0; for (int i = 0; i &lt; bucket.length; i++) &#123; while (bucket[i] &gt; 0) &#123; bucket[i] -= 1; arr[index++] = i; &#125; &#125; &#125; &#125; &#125; 桶排序算法思想桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点： 在额外空间充足的情况下，尽量增大桶的数量使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。 代码实现 /** * @author blog.unclezs.com * @date 2020/7/30 19:35 */ public class BucketSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; sort(arr, 5); System.out.println(Arrays.toString(arr)); &#125; private static void sort(int[] arr, int bucketSize) &#123; if (arr.length == 0) &#123; return; &#125; int minValue = arr[0]; int maxValue = arr[0]; for (int value : arr) &#123; if (value &lt; minValue) &#123; minValue = value; &#125; else if (value &gt; maxValue) &#123; maxValue = value; &#125; &#125; int bucketCount = (maxValue - minValue) / bucketSize + 1; int[][] buckets = new int[bucketCount][0]; // 利用映射函数将数据分配到各个桶中 for (int item : arr) &#123; int index = (item - minValue) / bucketSize; buckets[index] = arrAppend(buckets[index], item); &#125; int arrIndex = 0; for (int[] bucket : buckets) &#123; if (bucket.length &lt;= 0) &#123; continue; &#125; // 对每个桶进行排序，这里使用了归并排序 MergeSort.sort(bucket); for (int value : bucket) &#123; arr[arrIndex++] = value; &#125; &#125; &#125; /** * 自动扩容，并保存数据 */ private static int[] arrAppend(int[] arr, int value) &#123; arr = Arrays.copyOf(arr, arr.length + 1); arr[arr.length - 1] = value; return arr; &#125; &#125; 基数排序算法思想基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 基数排序有两种方法： 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶； 计数排序：每个桶只存储单一键值； 桶排序：每个桶存储一定范围的数值； 代码实现/** * 基数排序 * 考虑负数的情况还可以参考： https://code.i-harness.com/zh-CN/q/e98fa9 */ public class RadixSort &#123; public static void main(String[] args) &#123; int arr[] = &#123;5, 11, 7, 9, 2, 3, 12, 8, 6, 1, 4, 10&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static int[] sort(int[] arr) &#123; int maxDigit = getMaxDigit(arr); return radixSort(arr, maxDigit); &#125; /** * 获取最高位数 */ private static int getMaxDigit(int[] arr) &#123; int maxValue = getMaxValue(arr); return getNumLength(maxValue); &#125; private static int getMaxValue(int[] arr) &#123; int maxValue = arr[0]; for (int value : arr) &#123; if (maxValue &lt; value) &#123; maxValue = value; &#125; &#125; return maxValue; &#125; protected static int getNumLength(long num) &#123; if (num == 0) &#123; return 1; &#125; int lenght = 0; for (long temp = num; temp != 0; temp /= 10) &#123; lenght++; &#125; return lenght; &#125; private static int[] radixSort(int[] arr, int maxDigit) &#123; int mod = 10; int dev = 1; for (int i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) &#123; // 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10) int[][] counter = new int[mod * 2][0]; for (int j = 0; j &lt; arr.length; j++) &#123; int bucket = ((arr[j] % mod) / dev) + mod; counter[bucket] = arrayAppend(counter[bucket], arr[j]); &#125; int pos = 0; for (int[] bucket : counter) &#123; for (int value : bucket) &#123; arr[pos++] = value; &#125; &#125; &#125; return arr; &#125; /** * 自动扩容，并保存数据 * * @param arr * @param value */ private static int[] arrayAppend(int[] arr, int value) &#123; arr = Arrays.copyOf(arr, arr.length + 1); arr[arr.length - 1] = value; return arr; &#125; &#125; 算法对比 参考十大经典排序算法","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://blog.unclezs.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"操作系统之进程调度算法","slug":"操作系统/操作系统之进程调度算法","date":"2020-07-29T13:25:37.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"操作系统/操作系统之进程调度算法.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95.html","excerpt":"介绍无论是在批处理系统还是分时系统中，用户进程数一般都多于处理机数、这将导致它们互相争夺处理机。另外，系统进程也同样需要使用处理机。这就要求进程调度程序按一定的策略，动态地把处理机分配给处于就绪队列中的某一个进程，以使之执行。 算法先来先服务调度算法（FCFS）先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 执行时间与调度之后执行顺序： 短作业优先(SJF)的调度算法从就绪队列中选出⼀个估计运⾏时间最短的进程为之分配资源，使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻塞放弃占⽤ CPU 时再重新调度。","text":"介绍无论是在批处理系统还是分时系统中，用户进程数一般都多于处理机数、这将导致它们互相争夺处理机。另外，系统进程也同样需要使用处理机。这就要求进程调度程序按一定的策略，动态地把处理机分配给处于就绪队列中的某一个进程，以使之执行。 算法先来先服务调度算法（FCFS）先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 执行时间与调度之后执行顺序： 短作业优先(SJF)的调度算法从就绪队列中选出⼀个估计运⾏时间最短的进程为之分配资源，使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻塞放弃占⽤ CPU 时再重新调度。 时间⽚轮转调度算法 时间⽚轮转调度是⼀种最古⽼，最简单，最公平且使⽤最⼴的算法，⼜称 RR(Round robin)调度。每个进程被分配⼀个时间段，称作它的时间⽚，即该进程允许运⾏的时间。 时间片为4，到期后切换下一个进程： 多级反馈队列调度算法前⾯介绍的⼏种进程调度的算法都有⼀定的局限性。如短进程优先的调度算法，仅照顾了短进程⽽忽略了⻓进程 。多级反馈队列调度算法既能使⾼优先级的作业得到响应⼜能使短作业（进程）迅速完成。，因⽽它是⽬前被公认的⼀种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。 多级反馈队列调度算法的实现思想如下： 应设置多个就绪队列，并为各个队列赋予不同的优先级，第1级队列的优先级最高，第2级队列次之，其余队列的优先级逐次降低。 赋予各个队列中进程执行时间片的大小也各不相同，在优先级越高的队列中，每个进程的运行时间片就越小。例如，第2级队列的时间片要比第1级队列的时间片长一倍， ……第i+1级队列的时间片要比第i级队列的时间片长一倍。 当一个新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾，再同样地按FCFS 原则等待调度执行；如果它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第3级队列……如此下去，当一个长进程从第1级队列依次降到第 n 级队列后，在第 n 级队列中便釆用时间片轮转的方式运行。 仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行；仅当第1 ~ (i-1)级队列均为空时，才会调度第i级队列中的进程运行。如果处理机正在执行第i级队列中的某进程时，又有新进程进入优先级较高的队列（第 1 ~ (i-1)中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i级队列的末尾，把处理机分配给新到的更高优先级的进程。 优先级调度为每个流程分配优先级，⾸先执⾏具有最⾼优先级的进程，依此类推。具有相同优先级的进程以 FCFS ⽅式执⾏。可以根据内存要求，时间要求或任何其他资源要求来确定优先级 高响应比优先调度算法​ 根据比率：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间） 如果该进程被立即调用，则R值等于归一化周转时间（周转时间和服务时间的比率）。R最小值为1.0，只有第一个进入系统的进程才能达到该值。调度规则为：当前进程完成或被阻塞时，选择R值最大的就绪进程，它说明了进程的年龄。当偏向短作业时，长进程由于得不到服务，等待时间不断增加，从而增加比值，最终在竞争中赢了短进程。和最短进程优先、最短剩余时间优先一样，使用最高响应比策略需要估计预计服务时间。 ​ 高响应比优先调度算法主要用于作业调度，该算法是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。 根据公式可知： 当作业的等待时间相同时，则要求服务时间越短，其响应比越高，有利于短作业。 当要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。克服了饥饿状态，兼顾了长作业。 最短剩余时间优先​ 最短剩余时间是针对最短进程优先增加了抢占机制的版本。在这种情况下，进程调度总是选择预期剩余时间最短的进程。当一个进程加入到就绪队列时，他可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就能可能抢占当前正在运行的进程。像最短进程优先一样，调度程序正在执行选择函数是必须有关于处理时间的估计，并且存在长进程饥饿的危险。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程调度","slug":"进程调度","permalink":"https://blog.unclezs.com/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"}]},{"title":"操作系统之进程通讯IPC","slug":"操作系统/操作系统之进程通讯IPC","date":"2020-07-29T10:01:00.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"操作系统/操作系统之进程通讯IPC.html","link":"","permalink":"https://blog.unclezs.com/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%E9%80%9A%E8%AE%AFIPC.html","excerpt":"概念每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication） 进程通讯的七种方式管道/匿名管道(Pipes)一句话介绍大白话来说，就是只能在父子间单向传递数据的方式，数据放在内核缓冲区，像FIFO的方式循环队列来存取。管道单独构成一种文件系统，并且只存在与内存中。 特点 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程); 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。 实质","text":"概念每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication） 进程通讯的七种方式管道/匿名管道(Pipes)一句话介绍大白话来说，就是只能在父子间单向传递数据的方式，数据放在内核缓冲区，像FIFO的方式循环队列来存取。管道单独构成一种文件系统，并且只存在与内存中。 特点 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程); 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。 实质管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。 局限性 只支持单向数据流； 只能用于具有亲缘关系的进程之间； 没有名字； 管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）； 管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等； 有名管道(Names Pipes)一句话介绍与匿名管道一样，但是存在有一个名字，这个名字就是文件路径，存在于文件系统中，但是内容还是在内存，这样就可以非父子进程通信了。 介绍匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循先进先出(first in first out),对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。有名管道的名字存在于文件系统中，内容存放在内存中。 匿名管道和有名管道总结（1）管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。（2）匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。（3）无名管道阻塞问题：无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。（4）有名管道阻塞问题：有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。 信号(Signal)信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。 SIGINT：程序终止信号。程序运行过程中，按Ctrl+C键将产生该信号。 消息队列(Message Queuing) 消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。 另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。 特点 消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识. 消息队列允许一个或多个进程向它写入与读取消息. 管道和消息队列的通信数据都是先进先出的原则。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。 消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。 目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。 信号量(Semaphores)一句话介绍信号量是⼀个计数器，⽤于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。 实际过程信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。 为了获得共享资源，进程需要执行下列操作： 创建一个信号量：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。 等待一个信号量：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。 挂出一个信号量：该操作将信号量的值加1，也称为V操作。 为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。 信号量与普通整型变量的区别 信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问； 操作也被成为PV原语（P来源于荷兰语proberen”测试”，V来源于荷兰语verhogen”增加”，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问； 信号量与互斥量之间的区别： 互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。 互斥：是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。同步：是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源2. 互斥量值只能为0/1，信号量值可以为非负整数。也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。3. 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。 共享内存(Shared memory) 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。 套接字(Sockets)套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。 套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程通讯","slug":"进程通讯","permalink":"https://blog.unclezs.com/tags/%E8%BF%9B%E7%A8%8B%E9%80%9A%E8%AE%AF/"},{"name":"IPC","slug":"IPC","permalink":"https://blog.unclezs.com/tags/IPC/"}]},{"title":"DFS(深度优先)与BFS(广度优先)算法","slug":"算法/DFS-深度优先-与BFS-广度优先-算法","date":"2020-07-29T08:21:07.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"算法/DFS-深度优先-与BFS-广度优先-算法.html","link":"","permalink":"https://blog.unclezs.com/%E7%AE%97%E6%B3%95/DFS-%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88-%E4%B8%8EBFS-%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88-%E7%AE%97%E6%B3%95.html","excerpt":"介绍BFS（广度优先遍历，Breadth First Search）及DFS（深度优先遍历，Depth First Search）是遍历树或图的两种最常用的方法。 深度优先算法算法描述深度优先算法是从起始顶点开始，递归访问其所有邻近节点，比如A节点是其第一个邻近节点，而B节点又是A的一个邻近节点，则DFS访问A节点后再访问B节点，如果B节点有未访问的邻近节点的话将继续访问其邻近节点，否则继续访问A的未访问邻近节点，当所有从A节点出去的路径都访问完之后，继续递归访问除A以外未被访问的邻近节点。 Java实现可以用递归和栈实现，时间复杂度为O(N)。 public class DFS &#123; static class TreeNode &#123; TreeNode left; TreeNode right; int data; public TreeNode(int data) &#123; this.data = data; &#125; &#125; public static void main(String[] args) &#123; TreeNode root = new TreeNode(-1); root.left = new TreeNode(10); root.right = new TreeNode(5); root.right.left = new TreeNode(2); root.left.left = new TreeNode(3); root.left.left.left = new TreeNode(4); dfsByRecursion(root); dfsByStack(root); &#125; /** * 递归实现DFS * * @param node 树节点 */ public static void dfsByRecursion(TreeNode node) &#123; if (node != null) &#123; System.out.println(node.data); if (node.left != null) &#123; dfsByRecursion(node.left); &#125; if (node.right != null) &#123; dfsByRecursion(node.right); &#125; &#125; &#125; /** * 栈实现 * @param node 节点 */ public static void dfsByStack(TreeNode node) &#123; Stack&lt;TreeNode&gt; nodes = new Stack&lt;&gt;(); nodes.push(node); while (!nodes.isEmpty()) &#123; TreeNode treeNode = nodes.pop(); System.out.println(treeNode.data); if (treeNode.right != null) &#123; nodes.push(treeNode.right); &#125; if (treeNode.left != null) &#123; nodes.push(treeNode.left); &#125; &#125; &#125; &#125; //-1，10，3，4，5，2 广度优先算法","text":"介绍BFS（广度优先遍历，Breadth First Search）及DFS（深度优先遍历，Depth First Search）是遍历树或图的两种最常用的方法。 深度优先算法算法描述深度优先算法是从起始顶点开始，递归访问其所有邻近节点，比如A节点是其第一个邻近节点，而B节点又是A的一个邻近节点，则DFS访问A节点后再访问B节点，如果B节点有未访问的邻近节点的话将继续访问其邻近节点，否则继续访问A的未访问邻近节点，当所有从A节点出去的路径都访问完之后，继续递归访问除A以外未被访问的邻近节点。 Java实现可以用递归和栈实现，时间复杂度为O(N)。 public class DFS &#123; static class TreeNode &#123; TreeNode left; TreeNode right; int data; public TreeNode(int data) &#123; this.data = data; &#125; &#125; public static void main(String[] args) &#123; TreeNode root = new TreeNode(-1); root.left = new TreeNode(10); root.right = new TreeNode(5); root.right.left = new TreeNode(2); root.left.left = new TreeNode(3); root.left.left.left = new TreeNode(4); dfsByRecursion(root); dfsByStack(root); &#125; /** * 递归实现DFS * * @param node 树节点 */ public static void dfsByRecursion(TreeNode node) &#123; if (node != null) &#123; System.out.println(node.data); if (node.left != null) &#123; dfsByRecursion(node.left); &#125; if (node.right != null) &#123; dfsByRecursion(node.right); &#125; &#125; &#125; /** * 栈实现 * @param node 节点 */ public static void dfsByStack(TreeNode node) &#123; Stack&lt;TreeNode&gt; nodes = new Stack&lt;&gt;(); nodes.push(node); while (!nodes.isEmpty()) &#123; TreeNode treeNode = nodes.pop(); System.out.println(treeNode.data); if (treeNode.right != null) &#123; nodes.push(treeNode.right); &#125; if (treeNode.left != null) &#123; nodes.push(treeNode.left); &#125; &#125; &#125; &#125; //-1，10，3，4，5，2 广度优先算法算法描述其主要思想是从起始点开始，将其邻近的所有顶点都加到一个队列（FIFO）中去，然后标记下这些顶点离起始顶点的距离为1.最后将起始顶点标记为已访问，今后就不会再访问。然后再从队列中取出最先进队的顶点A，也取出其周边邻近节点，加入队列末尾，最后离开这个顶点A。依次下去，直到队列为空为止。从上面描述的过程我们知道每个顶点被访问的次数最多一次（已访问的节点不会再访问）。 Java实现通过队列实现，其中树节点和测试数据和DFS一样。时间复杂度为O(N)。 /** * 队列实现 BFS * @param node 节点 */ public static void bfsByQueue(TreeNode node) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(node); while (!queue.isEmpty()) &#123; TreeNode treeNode = queue.poll(); System.out.println(treeNode.data); if (treeNode.left != null) &#123; queue.add(treeNode.left); &#125; if (treeNode.right != null) &#123; queue.add(treeNode.right); &#125; &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"DFS","slug":"DFS","permalink":"https://blog.unclezs.com/tags/DFS/"},{"name":"BFS","slug":"BFS","permalink":"https://blog.unclezs.com/tags/BFS/"}]},{"title":"数据结构之图","slug":"数据结构/数据结构之图","date":"2020-07-29T06:26:27.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之图.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%9B%BE.html","excerpt":"什么是图在计算机科学中，一个图就是一些顶点的集合，这些顶点通过一系列边结对（连接）。顶点用圆圈表示，边就是这些圆圈之间的连线。顶点之间通过边连接。 图的术语在图中，最基本的单元是顶点（vertex），相当于树中的节点。顶点之间的关联关系，被称为边（edge）。 在有些图中，每一条边并不是完全等同的。比如刚才地铁线路的例子，从A站到B站的距离是3公里，从B站到C站的距离是5公里……这样就引入一个新概念：边的权重（Weight）。涉及到权重的图，被称为带权图（Weighted Graph）。 图的表示邻接矩阵拥有n个顶点的图，它所包含的连接数量最多是n（n-1）个。因此，要表达各个顶点之间的关联关系，最清晰易懂的方式是使用二维数组（矩阵）。","text":"什么是图在计算机科学中，一个图就是一些顶点的集合，这些顶点通过一系列边结对（连接）。顶点用圆圈表示，边就是这些圆圈之间的连线。顶点之间通过边连接。 图的术语在图中，最基本的单元是顶点（vertex），相当于树中的节点。顶点之间的关联关系，被称为边（edge）。 在有些图中，每一条边并不是完全等同的。比如刚才地铁线路的例子，从A站到B站的距离是3公里，从B站到C站的距离是5公里……这样就引入一个新概念：边的权重（Weight）。涉及到权重的图，被称为带权图（Weighted Graph）。 图的表示邻接矩阵拥有n个顶点的图，它所包含的连接数量最多是n（n-1）个。因此，要表达各个顶点之间的关联关系，最清晰易懂的方式是使用二维数组（矩阵）。 邻接表和逆邻接表为了解决邻接矩阵占用空间的问题，人们想到了另一种图的表示方法：邻接表。在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。 十字链表十字链表的每一个顶点，都是两个链表的根节点，其中一个链表存储着该顶点能到达的相邻顶点，另一个链表存储着能到达该顶点的相邻节点。 我们没有必要把链表的节点都重复存储两次。在优化之后的十字链表中，链表的每一个节点不再是顶点，而是一条边，里面包含起止顶点的下标。 总结 根据图的边是否有方向，可分为有向图和无向图。根据图的边是否有权重，可分为带权图和无权图。当然，也可以把两个维度结合起来描述，比如有向带权图，无向无权图等等。 图的表示方法有很多种。包括邻接矩阵、邻接表、逆邻接表、十字链表（还有一种邻接多重表，有兴趣的小伙伴可以自学下）。 推荐阅读漫画：为什么你需要了解数据结构中的图？","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"图","slug":"图","permalink":"https://blog.unclezs.com/tags/%E5%9B%BE/"},{"name":"邻接矩阵","slug":"邻接矩阵","permalink":"https://blog.unclezs.com/tags/%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5/"},{"name":"十字链表","slug":"十字链表","permalink":"https://blog.unclezs.com/tags/%E5%8D%81%E5%AD%97%E9%93%BE%E8%A1%A8/"},{"name":"邻接表和逆邻接表","slug":"邻接表和逆邻接表","permalink":"https://blog.unclezs.com/tags/%E9%82%BB%E6%8E%A5%E8%A1%A8%E5%92%8C%E9%80%86%E9%82%BB%E6%8E%A5%E8%A1%A8/"}]},{"title":"数据结构之堆Heap","slug":"数据结构/数据结构之堆Heap","date":"2020-07-27T10:16:38.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之堆Heap.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%A0%86Heap.html","excerpt":"定义堆(Heap)是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵完全二叉树的数组对象。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。 堆中某个节点的值总是不大于或不小于其父节点的值； 堆总是一棵完全二叉树。 图一为最大堆，图二为最小堆】 堆的存储结构 根节点位置：根节点的数据总是在数组的位置[0] 节点的父节点位置：假设一个非根节点的数据在数组中的位置[i]，那么它的父节点总是在位置[(i-1)/2] 节点的孩子节点位置：假设一个节点的数据在数组中的位置为[i]，那么它的孩子（如果有）总是在下面的这两个位置：左孩子在[2 * i+1]，右孩子在[2 * i+2] 堆的一些操作插入过程","text":"定义堆(Heap)是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵完全二叉树的数组对象。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。 堆中某个节点的值总是不大于或不小于其父节点的值； 堆总是一棵完全二叉树。 图一为最大堆，图二为最小堆】 堆的存储结构 根节点位置：根节点的数据总是在数组的位置[0] 节点的父节点位置：假设一个非根节点的数据在数组中的位置[i]，那么它的父节点总是在位置[(i-1)/2] 节点的孩子节点位置：假设一个节点的数据在数组中的位置为[i]，那么它的孩子（如果有）总是在下面的这两个位置：左孩子在[2 * i+1]，右孩子在[2 * i+2] 堆的一些操作插入过程 将新元素增加到堆的末尾 按照优先顺序，将新元素与其父节点比较，如果新元素小于父节点则将两者交换位置。 不断进行第2步操作，直到不需要交换新元素和父节点，或者达到堆顶则插入成功 删除根过程堆的删除操作与插入操作相反，插入操作从下往上调整堆，而删除操作则从上往下调整堆。 删除堆顶元素（通常是将堆顶元素放置在数组的末尾） 比较左右子节点，将小的元素上调。 不断进行步骤2，直到不需要调整或者调整到堆底。 Java实现堆 大根堆/** * @author blog.unclezs.com * @date 2020/7/27 22:15 */ public class BigHeap &#123; private final int[] data; private int size; public BigHeap(int length) &#123; this.data = new int[length]; Arrays.fill(this.data, -1); &#125; public void add(int node) &#123; this.data[size] = node; int currentIndex = size++; while (currentIndex &gt; 0) &#123; int parentIndex = (currentIndex - 1) / 2; //如果这个节点比父节点小 if (data[currentIndex] &gt; data[parentIndex]) &#123; swap(currentIndex, parentIndex); &#125; else &#123; break; &#125; currentIndex = parentIndex; &#125; &#125; @Override public String toString() &#123; return Arrays.toString(data); &#125; /** * 删除根 * * @return 根 */ public int deleteRoot() &#123; //堆尾元素放到根 int root = data[0]; data[0] = data[--size]; data[size] = -1; int currentIndex = 0; for (; ; ) &#123; int leftIndex = 2 * currentIndex + 1; int rightIndex = 2 * currentIndex + 2; //已经没有子节点了 if (leftIndex &gt; size) &#123; break; &#125; //如果有右子节点，并且大于左子节点 if (rightIndex &lt; size &amp;&amp; data[rightIndex] &gt; data[leftIndex]) &#123; leftIndex = rightIndex; &#125; if (data[leftIndex] &gt; data[currentIndex]) &#123; swap(leftIndex, currentIndex); &#125; else &#123; break; &#125; currentIndex = leftIndex; &#125; return root; &#125; private void swap(int from, int to) &#123; int tmp = data[from]; data[from] = data[to]; data[to] = tmp; &#125; public static void main(String[] args) &#123; BigHeap heap = new BigHeap(10); heap.add(88); heap.add(11); heap.add(22); heap.add(3); heap.add(5); heap.add(1); heap.add(19); System.out.println(heap.deleteRoot()); System.out.println(heap); &#125; &#125; 小根堆修改增加删除方法public void add(int node) &#123; this.data[size] = node; int currentIndex = size++; while (currentIndex &gt; 0) &#123; int parentIndex = (currentIndex - 1) / 2; //如果这个节点比父节点小 if (data[currentIndex] &lt; data[parentIndex]) &#123; swap(currentIndex, parentIndex); &#125; else &#123; break; &#125; currentIndex = parentIndex; &#125; &#125; @Override public String toString() &#123; return Arrays.toString(data); &#125; /** * 删除根 * * @return 根 */ public int deleteRoot() &#123; //堆尾元素放到根 int root = data[0]; data[0] = data[--size]; data[size] = -1; int currentIndex = 0; for (; ; ) &#123; int leftIndex = 2 * currentIndex + 1; int rightIndex = 2 * currentIndex + 2; //已经没有子节点了 if (leftIndex &gt; size) &#123; break; &#125; //如果有右子节点，并且小于左子节点 if (rightIndex &lt; size &amp;&amp; data[rightIndex] &lt; data[leftIndex]) &#123; leftIndex = rightIndex; &#125; if (data[leftIndex] &lt; data[currentIndex]) &#123; swap(leftIndex, currentIndex); currentIndex = leftIndex; &#125; else &#123; break; &#125; &#125; return root; &#125; 参考 数据结构-堆和堆的Java实现 数据结构之堆的定义 数据结构-堆的实现+","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"heap","slug":"heap","permalink":"https://blog.unclezs.com/tags/heap/"},{"name":"堆","slug":"堆","permalink":"https://blog.unclezs.com/tags/%E5%A0%86/"},{"name":"二叉树","slug":"二叉树","permalink":"https://blog.unclezs.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"数据结构之树Tree","slug":"数据结构/数据结构之树Tree","date":"2020-07-27T08:21:16.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之树Tree.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%91Tree.html","excerpt":"树的概念树状图是一种数据结构，它是由n（n&gt;=0）个有限结点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点： 每个结点有零个或多个子结点； 没有父结点的结点称为根结点； 每一个非根结点有且只有一个父结点； 除了根结点外，每个子结点可以分为多个不相交的子树 满二叉树⼀个⼆叉树，如果每⼀个层的结点数都达到最⼤值，则这个⼆叉树就是满⼆叉树。也就是说，如果⼀个⼆叉树的层数为K，且结点总数是(2^k) -1 ，则它就是满⼆叉树。 一个层数为k 的满二叉树总结点数为：。因此满二叉树的结点数一定是奇数个。 第i层上的结点数为： 一个层数为k的满二叉树的叶子结点个数（也就是最后一层）：2^(k-1) 完全二叉树一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。 如果遇到一个结点，左孩子为空，右孩子不为空，则该树一定不是完全二叉树； 如果遇到一个结点，左孩子不为空，右孩子为空；或者左右孩子都为空；则该节点之后的队列中的结点都为叶子节点；该树才是完全二叉树，否则就不是完全二叉树； 二叉查找树（Binary Search Tree）","text":"树的概念树状图是一种数据结构，它是由n（n&gt;=0）个有限结点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点： 每个结点有零个或多个子结点； 没有父结点的结点称为根结点； 每一个非根结点有且只有一个父结点； 除了根结点外，每个子结点可以分为多个不相交的子树 满二叉树⼀个⼆叉树，如果每⼀个层的结点数都达到最⼤值，则这个⼆叉树就是满⼆叉树。也就是说，如果⼀个⼆叉树的层数为K，且结点总数是(2^k) -1 ，则它就是满⼆叉树。 一个层数为k 的满二叉树总结点数为：。因此满二叉树的结点数一定是奇数个。 第i层上的结点数为： 一个层数为k的满二叉树的叶子结点个数（也就是最后一层）：2^(k-1) 完全二叉树一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。 如果遇到一个结点，左孩子为空，右孩子不为空，则该树一定不是完全二叉树； 如果遇到一个结点，左孩子不为空，右孩子为空；或者左右孩子都为空；则该节点之后的队列中的结点都为叶子节点；该树才是完全二叉树，否则就不是完全二叉树； 二叉查找树（Binary Search Tree）也叫二叉搜索树、二叉排序树。⼆叉查找树的特点： 若任意节点的左⼦树不空，则左⼦树上所有结点的 值均⼩于它的根结点的值； 若任意节点的右⼦树不空，则右⼦树上所有结点的值均⼤于它的根结点的值； 任意节点的左、右⼦树也分别为⼆叉查找树； 没有键值相等的节点（no duplicate nodes）。 顺序表做储存的二叉查找树： 按数组下标进行存储，根节点存储在下标0处，其左孩子存储于下标2 * 0 + 1，右孩子存储于下标2 * 0 + 2 …依次类推。 下标为i的节点，左右孩子存储于下标2 * i + 1与2 * i + 2 平衡⼆叉树（Self-balancing binary search tree）平衡二叉树（Balanced Binary Tree）又被称为AVL树（有别于AVL算法），且具有以下性质：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。这个方案很好的解决了二叉查找树退化成链表的问题，把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)。但是频繁旋转会使插入和删除牺牲掉O(logN)左右的时间，不过相对二叉查找树来说，时间上稳定了很多。 推荐阅读：一文读懂平衡二叉树 红黑树 每个节点⾮红即⿊； 根节点总是⿊⾊的； 每个叶⼦节点都是⿊⾊的空节点（NIL节点）； 如果节点是红⾊的，则它的⼦节点必须是⿊⾊的（反之不⼀定）； 从根节点到叶节点或空⼦节点的每条路径，必须包含相同数⽬的⿊⾊节点（即相同的⿊⾊⾼度）。 为什么要⽤红⿊树？简单来说红⿊树就是为了解决⼆叉查找树的缺陷，因为⼆叉查找树在某些情况下会退化成⼀个线性结构。 推荐阅读： 漫画：什么是红黑树？ 红黑树的操作揭秘手册 红黑树深入剖析及Java实现 哈夫曼树 给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。 推荐阅读：漫画：什么是 “哈夫曼树” ？推荐阅读：数据结构——树——哈夫曼树 B树（B-树）B树性质 根结点至少有两个子女； 每个非根节点所包含的关键字个数 j 满足：(m/2) - 1 &lt;= j &lt;= m - 1； 除根结点以外的所有结点（不包括叶子结点）的度数正好是关键字总数加1，故内部子树个数 k 满足：(m/2) &lt;= k &lt;= m ； 所有的叶子结点都位于同一层。 B树特点 B-tree是一种多路搜索树（并不是二叉的），对于一棵M阶树： 定义任意非叶子结点最多只有M个孩子；且M&gt;2； 根结点的孩子数为[2, M]，除非根结点为叶子节点； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 非叶子结点的关键字个数=指向儿子的指针个数-1； 每个非叶子结点存放至少M/2-1（取上整）和至多M-1个关键字； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； 推荐阅读漫画：什么是B-树？ B+树B+ 树是一种树数据结构，是一个n叉树，每个节点通常有多个孩子，一棵B+树包含根节点、内部节点和叶子节点。根节点可能是一个叶子节点，也可能是一个包含两个或两个以上孩子节点的节点。 特点其定义基本与B-树同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； 应用B+ 树通常用于数据库和操作系统的文件系统中。NTFS, ReiserFS, NSS, XFS, JFS, ReFS 和BFS等文件系统都在使用B+树作为元数据索引。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入。 B*树B-tree是B+-tree的变体，在B+树的基础上(所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针)，B树中非根和非叶子结点再增加指向兄弟的指针； B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）。 关于B树类的文章 二叉树学习笔记之B树、B+树、B*树 B-树，B+树，B*树详解 B-树，B+树与B*树的优缺点比较 LSM树（Log-Structured Merge Tree）存储引擎和B树存储引擎一样，同样支持增、删、读、改、顺序扫描操作。而且通过批量存储技术规避磁盘随机写入问题。当然凡事有利有弊，LSM树和B+树相比，LSM树牺牲了部分读性能，用来大幅提高写性能。 因为B+树可能存在大量得随机IO访问 推荐阅读：LSM树由来、设计思想以及应用到HBase的索引 树的遍历 前序遍历:先访问根节点，再访问左子节点，最后访问右子节点。图中的二叉树的前序遍历的顺序是10、6、4、8、14、12、16。 中序遍历:先访问左子节点，再访问根节点，最后访问右子节点。图中的二叉树的中序遍历的顺序是4、6、8、10、12、14、16。 后序遍历:先访问左子节点，再访问右子节点，最后访问根节点。图中的二叉树的后序遍历的顺序是4、8、6、12、 16、14、10。 推荐阅读: 二叉树遍历（前序、中序、后序）- Java实现","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://blog.unclezs.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"tree","slug":"tree","permalink":"https://blog.unclezs.com/tags/tree/"},{"name":"树","slug":"树","permalink":"https://blog.unclezs.com/tags/%E6%A0%91/"},{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"数据结构之Map","slug":"数据结构/数据结构之Map","date":"2020-07-26T10:00:25.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之Map.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BMap.html","excerpt":"HashMap简介在Java中，HashMap是Map的最常用的。HashMap主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。与HashTable主要区别为不支持同步和允许null作为key和value，所以如果你想要保证线程安全，可以使用ConcurrentHashMap代替而不是线程安全的HashTable，因为HashTable基本已经被淘汰 版本差异JDK1.8之前JDK1.8之前，HashMap使用了拉链法解决冲突。也就是在Hash冲突的时候，直接将冲突的加入链表即可缺陷：如果散列分布不均匀，导致大量不同数据都有同一个Hash地址，这样拉链法的这个链表就会很长了，如果过于长，会降低HashMap的性能。 JDK1.8之后为了解决当链表过长出现的性能问题，HashMap采用拉链法+红黑树的方式解决冲突。也就是首先使用拉链法的方式，当链表长度达到一定长度之后(默认为8)，就将链表转换成红黑树。 源码探究以下都来自JDK1.8","text":"HashMap简介在Java中，HashMap是Map的最常用的。HashMap主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。与HashTable主要区别为不支持同步和允许null作为key和value，所以如果你想要保证线程安全，可以使用ConcurrentHashMap代替而不是线程安全的HashTable，因为HashTable基本已经被淘汰 版本差异JDK1.8之前JDK1.8之前，HashMap使用了拉链法解决冲突。也就是在Hash冲突的时候，直接将冲突的加入链表即可缺陷：如果散列分布不均匀，导致大量不同数据都有同一个Hash地址，这样拉链法的这个链表就会很长了，如果过于长，会降低HashMap的性能。 JDK1.8之后为了解决当链表过长出现的性能问题，HashMap采用拉链法+红黑树的方式解决冲突。也就是首先使用拉链法的方式，当链表长度达到一定长度之后(默认为8)，就将链表转换成红黑树。 源码探究以下都来自JDK1.8 核心成员public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; // 序列号 private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v&gt;[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容 int threshold; // 装填因子 final float loadFactor; &#125; 其中的MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 相当于是2的30次方。int一共32位，为什么不左移31位呢，也是2的幂次。原因就是因为31位为符号位，如果左移31位了就会是一个负数了，所以只能左移31位。 loadFactor就是装填因子，具体可以查看哈希表的那篇博文，HashMap默认设置为0.75f。 threshold，也就是容量阈值，就是装到了多少比例了再扩容，当作变量是不用每次都计算。只在容量变化时候计算。 树节点与链表节点 链表节点static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; // 哈希值，存放元素到hashmap中时用来与其他元素hash值比较 final int hash; final K key; V value; // 指向下一个节点 Node&lt;K,V&gt; next; &#125; 红黑树节点static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; // needed to unlink next upon deletion TreeNode&lt;K,V&gt; prev; // 是否为红色节点 boolean red; &#125; 增删查方法1.put与putVal public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果还没有初始化就进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //这里对hash值进行取余，保证hash的地址在数组长度以内，并且确定存放在哪个桶中，如果桶为空，则新的节点就放入桶中（在数组中的） if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //证明此时桶不为空 else &#123; Node&lt;K,V&gt; e; K k; //桶的第一个元素hash值和key值和新的节点一样 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //hash值不相等，即key不相等； //为红黑树结点 时候 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //为链表结点 时候 else &#123; //遍历到最后一个节点，将新的节点插入尾部 for (int binCount = 0; ; ++binCount) &#123; //没有下一个节点了则到尾部了 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果链表长度到达了阈值，则转化成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //遍历到的链表中的这个节点hash值和key值和新的节点一样，发现存在了，跳出循环。当前e为这个重复的节点。p为上一个节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //切换父节点为当前节点，做遍历 p = e; &#125; &#125; //e的值存在 if (e != null) &#123; // existing mapping for key V oldValue = e.value; //只有在值不存（onlyIfAbsent=false）在的或者为Null的时候才更新 if (!onlyIfAbsent || oldValue == null) e.value = value; // 访问后回调 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //判断是否需要扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null; &#125; 可以看到put方法只是对key进行了hash，然后调用了putVal方法，核心的添加逻辑还是在putVal方法里面。因为putTreeVal有添加树节点和红黑树的转换，不是这里的重点，具体可以查看红黑树那篇。 remove与removeNode public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //hash表已经初始化，并且这个位置有节点，才进入逻辑 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //桶中第一个元素key和hash值与新来的key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //不相等的时候，如果存下一个节点 else if ((e = p.next) != null) &#123; //桶中第一个节点节点为树节点时,拿到这个要删除的节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); //为链表时 else &#123; //遍历链表，直到找到 do &#123; if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //这个key对应的节点存在，并且不匹配值，或者值与期望的值相等，则进行删除。 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||(value != null &amp;&amp; value.equals(v)))) &#123; //如果是树节点，就调用删除树节点的方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果是第一个节点，那就把节点前移 ，桶中第一个节点变为下一个节点 else if (node == p) tab[index] = node.next; //否则 直接把节点前移 else p.next = node.next; ++modCount; --size; //一处后的回调 afterNodeRemoval(node); return node; &#125; &#125; //没有找到这个key则直接返回null return null; &#125; get与getNode public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //hash表已经初始化，并且这个位置有节点，才进入逻辑 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果桶中第一个就是了，直接返回 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果存在下一个节点 if ((e = first.next) != null) &#123; //桶中第一个如果是树节点。直接查找树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //不是的话就遍历链表，知道找到为止 do &#123; if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; //没有找到返回null return null; &#125; hash表扩容当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。 扩容条件就是当threshold=loadFactory*capacity大于等于hash表当前的节点个数 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //旧的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //旧的阈值 int oldThr = threshold; //新的容量与阈值 int newCap, newThr = 0; //如果初始化过了 if (oldCap &gt; 0) &#123; //如果旧的容量大于了最大的容量 2的30次方，装不下了，不再扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //设置为最大，后续不再进入此方法了 threshold = Integer.MAX_VALUE; return oldTab; &#125; //两倍扩容 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //未初始化的时候 //初始阈值大于0则将新的容量设置为旧的阈值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //否则使用默认的容量进行初始化新的容量 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; //计算新的阈值 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //计算新的阈值，如果新的阈值为0的话 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //更新新的阈值 threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历每个桶，拷贝到新的hash数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果桶不为空 if ((e = oldTab[j]) != null) &#123; //释放以前节点的空间 oldTab[j] = null; //这个桶只有这一个节点 if (e.next == null) //直接把这个节点放到新的桶里 newTab[e.hash &amp; (newCap - 1)] = e; //不只有一个节点 //是树节点的时候 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //为链表的时候 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //遍历桶的所有节点 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 对于以上的为链表时候的扩容源码解读，因为一两句说不清楚，推荐阅读深入理解HashMap(四): 关键源码逐行分析之resize扩容 线程不安全可能引发的链表成环问题(JDk1.7)推荐阅读大多数人不知道的：HashMap链表成环的原因和解决方案 HashTableHashTable和HashMap的实现原理几乎一样，差别无非是 HashTable不允许key和value为null； HashTable是线程安全的。 但是HashTable线程安全的策略实现代价却太大了，简单粗暴，get/put所有相关操作都是synchronized的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。 CurrentHashMap介绍 JDK1.7 HashTable性能差主要是由于所有操作需要竞争同一把锁，而如果容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。这就是ConcurrentHashMap所采用的”分段锁”思想。 JDK1.8取消segments字段，直接采用transient volatile HashEntry&lt;K,V&gt;[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，并发控制使用Synchronized和CAS来操作 区别从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树，总结如下： JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8实现降低锁的粒度就是HashEntry（首节点） JDK1.8版本的数据结构变得更加简单，去掉了Segment这种数据结构，使用synchronized来进行同步锁粒度降低，所以不需要分段锁的概念，实现的复杂度也增加了 JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档 JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock： 低粒度加锁方式，synchronized并不比ReentrantLock差，粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了 JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存 TreeMapTreeMap底层为红黑树，线程不安全的，如果需要使用请使用线程安全的，可以使用 Collections.synchronizedSortedMap(); Collections.synchronizedMap(new TreeMap()); 参考 集合框架源码学习之HashMap(JDK1.8) ConcurrentHashMap实现原理及源码分析","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"map","slug":"map","permalink":"https://blog.unclezs.com/tags/map/"}]},{"title":"数据结构之哈希表","slug":"数据结构/数据结构之哈希表","date":"2020-07-26T09:15:29.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之哈希表.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%93%88%E5%B8%8C%E8%A1%A8.html","excerpt":"关于哈希HashHash，一般翻译做散列、杂凑，或音译为哈希，是把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来确定唯一的输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。白话：给你一(多)个字符串(数据)，你根据字符串生产一个唯一的hash数 常用Hash函数直接寻址法取关键字或关键字的某个线性函数值为散列地址，即H(key)=key或H(key) = a·key + b，其中a和b为常数 数字分析法分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。 平方取中法取关键字平方后的中间几位作为散列地址。 折叠法","text":"关于哈希HashHash，一般翻译做散列、杂凑，或音译为哈希，是把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来确定唯一的输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。白话：给你一(多)个字符串(数据)，你根据字符串生产一个唯一的hash数 常用Hash函数直接寻址法取关键字或关键字的某个线性函数值为散列地址，即H(key)=key或H(key) = a·key + b，其中a和b为常数 数字分析法分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。 平方取中法取关键字平方后的中间几位作为散列地址。 折叠法将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。 随机数法选择一随机函数，取关键字作为随机函数的种子生成随机值作为散列地址，通常用于关键字长度不同的场合。 除留余数法取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即 H(key) = key MOD p,p&lt;=m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生碰撞。 处理Hash冲突方案哈希冲突即是，不同的数据，经过同一个hash函数，生成了同一个hash值。 开放寻址法Hi=(H(key) + di) MOD m，i=1,2,…，k(k&lt;=m-1)，其中H(key)为散列函数，m为散列表长，di为增量序列，可有下列三种取法： di=1,2,3,…，m-1，称线性探测再散列； di=1^2,-1^2,2^2,-2^2,3^2,…，±k^2,(k&lt;=m/2)称二次探测再散列； di=伪随机数序列，称伪随机探测再散列。 说的通俗一点，如果这个Hash冲突了，则根据上诉计算方式，尝试寻找下一个没有被占用地址的位置，就比如hash计算出来得1，则array[1]里面已经本占用了，这个时候可以根据方法1，计算得到下一个地址为2，如果2地址也被占用了，则3以此类推。直到找到没有被占用得即可。 再散列法（再哈希）Hi=RHi(key),i=1,2,…，k RHi均是不同的散列函数，即在同义词产生地址冲突时计算另一个散列函数地址，直到冲突不再发生，这种方法不易产生“聚集”，但增加了计算时间。 链地址法(拉链法)拉链法就是用一个数组存hash过后的地址值，地址值后面存这个hash值得链表，当hash冲突之后，则只需要将冲突的数据连接到这个链表之后就行了，这样有个问题就是增加了空间成本，而且还有个问题就是查找可能出现问题。当某个hash值冲突严重的时候，这个链表可能会非常的长，如果查找一个数据就需要根据hash找到链表，然后遍历链表找到真正的数据。所以可能性能上有些影响，在Java(1.8)的HashMap里面，是在链表长度到达一定长度之后，链表转化成了红黑树。 建立公共溢出区建立一个公共溢出区域，就是把冲突的都放在另一个地方，不在表里面。 平均查找长度与装填因子 平均查找长度为确定记录在查找表中的位置，需和给定值进行比较的关键字个数的期望值称为查找算法在查找成功时的平均查找长度()，ASL成功。在查找表中查找不到待查元素，但是找到待查元素应该在表中存在的位置的平均查找次数称为查找不成功时的平均查找长度，不成功。 装填因子散列表的装填因子定义为：α= 填入表中的元素个数/散列表的长度装填因子越大，说明hash表装的越多，冲突出现越大。 影响Hash表性能的因素 因素 散列函数是否均匀； 处理冲突的方法； 散列表的装填因子。 著名Hash算法 MD4 MD5 SHA-1 用Java实现Hash表使用了开放地址法和拉链法。 /** * Hash表的Java实现 * @author unclezs.com * @date 2019.06.04 18:51 */ public class MyHashTable&lt;K, V&gt; &#123; private int num = 0;//索引使用数量 private int capacity;//容量 private Node&lt;K, V&gt;[] table;//散列表 private int mode = 1;//处理冲突方式 1开放地址法，2链表储存法 private double eRate = 0.8;//扩容因子（达到容量的多少比例后扩容） private int hashMode;//哈希值生成函数选择 private int conflictsNum;//冲突次数 private int linkNodeNum;//链式储存时当前节点个数 private int queryNum;//查询一次比较次数 //默认容量16 public MyHashTable() &#123; this(16); &#125; //构建散列表 public MyHashTable(int capacity) &#123; this.capacity = capacity; table = new Node[capacity]; &#125; /** * 高级构造 * * @param capacity 容量 * @param mode 处理冲突方式 * @param eRate 扩容因子 */ public MyHashTable(int capacity, int mode, double eRate, int hashMode) &#123; this(capacity); this.mode = mode; this.eRate = eRate; this.hashMode = hashMode; &#125; //散列函数 public int hash(K key) &#123; if (hashMode == 1) &#123;//余数法 return (key.hashCode() &amp; 0x7fffffff); &#125; else &#123;//折叠法+余数法 int code = key.hashCode() &amp; 0x7fffffff; //1865644118 int h = code / 1000000;//186 h += code / 1000 % 1000;//564 h += code % 1000;//118 return h; &#125; &#125; //添加数据（三种情况，还没有初始化hash表，初始化了但是hash值冲突，key相同） public void put(K k, V v) &#123; //自动扩容，2倍扩容 if (num &gt; eRate * capacity &amp;&amp; mode == 1) &#123; resize(capacity * 2); &#125; int hash = hash(k);//计算哈希值 int index = indexFor(hash);//计算索引 //如果没有冲突 if (table[index] == null) &#123; table[index] = new Node&lt;&gt;(k, v, hash); linkNodeNum++; conflictsNum++; &#125; else if (mode == 1) &#123;//开放地址法解决冲突 if (hash == table[index].hash &amp;&amp; (k.equals(table[index].getKey()))) &#123;//如果键的值一样且与上次hash值相同则更新 table[index].setValue(v); conflictsNum++; return; &#125; else &#123;//确认为冲突 while (table[index] != null) &#123; conflictsNum++; //找到可以插入的索引 index = (index + 1) % capacity; &#125; table[index] = new Node&lt;&gt;(k, v, hash); &#125; &#125; else if (mode == 2) &#123;//链式储存法解决冲突 //判断是否为过更新 Node&lt;K, V&gt; node = table[index]; while (node.next != null &amp;&amp; !node.getKey().equals(k)) &#123;//遍历找到末尾节点或者找到键值相同的节点 node = node.next; conflictsNum++; &#125; if (node.getKey().equals(k)) &#123; node.setValue(v); return; &#125; //非更新 linkNodeNum++; conflictsNum++; node.next = new Node&lt;K, V&gt;(k, v, hash); return; &#125; num++;//当前表中索引使用数量增加 &#125; //删除数据 public void remove(K k) &#123; &#125; /** * 查询数据 * * @param k key值 * @return 没找到返回null */ public V get(K k) &#123; queryNum = 1; int hash = hash(k); int index = indexFor(hash); Node&lt;K, V&gt; node = table[index]; if (node == null) &#123; return null; &#125; //开放地址法 if (mode == 1) &#123; //如果当前索引处node为空了并且还没有找到与键值匹配的关键字则跳出循环 while (table[index] != null &amp;&amp; !k.equals(table[index].getKey())) &#123; index = (index + 1) % capacity; queryNum++; &#125; return table[index] == null ? null : table[index].getValue(); &#125; else &#123;//链式储存法 while (node.next != null &amp;&amp; !k.equals(node.getKey())) &#123; node = node.next; queryNum++; &#125; if (k.equals(node.getKey())) &#123; return node.getValue(); &#125; return null; &#125; &#125; //获取index private int indexFor(int hash) &#123; return hash % capacity; &#125; //获取当前表中数量,1线性探测法,2链式法 public int getNum(int type) &#123; return type == 1 ? num : linkNodeNum; &#125; //获取容量 public int getCapacity() &#123; return capacity; &#125; //获取冲突次数 public int getConflictsNum() &#123; return conflictsNum; &#125; /** * 更改处理冲突模式 * * @param mode 1开放地址法，2链表储存法 */ public void setMode(int mode) &#123; this.mode = mode; &#125; //获取本次查询比较次数 public int getQueryNum() &#123; return queryNum; &#125; //重新设置大小 public void resize(int capacity) &#123; //如果传入容量小于当前容量则不处理 int size = this.capacity; if (capacity &lt; this.capacity) &#123; return; &#125; conflictsNum = 0; num = 0; this.capacity = capacity; //数据迁移 Node&lt;K, V&gt;[] oldTab = table; table = new Node[capacity]; for (int i = 0; i &lt; size; i++) &#123; if (oldTab[i] != null) &#123; put(oldTab[i].getKey(), oldTab[i].getValue()); &#125; &#125; &#125; //自定义节点类 static class Node&lt;K, V&gt; &#123; final K key;//键 final int hash;//哈希值 V value;//值 Node&lt;K, V&gt; next;//链表处理冲突时用 Node(K k, V v, int hash) &#123; this.key = k; this.value = v; this.hash = hash; this.next = null; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; @Override public final int hashCode() &#123; return key.hashCode() ^ value.hashCode(); &#125; @Override public final boolean equals(Object o) &#123; Node&lt;?, ?&gt; e = (Node&lt;?, ?&gt;) o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; return false; &#125; @Override public final String toString() &#123; return key + &quot;=&quot; + value; &#125; &#125; &#125; 参考 解决Hash冲突四种方法 百度百科 集合框架源码学习之HashMap(JDK1.8)","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"哈希表","slug":"哈希表","permalink":"https://blog.unclezs.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"hash","slug":"hash","permalink":"https://blog.unclezs.com/tags/hash/"},{"name":"开放地址法","slug":"开放地址法","permalink":"https://blog.unclezs.com/tags/%E5%BC%80%E6%94%BE%E5%9C%B0%E5%9D%80%E6%B3%95/"},{"name":"拉链法","slug":"拉链法","permalink":"https://blog.unclezs.com/tags/%E6%8B%89%E9%93%BE%E6%B3%95/"}]},{"title":"数据结构之栈Stack","slug":"数据结构/数据结构之栈Stack","date":"2020-07-26T08:35:38.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之栈Stack.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%88Stack.html","excerpt":"什么是栈栈是一种用于存储数据的简单数据结构，有点类似链表或者顺序表（统称线性表），栈与线性表的最大区别是数据的存取的操作，我们可以这样认为栈(Stack)是一种特殊的线性表，其插入和删除操作只允许在线性表的一端进行，一般而言，把允许操作的一端称为栈顶(Top)，不可操作的一端称为栈底(Bottom)，同时把插入元素的操作称为入栈(Push),删除元素的操作称为出栈(Pop)。若栈中没有任何元素，则称为空栈 Java中的栈Stack介绍Stack继承于Vector，所以也是线程安全的。 源码Stack的源码比较简单，主要功能全部依赖与Vector方法实现。 public class Stack&lt;E&gt; extends Vector&lt;E&gt; &#123; public E push(E item) &#123; addElement(item); return item; &#125; public synchronized E pop() &#123; E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; &#125; public synchronized E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; public boolean empty() &#123; return size() == 0; &#125; public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1; &#125; &#125; 附录参考 java数据结构与算法之栈（Stack）设计与实现","text":"什么是栈栈是一种用于存储数据的简单数据结构，有点类似链表或者顺序表（统称线性表），栈与线性表的最大区别是数据的存取的操作，我们可以这样认为栈(Stack)是一种特殊的线性表，其插入和删除操作只允许在线性表的一端进行，一般而言，把允许操作的一端称为栈顶(Top)，不可操作的一端称为栈底(Bottom)，同时把插入元素的操作称为入栈(Push),删除元素的操作称为出栈(Pop)。若栈中没有任何元素，则称为空栈 Java中的栈Stack介绍Stack继承于Vector，所以也是线程安全的。 源码Stack的源码比较简单，主要功能全部依赖与Vector方法实现。 public class Stack&lt;E&gt; extends Vector&lt;E&gt; &#123; public E push(E item) &#123; addElement(item); return item; &#125; public synchronized E pop() &#123; E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; &#125; public synchronized E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; public boolean empty() &#123; return size() == 0; &#125; public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1; &#125; &#125; 附录参考 java数据结构与算法之栈（Stack）设计与实现","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://blog.unclezs.com/tags/%E6%A0%88/"},{"name":"stack","slug":"stack","permalink":"https://blog.unclezs.com/tags/stack/"}]},{"title":"数据结构之列表List","slug":"数据结构/数据结构之列表List","date":"2020-07-26T07:35:58.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之列表List.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%88%97%E8%A1%A8List.html","excerpt":"什么是List在 List 中，⽤户可以精确控制列表中每个元素的插⼊位置，另外⽤户可以通过整数索引（列表中的位置）访问元素，并搜索列表中的元素。 与 Set 不同，List 通常允许重复的元素。 另外 List 是有序集合⽽ Set 是⽆序集合。 ArrayList介绍ArrayList是一个Java日常开发中经常使用到的类，底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 在我们学数据结构的时候就知道了线性表的顺序存储，插入删除元素的时间复杂度为O(n）,求表长以及增加元素，取第 i 元素的时间复杂度为O(1） 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 实现了RandomAccess 接口， RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。 线程不安全，所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 扩容机制解释","text":"什么是List在 List 中，⽤户可以精确控制列表中每个元素的插⼊位置，另外⽤户可以通过整数索引（列表中的位置）访问元素，并搜索列表中的元素。 与 Set 不同，List 通常允许重复的元素。 另外 List 是有序集合⽽ Set 是⽆序集合。 ArrayList介绍ArrayList是一个Java日常开发中经常使用到的类，底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 在我们学数据结构的时候就知道了线性表的顺序存储，插入删除元素的时间复杂度为O(n）,求表长以及增加元素，取第 i 元素的时间复杂度为O(1） 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 实现了RandomAccess 接口， RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 实现了Cloneable 接口，即覆盖了函数 clone()，能被克隆。 实现java.io.Serializable 接口，这意味着ArrayList支持序列化，能通过序列化去传输。 线程不安全，所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者 CopyOnWriteArrayList。 扩容机制解释ArrayList在添加数据的时候会判断是否大于容量，如果大于了当前数组的容量，则进行扩容，每次扩容的容量为当前容量的1.5倍。如果每次增加一个，这个效率肯定不高的。 数组容量不能超过Integer.MAX_VALUE-8;如果超过则会OOM。因为对象头里面会存储_length字段，而这个字段长度为8，所以要减去8； 源码private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; 关于快速删除在ArrayList源码中可以看到有个fastRemove方法，这个方法为甚么叫快速删除呢，是因为直接调用了System.arraycopy方法，这样就不用考虑数组的边界问题而且还不用有返回值。 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; 关于内部类中的迭代器 Itr 其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()， next()， remove() 等方法； ListItr 继承 Itr，实现了ListIterator接口，同时重写了hasPrevious()， nextIndex()， previousIndex()， previous()， set(E e)， add(E e) 等方法。 可以看出了 Iterator和ListIterator的区别: ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。 Vector介绍Vector相当于是线程安全的ArrayList，实现线程安全的方法也就是在每个修改数组的方法上面加上了一个Synchronized方法，所以效率很低，现在一般使用Collections.syschronizedList方法来创建线程安全的集合。 扩容机制解释与ArrayList有所不同，Vector设置了一个自己的扩容数量capacityIncrement，通过设置这个的大小，可以默认让Vector每次扩容这么多，如果不设置，则就以默认的2倍进行扩容。 源码private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); &#125; 动手实现ArrayList/** * @author unclezs.com * @date 2019.06.03 14:40 */ public class MyList&lt;T&gt; implements Serializable &#123; /** * 元素 */ Object[] elementData = &#123;&#125;; private static final Object[] EMPTY_ELEMENT_DATA = &#123;&#125;; /** * 容量 */ private static int capacity = 10; /** * 当前元素个数 */ private int size = 0; /** * 泛型转化 * * @param capacity 容量 */ public MyList(int capacity) &#123; if (capacity &gt; 0) &#123; elementData = new Object[capacity]; &#125; else if (capacity == 0) &#123; elementData = EMPTY_ELEMENT_DATA; &#125; else &#123; throw new IllegalArgumentException(&quot;参数错误&quot;); &#125; &#125; public MyList() &#123; this(capacity); &#125; /** * 当前容量 * * @return size */ public int size() &#123; return size; &#125; /** * 检测是否满了，满了则扩容 */ private void checkAndExpansion() &#123; if (size + 1 &gt; capacity) &#123; this.elementData = Arrays.copyOf(elementData, size * 2); &#125; &#125; /** * 泛型转化 * * @param index 索引 * @return 泛型对象 */ @SuppressWarnings(&quot;unchecked&quot;) private T elementData(int index) &#123; return (T) elementData[index]; &#125; /** * 指定下标设置值 * * @param index 索引 * @param o 元素 */ public void set(int index, T o) &#123; checkAndExpansion(); elementData[index] = o; &#125; /** * 在尾部添加一个元素 * * @param o 元素 */ public void add(T o) &#123; checkAndExpansion(); elementData[size++] = o; &#125; /** * 移除一个元素 * * @param index 索引 */ public void remove(int index) &#123; System.arraycopy(elementData, index + 1, elementData, index, size - index - 1); size--; &#125; /** * 根据下标查询 * * @param index / * @return / */ public T get(int index) &#123; checkAndExpansion(); return elementData(index); &#125; /** * 清空集合 */ public void clear() &#123; this.size = 0; elementData = new Object[capacity]; &#125; /** * 添加一个集合 * * @param myList / */ public void addAll(MyList&lt;T&gt; myList) &#123; if (myList == null || myList.size() == 0) &#123; return; &#125; for (int i = 0; i &lt; myList.size(); i++) &#123; this.add(myList.get(i)); &#125; &#125; /** * 查看是否有这个元素元素 * * @param e 元素 * @return / */ public boolean isExist(T e) &#123; for (Object elementDatum : elementData) &#123; if (e.equals(elementDatum)) &#123; return true; &#125; &#125; return false; &#125; /** * 查找元素下标 * * @param t 元素 * @return / */ public int indexOf(T t) &#123; if (t == null) &#123; return -1; &#125; for (int i = 0; i &lt; elementData.length; i++) &#123; if (elementData[i] != null &amp;&amp; t.equals(elementData[i])) &#123; return i; &#125; &#125; return -1; &#125; @Override public String toString() &#123; return Arrays.toString(elementData); &#125; &#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"list","slug":"list","permalink":"https://blog.unclezs.com/tags/list/"},{"name":"列表","slug":"列表","permalink":"https://blog.unclezs.com/tags/%E5%88%97%E8%A1%A8/"}]},{"title":"数据结构之Set","slug":"数据结构/数据结构之Set","date":"2020-07-26T07:02:05.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之Set.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BSet.html","excerpt":"Set集合Set 继承于 Collection 接⼝，是⼀个不允许出现重复元素，并且⽆序的集合，主要 HashSet 和TreeSet 两⼤实现类。在判断重复元素的时候，HashSet 集合会调⽤ hashCode()和 equal()⽅法来实现；TreeSet 集合会调⽤compareTo⽅法来实现。 HashSet介绍HashSet 是哈希表结构，主要利⽤ HashMap 的 key 来存储元素,value为一个静态常量Object，计算插⼊元素的 hashCode 来获取元,素在集合中的位置； 此类允许null元素。 拓展 LinkedHashSet，基于LinkedHashMap，实现保证插入的顺序和输出的顺序是一样的。 ConcurrentHashSet，一个线程安全的 TreeSet介绍与HashSet不同的是，TreeSet具有排序功能，分为自然排序(123456)和自定义排序两类，默认是自然排序；在程序中，我们可以按照任意顺序将元素插入到集合中，等到遍历时TreeSet会按照一定顺序输出–倒序或者升序；","text":"Set集合Set 继承于 Collection 接⼝，是⼀个不允许出现重复元素，并且⽆序的集合，主要 HashSet 和TreeSet 两⼤实现类。在判断重复元素的时候，HashSet 集合会调⽤ hashCode()和 equal()⽅法来实现；TreeSet 集合会调⽤compareTo⽅法来实现。 HashSet介绍HashSet 是哈希表结构，主要利⽤ HashMap 的 key 来存储元素,value为一个静态常量Object，计算插⼊元素的 hashCode 来获取元,素在集合中的位置； 此类允许null元素。 拓展 LinkedHashSet，基于LinkedHashMap，实现保证插入的顺序和输出的顺序是一样的。 ConcurrentHashSet，一个线程安全的 TreeSet介绍与HashSet不同的是，TreeSet具有排序功能，分为自然排序(123456)和自定义排序两类，默认是自然排序；在程序中，我们可以按照任意顺序将元素插入到集合中，等到遍历时TreeSet会按照一定顺序输出–倒序或者升序； 它继承AbstractSet，实现NavigableSet, Cloneable, Serializable接口。 （1）与HashSet同理，TreeSet继承AbstractSet类，获得了Set集合基础实现操作； （2）TreeSet实现NavigableSet接口，而NavigableSet又扩展了SortedSet接口。这两个接口主要定义了搜索元素的能力，例如给定某个元素，查找该集合中比给定元素大于、小于、等于的元素集合，或者比给定元素大于、小于、等于的元素个数；简单地说，实现NavigableSet接口使得TreeSet具备了元素搜索功能； （3）TreeSet实现Cloneable接口，意味着它也可以被克隆； （4）TreeSet实现了Serializable接口，可以被序列化，可以使用hessian协议来传输； 具有如下特点： 对插入的元素进行排序，是一个有序的集合（主要与HashSet的区别） 底层使用红黑树结构，而不是哈希表结构 允许插入Null值 不允许插入重复元素 线程不安全 拓展 SortedSet，一个有序Set的接口，是所有有序集合的父类。 CopyOnWriteArraySet基于CopyOnWriteArrayList实现，每次添加都会去遍历LIst中是否存在元素，如果存在则不添加。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"set","slug":"set","permalink":"https://blog.unclezs.com/tags/set/"}]},{"title":"数据结构之队列","slug":"数据结构/数据结构之队列","date":"2020-07-25T12:47:15.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据结构/数据结构之队列.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%98%9F%E5%88%97.html","excerpt":"什么是队列队列是数据结构中⽐᫾重要的⼀种类型，它⽀持 FIFO，尾部添加、头部删除（先进队列的元素先出队列），跟我们⽣活中的排队类似。因为队列是线性表，所以队列也有类似线性表的各种操作，不同的就是插入数据只能在队尾进行，删除数据只能在队头进行。 队列的种类单队列 单队列就是常⻅的队列, 每次添加元素时，都是添加到队尾，存在“假溢出”的问题也就是明明有位置却不能添加的情况 假溢出 假设是长度为5的数组，初始状态，空队列如所示，front与 rear指针均指向下标为0的位置。然后入队a1、a2、a3、a4, front指针依然指向下标为0位置，而rear指针指向下标为4的位置。 出队a1、a2，则front指针指向下标为2的位置，rear不变，如下图所示，再入队a5，此时front指针不变，rear指针移动到数组之外。嗯？数组之外，那将是哪里？ 问题还不止于此。假设这个队列的总个数不超过5个，但目前如果接着入队的话，因数组末尾元素已经占用，再向后加，就会产生数组越界的错误，可实际上，我们的队列在下标为0和1的地方还是空闲的。我们把这种现象叫做“假溢出”。 循环队列 解决假溢出的办法就是后面满了，就再从头开始，也就是头尾相接的循环。我们把队列的这种头尾相接的顺序存储结构称为循环队列。 解决 rear可以改为指向下标为0的位置，这样就不会造成指针指向不明的问题了。 但是这个时候，如果继续插入a6、a7的话，指针rear就会与front重合了。 这个时候新的问题来了，就是rear=front的时候，队列是空了还是满了？有两种解决方案 设置一个标志变量flag，当front == rear,且flag = 0时为队列空，当front == rear,且flag= 1时为队列满。 当队列空时，条件就是from = rear，当队列满时，我们修改其条件，保留一个元素空间。也就是说，队列满时，数组中还有一个空闲单元。 如下图所示，我们就认为此队列已经满了，也就是说，我们不允许上图情况出现。 说说第二种方法，由于rear可能比front大，也可能比front小，所以尽管它们只相差一个位置时就是满的情况，但也可能是相差整整一圈。所以若队列的最大尺寸为QueueSize，那么队列满的条件是(rear+1) %QueueSize == front (取模“%的目的就是为了整合rear与front大小为一个问题)。QueueSize = 5，当 front=0，而 rear=4, (4+1) %5 = 0，所以此时队列满。再比如，front = 2而rear =1。(1 + 1) %5 = 2，所以此时 队列也是满的。而对于下图, front = 2而rear= 0, (0+1) %5 = 1，1!=2,所以此时队列并没有满。 队列长度计算当rear &gt; front时，此时队列的长度为rear-front。但当rear &lt; front时，队列长度分为两段，一段是QueueSize-front，另一段是0 + rear，加在一起，队列长度为rear-front + QueueSize，因此通用的计算队列长度公式为：(rear—front + QueueSize) % QueueSize Java实现 /** * 循环队列 * * @author blog.unclezs.com * @date 2020/7/26 9:37 */ public class CycleQueue&lt;E&gt; &#123; private int rear = 0; private int front = 0; private final Object[] elementData; public CycleQueue(int len) &#123; this.elementData = new Object[len + 1]; &#125; public void add(E e) &#123; if (isFull()) &#123; throw new RuntimeException(&quot;队列满了&quot;); &#125; else &#123; elementData[rear++] = e; if (rear == elementData.length) &#123; rear = 0; &#125; &#125; &#125; /** * 取出队头 并且删除 * * @return 队头元素 */ @SuppressWarnings(&quot;unchecked&quot;) public E poll() &#123; Object value = elementData[front]; elementData[front++] = null; if (front == elementData.length) &#123; front = 0; &#125; return (E) value; &#125; /** * 判断队列满了没有 * * @return / */ public boolean isFull() &#123; return (rear + 1) % elementData.length == front; &#125; /** * 当前队列长度 * * @return / */ public int size() &#123; return (rear - front + elementData.length) % elementData.length; &#125; &#125; 单是顺序存储，若不是循环队列，算法的时间性能是不高的，但循环队列又面临着数组可能会溢出的问题，所以我们还需要研究一下不需要担心队列长度的链式存储结构。","text":"什么是队列队列是数据结构中⽐᫾重要的⼀种类型，它⽀持 FIFO，尾部添加、头部删除（先进队列的元素先出队列），跟我们⽣活中的排队类似。因为队列是线性表，所以队列也有类似线性表的各种操作，不同的就是插入数据只能在队尾进行，删除数据只能在队头进行。 队列的种类单队列 单队列就是常⻅的队列, 每次添加元素时，都是添加到队尾，存在“假溢出”的问题也就是明明有位置却不能添加的情况 假溢出 假设是长度为5的数组，初始状态，空队列如所示，front与 rear指针均指向下标为0的位置。然后入队a1、a2、a3、a4, front指针依然指向下标为0位置，而rear指针指向下标为4的位置。 出队a1、a2，则front指针指向下标为2的位置，rear不变，如下图所示，再入队a5，此时front指针不变，rear指针移动到数组之外。嗯？数组之外，那将是哪里？ 问题还不止于此。假设这个队列的总个数不超过5个，但目前如果接着入队的话，因数组末尾元素已经占用，再向后加，就会产生数组越界的错误，可实际上，我们的队列在下标为0和1的地方还是空闲的。我们把这种现象叫做“假溢出”。 循环队列 解决假溢出的办法就是后面满了，就再从头开始，也就是头尾相接的循环。我们把队列的这种头尾相接的顺序存储结构称为循环队列。 解决 rear可以改为指向下标为0的位置，这样就不会造成指针指向不明的问题了。 但是这个时候，如果继续插入a6、a7的话，指针rear就会与front重合了。 这个时候新的问题来了，就是rear=front的时候，队列是空了还是满了？有两种解决方案 设置一个标志变量flag，当front == rear,且flag = 0时为队列空，当front == rear,且flag= 1时为队列满。 当队列空时，条件就是from = rear，当队列满时，我们修改其条件，保留一个元素空间。也就是说，队列满时，数组中还有一个空闲单元。 如下图所示，我们就认为此队列已经满了，也就是说，我们不允许上图情况出现。 说说第二种方法，由于rear可能比front大，也可能比front小，所以尽管它们只相差一个位置时就是满的情况，但也可能是相差整整一圈。所以若队列的最大尺寸为QueueSize，那么队列满的条件是(rear+1) %QueueSize == front (取模“%的目的就是为了整合rear与front大小为一个问题)。QueueSize = 5，当 front=0，而 rear=4, (4+1) %5 = 0，所以此时队列满。再比如，front = 2而rear =1。(1 + 1) %5 = 2，所以此时 队列也是满的。而对于下图, front = 2而rear= 0, (0+1) %5 = 1，1!=2,所以此时队列并没有满。 队列长度计算当rear &gt; front时，此时队列的长度为rear-front。但当rear &lt; front时，队列长度分为两段，一段是QueueSize-front，另一段是0 + rear，加在一起，队列长度为rear-front + QueueSize，因此通用的计算队列长度公式为：(rear—front + QueueSize) % QueueSize Java实现 /** * 循环队列 * * @author blog.unclezs.com * @date 2020/7/26 9:37 */ public class CycleQueue&lt;E&gt; &#123; private int rear = 0; private int front = 0; private final Object[] elementData; public CycleQueue(int len) &#123; this.elementData = new Object[len + 1]; &#125; public void add(E e) &#123; if (isFull()) &#123; throw new RuntimeException(&quot;队列满了&quot;); &#125; else &#123; elementData[rear++] = e; if (rear == elementData.length) &#123; rear = 0; &#125; &#125; &#125; /** * 取出队头 并且删除 * * @return 队头元素 */ @SuppressWarnings(&quot;unchecked&quot;) public E poll() &#123; Object value = elementData[front]; elementData[front++] = null; if (front == elementData.length) &#123; front = 0; &#125; return (E) value; &#125; /** * 判断队列满了没有 * * @return / */ public boolean isFull() &#123; return (rear + 1) % elementData.length == front; &#125; /** * 当前队列长度 * * @return / */ public int size() &#123; return (rear - front + elementData.length) % elementData.length; &#125; &#125; 单是顺序存储，若不是循环队列，算法的时间性能是不高的，但循环队列又面临着数组可能会溢出的问题，所以我们还需要研究一下不需要担心队列长度的链式存储结构。 链队列队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，我们把它简称为链队列。 java实现/** * 链队列 * * @author blog.unclezs.com * @date 2020/7/26 10:49 */ public class LinkQueue &#123; private Node head; private Node tail; private int size; private static class Node &#123; Node front; Node rear; Object data; public Node(Object data) &#123; this.data = data; &#125; &#125; public void add(Object e) &#123; if (head == null) &#123; head = new Node(e); tail = head; &#125; else &#123; Node last = new Node(e); last.front = tail; tail.rear = last; tail = last; &#125; size++; &#125; public Object poll() &#123; Node value = this.head; head = head.rear; return value; &#125; public int size() &#123; return size; &#125; &#125; Java中的队列以下都是基于JDK1.8版本。 Queue单向队列介绍Queue是Java队列的最高层接口，定义了一些常用的方法 add添加失败抛出异常，offer添加失败不会抛出异常 element取出队头元素不删除，队列为空则抛出NoSuchElementException异常，peek一样作用只是不会抛出异常 remove取出队头元素并且从队列中删除，队列为空则抛出NoSuchElementException异常，poll一样作用只是不会抛出异常 拓展 PriorityQueue优先队列，过传入一个Comparator比较器，来判断队列中元素的优先顺序，所以，队列也不一定全部都是FIFO（先进先出）的。 BlockingQueue 阻塞队列，在操作不可行时的时候阻塞当前线程，比如想要添加一个元素， 但是队列已经满了，阻塞住当前线程直到队列可以添加元素为止，当然也可以传入等待时间。 DelayQueue 一个无界阻塞队列，每个元素有一个延迟时间，如果延迟时间没有到，那么获取不到这个元素，因为队列每次从队列头获取元素，如果队头的元素一直没有到期，那么后面的元素将无法获取到。poll方法如果获取不到已经到期的元素则返回null，take方法会阻塞着一直等到可以获取到到期元素。 SynchronousQueue，一个只能装一个元素的队列，插入元素到队列的线程被阻塞，直到另一个线程从队列中获取了队列中存储的元素。同样，如果线程尝试获取元素并且当前不存在任何元素，则该线程将被阻塞，直到线程将元素插入队列。 ArrayBlockingQueue，一个阻塞有界队列，创建后队列长度将不能改变。 LinkedBlockingQueue，一个阻塞有界链队列，可以指定长度来控制队列长度。如果不指定则默认为Integer.MAX_VALUE Deque双向队列介绍一个双向队列的定义，实现了Queue接口，可以在两端进行插入删除操作，也可以当作栈来用。在Queue基础上添加了一些可以在队列头部进行插入，队列尾部进行删除的方法。 拓展 BlockingDeque，一个阻塞的双向队列，也就是当队列满了之后，将会阻塞等到可以添加再添加。 LinkedList双向链表，这个类比较常用，实现了Deque与List接口。所以也可以当作一个双向队列。 ArrayDeque，双向无界队列，基础数组实现，可以实现自动扩容，与双向链表实现区别在于，对于长度固定的可以使用这个，比较节省内存（没有头尾节点这些，直接存数据） ConcurrentLinkedDeque，线程安全的双向队列，无界的。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"queue","slug":"queue","permalink":"https://blog.unclezs.com/tags/queue/"},{"name":"队列","slug":"队列","permalink":"https://blog.unclezs.com/tags/%E9%98%9F%E5%88%97/"}]},{"title":"TCP的滑动窗口与拥塞控制","slug":"计算机网络/TCP的滑动窗口与拥塞控制","date":"2020-07-24T12:38:37.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/TCP的滑动窗口与拥塞控制.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E7%9A%84%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%8E%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6.html","excerpt":"滑动窗口与流量控制流量控制TCP 利⽤滑动窗⼝实现流量控制。流量控制是为了控制发送⽅发送速率，保证接收⽅来得及接收。 接收⽅发送的确认报⽂中的窗⼝字段可以⽤来控制发送⽅窗⼝⼤⼩，从⽽影响发送⽅的发送速率。将窗⼝字段设置为 0，则发送⽅不能发送数据。 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。","text":"滑动窗口与流量控制流量控制TCP 利⽤滑动窗⼝实现流量控制。流量控制是为了控制发送⽅发送速率，保证接收⽅来得及接收。 接收⽅发送的确认报⽂中的窗⼝字段可以⽤来控制发送⽅窗⼝⼤⼩，从⽽影响发送⽅的发送速率。将窗⼝字段设置为 0，则发送⽅不能发送数据。 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。 在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。 若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。 情况分析当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。 拥塞控制的算法为了进⾏拥塞控制，TCP 发送⽅要维持⼀个 拥塞窗⼝(cwnd) 的状态变量。拥塞控制窗⼝的⼤⼩取决于⽹络的拥塞程度，并且动态变化。发送⽅让⾃⼰的发送窗⼝取为拥塞窗⼝和接收⽅的接受窗⼝中᫾⼩的⼀个。 TCP的拥塞控制采⽤了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在⽹络层也可以使路由器采⽤适当的分组丢弃策略（如主动队列管理 AQM），以减少⽹络拥塞的发⽣。 慢开始慢开始算法的思路是当主机开始发送数据时，如果⽴即把⼤量数据字节注⼊到⽹络，那么可能会引起⽹络阻塞，因为现在还不知道⽹络的符合情况。经验表明，好的⽅法是先探测⼀下，即由⼩到⼤逐渐增⼤发送窗⼝，也就是由⼩到⼤逐渐增⼤拥塞窗⼝数值。cwnd初始值为1，每经过⼀个传播轮次，cwnd加倍。 拥塞避免拥塞避免算法的思路是让拥塞窗⼝cwnd缓慢增⼤，即每经过⼀个往返时间RTT就把发送放的cwnd加1. 快重传与快恢复在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是⼀种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使⽤定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到⼀个不按顺序的数据段，它会⽴即给发送机发送⼀个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并⽴即重传这些丢失的数据段。有了FRR，就不会因为重传时要求的暂停被耽误。 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某⼀段很短的时间内丢失时，它则不能很有效地⼯作。 图解 附录参考：https://blog.csdn.net/qq_41431406/article/details/97926927","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://blog.unclezs.com/tags/tcp/"},{"name":"拥塞控制","slug":"拥塞控制","permalink":"https://blog.unclezs.com/tags/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"}]},{"title":"TCP的三次握手与四次挥手","slug":"计算机网络/TCP的三次握手与四次挥手","date":"2020-07-24T09:23:40.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/TCP的三次握手与四次挥手.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8E%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.html","excerpt":"TCP三次握手三次握⼿的⽬的是建⽴可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，⽽三次握⼿最主要的⽬的就是双⽅确认⾃⼰与对⽅的发送与接收是正常的。 第⼀次握⼿：Client 什么都不能确认；Server 确认了对⽅发送正常，⾃⼰接收正常第⼆次握⼿：Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常；Server 确认了：对⽅发送正常，⾃⼰接收正常第三次握⼿：Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常；Server 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常 所以三次握⼿就能确认双发收发功能都正常，缺⼀不可。 流程 TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态； TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 动图演示 一些问题","text":"TCP三次握手三次握⼿的⽬的是建⽴可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，⽽三次握⼿最主要的⽬的就是双⽅确认⾃⼰与对⽅的发送与接收是正常的。 第⼀次握⼿：Client 什么都不能确认；Server 确认了对⽅发送正常，⾃⼰接收正常第⼆次握⼿：Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常；Server 确认了：对⽅发送正常，⾃⼰接收正常第三次握⼿：Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常；Server 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常 所以三次握⼿就能确认双发收发功能都正常，缺⼀不可。 流程 TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态； TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 动图演示 一些问题为什么不四次握手？ 四次握手的过程就是把第二次握手拆分成了两次，一次服务器响应ACK，再一次发回SYN来确定客户端的接收是否正常。因为握手没有数据传输，所以可以放在一次就可以完成的没有必要用两次。 为什么不两次握手？ 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 TCP四次挥手流程 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗*∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 问题为什么需要四次挥手？ 任何⼀⽅都可以在数据传送结束后发出连接释放的通知，待对⽅确认后进⼊半关闭状态。当另⼀⽅也没有数据再发送的时候，则发出连接&gt;释放通知，对⽅确认后就完全关闭了TCP连接。 举个例⼦：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 &gt;B 跟着⾃⼰的节奏结束通话，于是 B 可能⼜巴拉巴拉说了⼀通，最后B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 为什么客户端最后还要等待2MSL？ MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 如果已经建立了连接，但是客户端突然出现故障了怎么办？ TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 为什么建立连接是三次握手，关闭连接确是四次挥手呢？ 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 TIME_WAIT和CLOSE_WAIT过多什么原因及解决？原因： 在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。 解决： 负载均衡，将请求分发到多个服务器上进行处理。 附录本文参考与动图来自：https://blog.csdn.net/qzcsu/article/details/72861891","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://blog.unclezs.com/tags/tcp/"},{"name":"网络","slug":"网络","permalink":"https://blog.unclezs.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"三次握手","slug":"三次握手","permalink":"https://blog.unclezs.com/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"}]},{"title":"OSI的七层模型","slug":"计算机网络/OSI的七层模型","date":"2020-07-24T08:36:44.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"计算机网络/OSI的七层模型.html","link":"","permalink":"https://blog.unclezs.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/OSI%E7%9A%84%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B.html","excerpt":"体系结构图 七层OSI 物理层(Physical Laye)主要功能：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。作用：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 数据链路层(Data Link Layer)主要功能：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。作用：接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层；并且，还负责处理接收端发回的确认帧的信息，以便提供可靠的数据传输。 网络层(Network Layer)主要功能：通过路由选择算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。作用：解决不同子网间的通信。例如在广域网之间通信时，必然会遇到路由（即两节点间可能有多条路径）选择问题。","text":"体系结构图 七层OSI 物理层(Physical Laye)主要功能：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。作用：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 数据链路层(Data Link Layer)主要功能：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。作用：接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层；并且，还负责处理接收端发回的确认帧的信息，以便提供可靠的数据传输。 网络层(Network Layer)主要功能：通过路由选择算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。作用：解决不同子网间的通信。例如在广域网之间通信时，必然会遇到路由（即两节点间可能有多条路径）选择问题。 运输层(Transport Layer)主要功能：负责向两台主机进程之间的通信提供通⽤的数据传输服务。作用： 传输连接管理：提供建立、维护和拆除传输连接的功能。传输层在网络层的基础上为高层提供“面向连接”和“面向无接连”的两种服务。 处理传输差错：提供可靠的“面向连接”和不太可靠的“面向无连接”的数据传输服务、差错控制和流量控制。在提供“面向连接”服务时，通过这一层传输的数据将由目标设备确认，如果在指定的时间内未收到确认信息，数据将被重发。 会话层(Session Layer)主要功能：向两个实体的表示层提供建立和使用连接的方法。将不同实体之间的表示层的连接称为会话。因此会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。作用： 会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。例如提供单方向会话或双向同时会话，并管理会话中的发送顺序，以及会话所占用时间的长短。 会话流量控制：提供会话流量控制和交叉会话功能。 寻址：使用远程地址建立会话连接。l 出错控制：从逻辑上讲会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠正错误。会话控制和远程过程调用均属于这一层的功能。但应注意，此层检查的错误不是通信介质的错误，而是磁盘空间、打印机缺纸等类型的高级错误。 表示层(Presentation Layer)主要功能：对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。其主要功能是“处理用户信息的表示问题，如编码、数据格式转换和加密解密”等。作用： 数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。 数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。 压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。 数据的加密和解密：可以提高网络的安全性。 应用层(Application Layer)应用层提供的协议有Telnet，SMTP，FTP等等。主要功能：通过应⽤进程间的交互来完成特定⽹络应⽤作用： 用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。 实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。 四层TCP网络接口层 包括用于协作IP数据在已有网络介质上传输的协议。实际上TCP/IP标准并不定义与ISO数据链路层和物理层相对应的功能。相反，它定义像地址解析协议(Address Resolution Protocol,ARP)这样的协议，提供TCP/IP协议的数据结构和实际物理硬件之间的接口。 网间层 对应于OSI七层参考模型的网络层。本层包含IP协议、RIP协议(Routing Information Protocol，路由信息协议)，负责数据的包装、寻址和路由。同时还包含网间控制报文协议(Internet Control Message Protocol,ICMP)用来提供网络诊断信息。 传输层 对应于OSI七层参考模型的传输层，它提供两种端到端的通信服务。其中TCP协议(Transmission Control Protocol)提供可靠的数据流运输服务，UDP协议(Use Datagram Protocol)提供不可靠的用户数据报服务。 应用层 对应于OSI七层参考模型的应用层和表达层。因特网的应用层协议包括Finger、Whois、FTP(文件传输协议)、Gopher、HTTP(超文本传输协议)、Telent(远程终端协议)、SMTP(简单邮件传送协议)、IRC(因特网中继会话)、NNTP（网络新闻传输协议）等，这也是本书将要讨论的重点。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"osi","slug":"osi","permalink":"https://blog.unclezs.com/tags/osi/"}]},{"title":"endorsed覆盖JDK中的类","slug":"Java/基础/endorsed覆盖JDK中的类","date":"2020-07-24T01:42:42.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/endorsed覆盖JDK中的类.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/endorsed%E8%A6%86%E7%9B%96JDK%E4%B8%AD%E7%9A%84%E7%B1%BB.html","excerpt":"介绍endorsed技术是为了覆盖JDK提供的类。但是能够覆盖的类是有限制的，其中不包括java.lang包中的类(出于安全的考虑)。两种方式： 指定VM参数 -Djava.endorsed.dirs 指定的目录面放置的jar文件， 可以在$JAVA_HOME/jre/lib/endorsed目录存放jar文件而不使用VM参数的方式实现。 具体测试VM参数使用Date对象做测试，把Date对象从JDK拷贝出来，再构造中加入 /** * Allocates a &lt;code&gt;Date&lt;/code&gt; object and initializes it to * represent the specified number of milliseconds since the * standard base time known as &quot;the epoch&quot;, namely January 1, * 1970, 00:00:00 GMT. * * @param date the milliseconds since January 1, 1970, 00:00:00 GMT. * @see java.lang.System#currentTimeMillis() */ public Date(long date) &#123; fastTime = date; System.out.println(&quot;创建了时间实例&quot;); &#125; 然后就是jar包，图方便，我直接编译好Date.css，然后创建文件夹java/util/，把class文件放入进去zip后改后缀名xxx.jar。 编写测试： public static void main(String[] args) &#123; System.out.println(new Date()); &#125;","text":"介绍endorsed技术是为了覆盖JDK提供的类。但是能够覆盖的类是有限制的，其中不包括java.lang包中的类(出于安全的考虑)。两种方式： 指定VM参数 -Djava.endorsed.dirs 指定的目录面放置的jar文件， 可以在$JAVA_HOME/jre/lib/endorsed目录存放jar文件而不使用VM参数的方式实现。 具体测试VM参数使用Date对象做测试，把Date对象从JDK拷贝出来，再构造中加入 /** * Allocates a &lt;code&gt;Date&lt;/code&gt; object and initializes it to * represent the specified number of milliseconds since the * standard base time known as &quot;the epoch&quot;, namely January 1, * 1970, 00:00:00 GMT. * * @param date the milliseconds since January 1, 1970, 00:00:00 GMT. * @see java.lang.System#currentTimeMillis() */ public Date(long date) &#123; fastTime = date; System.out.println(&quot;创建了时间实例&quot;); &#125; 然后就是jar包，图方便，我直接编译好Date.css，然后创建文件夹java/util/，把class文件放入进去zip后改后缀名xxx.jar。 编写测试： public static void main(String[] args) &#123; System.out.println(new Date()); &#125; 指定VM参数 -Djava.endorsed.dirs=D:\\java\\endorsed输出 创建了时间实例 Fri Jul 24 09:54:48 CST 2020 可以看到成功覆盖了JDK的Date对象 直接放到jre里面 运行测试，不需要VM参数，一样的效果。 存在原因因为JDK的类是由Bootstrap类加载器进行加载的，而这个类加载器由C++编写无法获取到，也是最开始进行类加载的，并且JVM是采用双亲委派机制进行加载class类的。如果你想要在应用程序中替换掉jdk中的某个类是无法做到的，所以提供了endorsed来达到你想要替换到系统中的类。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"endorsed","slug":"endorsed","permalink":"https://blog.unclezs.com/tags/endorsed/"}]},{"title":"Java中的volatile关键字","slug":"Java/并发编程/volatile关键字","date":"2020-07-23T11:27:42.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/并发编程/volatile关键字.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/volatile%E5%85%B3%E9%94%AE%E5%AD%97.html","excerpt":"作用volatile 关键字的主要作⽤就是保证变量的可⻅性然后还有⼀个作⽤是防⽌指令重排序。 原因在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进⾏特别的注意的。⽽在当前的 Java 内存模型下，线程可以把变量保存本地内存（⽐如机器的寄存器）中，⽽不是直接在主存中进⾏读写。这就可能造成⼀个线程在主存中修改了⼀个变量的值，⽽另外⼀个线程还继续使⽤它在寄存器中的变量值的拷⻉，造成数据的不⼀致 要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使⽤它都到主存中进⾏读取。 无volatile 有volatile","text":"作用volatile 关键字的主要作⽤就是保证变量的可⻅性然后还有⼀个作⽤是防⽌指令重排序。 原因在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进⾏特别的注意的。⽽在当前的 Java 内存模型下，线程可以把变量保存本地内存（⽐如机器的寄存器）中，⽽不是直接在主存中进⾏读写。这就可能造成⼀个线程在主存中修改了⼀个变量的值，⽽另外⼀个线程还继续使⽤它在寄存器中的变量值的拷⻉，造成数据的不⼀致 要解决这个问题，就需要把变量声明为volatile，这就指示 JVM，这个变量是不稳定的，每次使⽤它都到主存中进⾏读取。 无volatile 有volatile","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"}]},{"title":"设计模式-单例模式","slug":"Java/设计模式/设计模式-单例模式","date":"2020-07-23T02:51:34.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/设计模式/设计模式-单例模式.html","link":"","permalink":"https://blog.unclezs.com/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.html","excerpt":"单例模式概念单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。Java中的Runtime即是单例。 单例的实现方式饿汉式Runtime类也是使用的饿汉式。 //饿汉式 public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 懒汉式(线程不安全)//懒汉模式 public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 证明不安全这种方法会存在一个问题就是，在并发情况下无法保证单例。比如两个线程同时运行到 if (Instance == null) 的时候，这个时候因为对象并未实例化，所以都是得到true.这个时候就会创建两个对象了，不能保证单例。","text":"单例模式概念单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。Java中的Runtime即是单例。 单例的实现方式饿汉式Runtime类也是使用的饿汉式。 //饿汉式 public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 懒汉式(线程不安全)//懒汉模式 public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 证明不安全这种方法会存在一个问题就是，在并发情况下无法保证单例。比如两个线程同时运行到 if (Instance == null) 的时候，这个时候因为对象并未实例化，所以都是得到true.这个时候就会创建两个对象了，不能保证单例。 public class Test &#123; public static void main(String[] args) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(SingleTon.getInstance()); &#125; &#125;, &quot;线程1&quot;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(SingleTon.getInstance()); &#125; &#125;, &quot;线程2&quot;).start(); &#125; &#125; //多运行几次得到 SingleTon@6d0ca4c7 SingleTon@455d5a7e 饿汉式 方法锁(线程安全、效率低)因为每次执行都是同步的，所以效率比较低 public class SingleTon &#123; private SingleTon()&#123;&#125;; private static SingleTon Instance; public synchronized static SingleTon getInstance() &#123; if (Instance == null) &#123; Instance = new SingleTon(); &#125; return Instance; &#125; &#125; 饿汉式 Double CheckLock 双重校验锁(线程安全、效率高)public class SingleTon &#123; private SingleTon()&#123;&#125;; private volatile static SingleTon Instance; public static SingleTon getInstance() &#123; if (Instance == null) &#123; synchronized (SingleTon.class) &#123; if (Instance == null) &#123; Instance = new SingleTon(); &#125; &#125; &#125; return Instance; &#125; &#125; 需要注意 Instance 采⽤ volatile 关键字修饰也是很有必要。Instance 采⽤ volatile 关键字修饰也是很有必要的， Instance = new Singleton();这段代码其实是分为三步执⾏： 1. 分配内存空间 2. 初始化 3. 将Instance指向分配的内存地址（这个时候已经不为null了） 但是由于 JVM 具有指令重排的特性，执⾏顺序有可能变成 1→3→2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致⼀个线程获得还没有初始化的实例。例如，线程 T1 执⾏了 1 和 3，此时 T2 调⽤ getInstance() 后发现 Instance 不为空，因此返回Instance，但此时 Instance 还未被初始化。使⽤ volatile 可以禁⽌ JVM 的指令重排，保证在多线程环境下也能正常运⾏。总结：如果不使用volatile关键词修饰，可能会导致拿到的对象是未被初始化的。 饿汉式 静态内部类通过JVM来保证线程安全，高效 public class SingleTon &#123; private SingleTon() &#123; &#125; private static class SingleTonHolder &#123; private static final SingleTon INSTANCE = new SingleTon(); &#125; public static SingleTon getInstances() &#123; return SingleTonHolder.INSTANCE; &#125; &#125; 枚举方式public enum SingleTonEnum &#123; /** * 实例 */ INSTANCE; public void doSomething() &#123; //todo &#125; &#125; 如何选用 单例对象 占用资源少，不需要延时加载，枚举 好于 饿汉 单例对象 占用资源多，需要延时加载，静态内部类 好于 懒汉式","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"单例","slug":"单例","permalink":"https://blog.unclezs.com/tags/%E5%8D%95%E4%BE%8B/"}]},{"title":"最佳评论系统Valine+Valine-Admin简洁且带邮件通知","slug":"问题教程/最佳评论系统Valine-Valine-Admin简洁且带邮件通知","date":"2020-07-19T02:17:36.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"问题教程/最佳评论系统Valine-Valine-Admin简洁且带邮件通知.html","link":"","permalink":"https://blog.unclezs.com/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/%E6%9C%80%E4%BD%B3%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9FValine-Valine-Admin%E7%AE%80%E6%B4%81%E4%B8%94%E5%B8%A6%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5.html","excerpt":"Valine因为博客最近换了一个主题，想着想着把评论也重新弄一弄，在茫茫网络中探索了一下，发现Valine挺方便，只需要填个用户名和邮箱就可以评论了，不需要登陆。而且用户输入了用户名和邮箱后，会自动把信息存在LocalStorage里面，这样在这个站点只要回复过一次就可以免除反复输入用户名来评论了。 这样的无后端的评论系统虽然是不错，但也存在一个明显存在一个问题，就是用户评论之后，自己怎么知道。自己回复了用户，用户怎么知道。这是一个很重要的问题，需要解决。因为Valine自带的邮件提醒功能将在v1.4.0发布时下线，需要更改为第三方邮件提醒。 所以要解决一个问题：无后端+邮件通知。 这个时候我找到了新的解决方案，Valine-Admin。 Valine-AdminValine Admin 是 Valine 评论系统的扩展和增强，主要实现评论邮件通知、评论管理、垃圾评论过滤等功能。支持完全自定义的邮件通知模板。基于Akismet API实现准确的垃圾评论过滤。此外，使用云函数等技术解决了免费版云引擎休眠问题，支持云引擎自动唤醒，漏发邮件自动补发。兼容云淡风轻及Deserts维护的多版本Valine。 使用教程 首先在LeanCloud注册你的账号，然后创建你的账号.创建自己的应用，拿到AppId和AppKey 设置环境变量 变量 示例 说明 SITE_NAME Deserts [必填]博客名称 SITE_URL https://deserts.io [必填]首页地址 SMTP_SERVICE QQ [新版支持]邮件服务提供商，支持 QQ、163、126、Gmail 以及 更多 SMTP_USER xxxxxx@qq.com [必填]SMTP登录用户 SMTP_PASS ccxxxxxxxxch [必填]SMTP登录密码（QQ邮箱需要获取独立密码） SENDER_NAME Deserts [必填]发件人 SENDER_EMAIL xxxxxx@qq.com [必填]发件邮箱 ADMIN_URL https://xxx.leanapp.cn/ [建议]Web主机二级域名，用于自动唤醒 BLOGGER_EMAIL xxxxx@gmail.com [可选]博主通知收件地址，默认使用SENDER_EMAIL AKISMET_KEY xxxxxxxxxxxx [可选]Akismet Key 用于垃圾评论检测，设为MANUAL_REVIEW开启人工审核，留空不使用反垃圾 以上必填参数请务必正确设置。 二级域名用于评论后台管理，如https://deserts.leanapp.cn 。 部署源码点击部署即可，然后服务将会自动部署。 测试 访问https://xxx.avosapps.us/sign-up注册自己的管理员用户名和密码， 然后访问https://xxx.avosapps.us/comments即可查看自己收到的评论了。 相关链接","text":"Valine因为博客最近换了一个主题，想着想着把评论也重新弄一弄，在茫茫网络中探索了一下，发现Valine挺方便，只需要填个用户名和邮箱就可以评论了，不需要登陆。而且用户输入了用户名和邮箱后，会自动把信息存在LocalStorage里面，这样在这个站点只要回复过一次就可以免除反复输入用户名来评论了。 这样的无后端的评论系统虽然是不错，但也存在一个明显存在一个问题，就是用户评论之后，自己怎么知道。自己回复了用户，用户怎么知道。这是一个很重要的问题，需要解决。因为Valine自带的邮件提醒功能将在v1.4.0发布时下线，需要更改为第三方邮件提醒。 所以要解决一个问题：无后端+邮件通知。 这个时候我找到了新的解决方案，Valine-Admin。 Valine-AdminValine Admin 是 Valine 评论系统的扩展和增强，主要实现评论邮件通知、评论管理、垃圾评论过滤等功能。支持完全自定义的邮件通知模板。基于Akismet API实现准确的垃圾评论过滤。此外，使用云函数等技术解决了免费版云引擎休眠问题，支持云引擎自动唤醒，漏发邮件自动补发。兼容云淡风轻及Deserts维护的多版本Valine。 使用教程 首先在LeanCloud注册你的账号，然后创建你的账号.创建自己的应用，拿到AppId和AppKey 设置环境变量 变量 示例 说明 SITE_NAME Deserts [必填]博客名称 SITE_URL https://deserts.io [必填]首页地址 SMTP_SERVICE QQ [新版支持]邮件服务提供商，支持 QQ、163、126、Gmail 以及 更多 SMTP_USER xxxxxx@qq.com [必填]SMTP登录用户 SMTP_PASS ccxxxxxxxxch [必填]SMTP登录密码（QQ邮箱需要获取独立密码） SENDER_NAME Deserts [必填]发件人 SENDER_EMAIL xxxxxx@qq.com [必填]发件邮箱 ADMIN_URL https://xxx.leanapp.cn/ [建议]Web主机二级域名，用于自动唤醒 BLOGGER_EMAIL xxxxx@gmail.com [可选]博主通知收件地址，默认使用SENDER_EMAIL AKISMET_KEY xxxxxxxxxxxx [可选]Akismet Key 用于垃圾评论检测，设为MANUAL_REVIEW开启人工审核，留空不使用反垃圾 以上必填参数请务必正确设置。 二级域名用于评论后台管理，如https://deserts.leanapp.cn 。 部署源码点击部署即可，然后服务将会自动部署。 测试 访问https://xxx.avosapps.us/sign-up注册自己的管理员用户名和密码， 然后访问https://xxx.avosapps.us/comments即可查看自己收到的评论了。 相关链接 Valine Valine-Admin 安装教程请以博客最新版为准。","categories":[{"name":"问题教程","slug":"问题教程","permalink":"https://blog.unclezs.com/categories/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.unclezs.com/tags/hexo/"},{"name":"valine","slug":"valine","permalink":"https://blog.unclezs.com/tags/valine/"}]},{"title":"Synchronized与ReentrantLock","slug":"Java/并发编程/Synchronized与ReentrantLock","date":"2020-07-08T13:40:47.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/并发编程/Synchronized与ReentrantLock.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Synchronized%E4%B8%8EReentrantLock.html","excerpt":"Java 里面，最基本的互斥同步手段就是 synchronized 关键字，这是一种块结构( Block Structured ）的同步语法。还有就是 Java 类库中新提供了 java. util.concurrent 包，其中的 java.util.concurrent.locks.Lock 接口便成了 Java 另一 全新的互斥 同步手段。 Synchronized 被 synchronized 修饰的同步块对同一条线程来说是可重人的 这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况 被synchronized 修饰的同步块在持有锁的线程执行完毕并释放锁之前，会元条件地阻塞后面其他线程的进入 意味着无法像处理某些数据库中 的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出 三种使⽤⽅式 修饰实例⽅法: 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁 修饰静态⽅法: 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员（ static 表明这是该类的⼀个静态资源，不管new了多少个对象，只有⼀份）。所以如果⼀个线程A调⽤⼀个实例对象的⾮静态 synchronized ⽅法，⽽线程B需要调⽤这个实例对象所属类的静态 synchronized ⽅法，是允许的，不会发⽣互斥现象，因为访问静态synchronized ⽅法占⽤的锁是当前类的锁，⽽访问⾮静态 synchronized ⽅法占⽤的锁是当前实例对象锁。 修饰代码块：指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。 总结： synchronized 关键字加到 static 静态⽅法和 synchronized(class)代码块上都是是给 Class类上锁。synchronized 关键字加到实例⽅法上是给对象实例上锁。尽量不要使⽤synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 底层实现作用于对象的时候当synchronized作用于对象时候（即代码块方式），JVM会使用字节码monitorenter，monitorexit来进行同步代码块区分: 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: sipush 666 11: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 14: aload_1 15: monitorexit","text":"Java 里面，最基本的互斥同步手段就是 synchronized 关键字，这是一种块结构( Block Structured ）的同步语法。还有就是 Java 类库中新提供了 java. util.concurrent 包，其中的 java.util.concurrent.locks.Lock 接口便成了 Java 另一 全新的互斥 同步手段。 Synchronized 被 synchronized 修饰的同步块对同一条线程来说是可重人的 这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况 被synchronized 修饰的同步块在持有锁的线程执行完毕并释放锁之前，会元条件地阻塞后面其他线程的进入 意味着无法像处理某些数据库中 的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出 三种使⽤⽅式 修饰实例⽅法: 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁 修饰静态⽅法: 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员（ static 表明这是该类的⼀个静态资源，不管new了多少个对象，只有⼀份）。所以如果⼀个线程A调⽤⼀个实例对象的⾮静态 synchronized ⽅法，⽽线程B需要调⽤这个实例对象所属类的静态 synchronized ⽅法，是允许的，不会发⽣互斥现象，因为访问静态synchronized ⽅法占⽤的锁是当前类的锁，⽽访问⾮静态 synchronized ⽅法占⽤的锁是当前实例对象锁。 修饰代码块：指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。 总结： synchronized 关键字加到 static 静态⽅法和 synchronized(class)代码块上都是是给 Class类上锁。synchronized 关键字加到实例⽅法上是给对象实例上锁。尽量不要使⽤synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 底层实现作用于对象的时候当synchronized作用于对象时候（即代码块方式），JVM会使用字节码monitorenter，monitorexit来进行同步代码块区分: 4: monitorenter 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: sipush 666 11: invokevirtual #4 // Method java/io/PrintStream.println:(I)V 14: aload_1 15: monitorexit 在执行 monitorenter 指令时，首先要去尝试获取对象的锁 如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行 monitorexit 指令时会将锁计数器的值减一 一旦计数器的值为零，锁随即就被释放了 如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。 锁的优化Java HotSpot 虚拟机中，每个对象都有对象头（包括 class 指针和 Mark Word）。Mark Word 平时存储这个对象的 哈希码 、 分代年龄 ，当加锁时，这些信息就根据情况被替换为 标记位 、 线程锁记录指 针 、 重量级锁指针 、 线程ID 等内容 高效并发是从 JDK 升级到 JDK 后一项重要的改进项， Hotspot 虚拟机开发团队在这个版本上花费了大 的资源去实现各种锁优化技术，如适应性自旋（ Adaptive Spinning锁消除（ Lock Elimination ）、锁膨胀（ Lock Coarsening 、轻量级锁（ Lightweight Locking）、偏向锁（ Biased Locking ）等，这些技术都是为了在线程之间更高效地共享数据及解决竞争问题，从而提高程序的执行效率 对象头 Mark Word 锁之间的转换 偏向锁轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量，而偏向锁在无竞争的情况下会把整个同步都会消除掉。 偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏” 它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“ 0”），撤销后标志位恢复到未锁定（标志位为“01 ”）或轻量级锁定（标志位为“00 ”）的状态 注意： 撤销偏向锁这个过程中所有线程需要暂停（STW） 访问对象的 hashCode 时候，如果对象处于偏向锁，也会撤销偏向锁，并且转换为重量级锁 如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2，重偏向会重置对象的 Thread ID 撤销偏向和重偏向都是批量进行的，以类为单位 如果撤销偏向到达某个阈值，整个类的所有对象都会变为不可偏向的 可以主动使用 -XX:-UseBiasedLocking 禁用偏向锁 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。 加锁：在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01 ”状态），那么虚拟机就会在当前线程栈帧中创建一个名字为Lock Record的空间，用于存储当前对象的MarK Word的拷贝（方便后期比较），虚拟机将会使用CAS把对象的Mark Word更新为指向Lock Recod的指针。 转化之前的对象头 转换之后的对象头 如果这个更新操作成功了，则代表这个对象获得了这个对象的锁，锁状态变成轻量级锁的“00”。如果失败了，则代表有多个线程正在竞争这个对象的锁，这个时候虚拟机再检查对象的Mark Word的指针是不是指向了当前线程存的Lock Record，如果是则直接进入同步代码块（锁重入）。如果不是则代表锁已经被其他线程占用了。当线程数量两个及以上时候，则可能进行锁膨胀。 解锁将Lock Recod存的Mark Word替换回去，同样是使用CAS操作，假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。 轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则 如果没有竞争，轻量级锁便通过 CAS 操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销 ，还额外发生了CAS作的开销 因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。 锁膨胀如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争），如果出现两条及以上的线程争用同一个锁的情况，后来的那条会自旋（循环等待）一定次数来等待锁，如果还是获取不到锁，这时需要进行锁膨胀，将轻量级锁变为重量级锁。 重量级锁重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 synchronized的其他优化 减少上锁时间：同步代码块中尽量短 减少锁的粒度：将一个锁拆分为多个锁提高并发度 锁粗化：多次循环进入同步块不如同步块内多次循环 另外 JVM 可能会做如下优化，把多次 append 的加锁操作粗化为一次（因为都是对同一个对象加锁，没必要重入多次） 锁消除：JVM 会进行代码的逃逸分析，例如某个加锁对象是方法内局部变量，不会被其它线程所访问到，这时候就会被即时编译器忽略掉所有同步操作。 读写分离：CopyOnWriteArrayList、ConyOnWriteSet等 ReentrantLock重人锁（ ReentrantLock ）是 Lock 接口最常见的一种实现，顾名思义，它与 synchronized样是可重人的 在基本用法上， ReentrantLock 也与 synchronized 很相似，只是代码写法上稍有区别而已 不过， ReentrantLock synchronized 相比增加了一些高级功能，主要有以下 等待可中断、可实现公平锁及锁可以绑定多个条件 等待可中断： 是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情 可中断特性对处理执行时间非常长的同步块很有帮助 公平锁： 是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何－个等待锁的线程都有机会获得锁 synchronized 中的锁是非公平的， ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁 不过一旦使用了公平锁，将会导致 ReentrantLock 的性能急剧下降，会明显 吞吐量 锁绑定多个条件： 是指一个 ReentrantLock 象可以同时绑定多个 Condition 对象synchronized 中，锁对象的 wait() 跟的 notify()或者 notifyAll ()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而 ReentrantLock 则无须这样做，多次调用 newCondition（）方法即可 Synchronized 和 ReentrantLock 的对比① 两者都是可重入锁 两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 ② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 ③ ReenTrantLock 比 synchronized 增加了一些高级功能 相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件） ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。 synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。 如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。 ④ 性能已不是选择标准 在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量随线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。 图解","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://blog.unclezs.com/tags/jvm/"}]},{"title":"认识CAS与ABA问题","slug":"Java/并发编程/认识CAS与ABA问题","date":"2020-07-08T12:10:59.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/并发编程/认识CAS与ABA问题.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E8%AE%A4%E8%AF%86CAS%E4%B8%8EABA%E9%97%AE%E9%A2%98.html","excerpt":"什么是CASCAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。 CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。它体现的一种乐观锁的思想，比如多个线程要对一个共享的整型变量执行 +1 操作 获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。结合 CAS 和 volatile 可以实现无锁并发，适用于竞争不激烈、多核 CPU 的场景下。 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 CAS 底层依赖于一个 Unsafe 类来直接调用操作系统底层的 CAS 指令 伪代码： // 需要不断尝试 while(true) &#123; int 旧值 = 共享变量;//比如拿到了当前值 0 int 结果 = 旧值 + 1;//在旧值 0 的基础上增加 1 ，正确结果是 1 //这时候如果别的线程把共享变量改成了 5，本线程的正确结果 1 就作 //废了，这时候 compareAndSwap 返回 false，重新尝试，直到： compareAndSwap 返回 //true，表示我本线程做修改的同时，别的线程没有干扰 */ if( compareAndSwap ( 旧值, 结果 )) &#123; // 成功，退出循环 &#125; &#125; CAS的缺点CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题。 循环时间长开销很大。 只能保证一个变量的原子操作。 ABA问题。","text":"什么是CASCAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。 CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。它体现的一种乐观锁的思想，比如多个线程要对一个共享的整型变量执行 +1 操作 获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。结合 CAS 和 volatile 可以实现无锁并发，适用于竞争不激烈、多核 CPU 的场景下。 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 CAS 底层依赖于一个 Unsafe 类来直接调用操作系统底层的 CAS 指令 伪代码： // 需要不断尝试 while(true) &#123; int 旧值 = 共享变量;//比如拿到了当前值 0 int 结果 = 旧值 + 1;//在旧值 0 的基础上增加 1 ，正确结果是 1 //这时候如果别的线程把共享变量改成了 5，本线程的正确结果 1 就作 //废了，这时候 compareAndSwap 返回 false，重新尝试，直到： compareAndSwap 返回 //true，表示我本线程做修改的同时，别的线程没有干扰 */ if( compareAndSwap ( 旧值, 结果 )) &#123; // 成功，退出循环 &#125; &#125; CAS的缺点CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题。 循环时间长开销很大。 只能保证一个变量的原子操作。 ABA问题。 ABA问题什么是ABA问题ABA问题通俗一点的说，就是一个从内存里面读取到了值A，正在改的时候也检查到了还是A，但是真实的值是被改成了B再改回了A的。 怎么解决ABA解决ABA问题就是给操作数加上一个“版本号”，就像Mysql的乐观锁一样。而Java中提供了AtomicStampedReference类来实现这个功能。 AtomicStampedReference类可以给一个引用标记上一个标记位，来保证原子性。AtomicStampedReference可以给一个引用标记上一个整型的版本戳，来保证原子性。 代码测试/** * @author blog.unclezs.com * @date 2020/7/26 21:22 */ public class CASTest &#123; public static String A = &quot;A&quot;; public static String B = &quot;B&quot;; public static String C = &quot;C&quot;; public static AtomicStampedReference&lt;String&gt; atomic = new AtomicStampedReference&lt;&gt;(A, 0); public static void main(String[] args) &#123; //线程1来了，先检查是否和当前值一样,我准备把A改成C了,并且拿到线程1比较时候的stamp boolean same = atomic.attemptStamp(A, 1); int stamp = atomic.getStamp(); //线程2来了，我准备把A换成B了 atomic.compareAndSet(A, B, atomic.getStamp(), atomic.getStamp() + 1); //线程3来了，我准备把B换回A了 atomic.compareAndSet(A, B, atomic.getStamp(), atomic.getStamp() + 1); //到线程1来修改了A成C了 if (same) &#123; boolean b = atomic.compareAndSet(A, C, stamp, stamp + 1); System.out.println(b?&quot;修改成功&quot;:&quot;修改失败ABA了&quot;); &#125; &#125; &#125; 参考 面试必问的CAS，你懂了吗？ CAS算法与ABA问题","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"}]},{"title":"Servlet 3.0 通过SPI 进行注册组件，SpringMVC 无web.xml配置采用此种方式","slug":"Java/javaee/Servlet-3-0-通过SPI-进行注册组件，SpringMVC-无web-xml配置采用此种方式","date":"2020-03-20T12:59:51.000Z","updated":"2021-01-03T10:24:42.000Z","comments":true,"path":"Java/javaee/Servlet-3-0-通过SPI-进行注册组件，SpringMVC-无web-xml配置采用此种方式.html","link":"","permalink":"https://blog.unclezs.com/Java/javaee/Servlet-3-0-%E9%80%9A%E8%BF%87SPI-%E8%BF%9B%E8%A1%8C%E6%B3%A8%E5%86%8C%E7%BB%84%E4%BB%B6%EF%BC%8CSpringMVC-%E6%97%A0web-xml%E9%85%8D%E7%BD%AE%E9%87%87%E7%94%A8%E6%AD%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html","excerpt":"什么是SPISPI ，全称为 Service Provider Interface，是一种服务发现机制。它通过在ClassPath路径下的META-INF/services文件夹查找文件，自动加载文件里所定义的类。 这一机制为很多框架扩展提供了可能，比如在JDBC的加载驱动方式也是采用了这种方式，只需要导入对应驱动jar包则可以自动注册驱动。本文提到的Servlet3.0也提供了这一机制，只需要在META-INF/services下面创建javax.servlet.ServletContainerInitializer这一文件，并在里面填入需要在Tomcat启动的时候加载的类的全限定类名即可，如果有多个，一行一个。 快速体验总体流程 首先引入Servlet-Api 创建一个类实现ServletContainerInitializer接口，并重写onStartup方法 在src/META-INF下面创建上述文件，并在其中填入创建的类的全限定类名 配置tomcat并启动项目即可 代码实例 maven创建工程引入Servet-Api并改打包方式为war 创建MyServletContainerInitializer实现ServletContainerInitializer package com.unclezs.initializer; import javax.servlet.ServletContainerInitializer; import javax.servlet.ServletContext; import javax.servlet.ServletException; import java.util.Set; /** * @author uncle * @date 2020/3/20 20:51 */ public class MyServletContainerInitializer implements ServletContainerInitializer &#123; public void onStartup(Set&lt;Class&lt;?&gt;&gt; c, ServletContext ctx) throws ServletException &#123; System.out.println(&quot;容器初始化了&quot;) &#125; &#125; 在src下面创建META-INF/service/javax.servlet.ServletContainerInitializer 配置Tomcat启动查看效果","text":"什么是SPISPI ，全称为 Service Provider Interface，是一种服务发现机制。它通过在ClassPath路径下的META-INF/services文件夹查找文件，自动加载文件里所定义的类。 这一机制为很多框架扩展提供了可能，比如在JDBC的加载驱动方式也是采用了这种方式，只需要导入对应驱动jar包则可以自动注册驱动。本文提到的Servlet3.0也提供了这一机制，只需要在META-INF/services下面创建javax.servlet.ServletContainerInitializer这一文件，并在里面填入需要在Tomcat启动的时候加载的类的全限定类名即可，如果有多个，一行一个。 快速体验总体流程 首先引入Servlet-Api 创建一个类实现ServletContainerInitializer接口，并重写onStartup方法 在src/META-INF下面创建上述文件，并在其中填入创建的类的全限定类名 配置tomcat并启动项目即可 代码实例 maven创建工程引入Servet-Api并改打包方式为war 创建MyServletContainerInitializer实现ServletContainerInitializer package com.unclezs.initializer; import javax.servlet.ServletContainerInitializer; import javax.servlet.ServletContext; import javax.servlet.ServletException; import java.util.Set; /** * @author uncle * @date 2020/3/20 20:51 */ public class MyServletContainerInitializer implements ServletContainerInitializer &#123; public void onStartup(Set&lt;Class&lt;?&gt;&gt; c, ServletContext ctx) throws ServletException &#123; System.out.println(&quot;容器初始化了&quot;) &#125; &#125; 在src下面创建META-INF/service/javax.servlet.ServletContainerInitializer 配置Tomcat启动查看效果 细节说明可以看到，当我们实现了ServletContainerInitializer接口的话，在onStartUp方法中传入了 public void onStartup(Set&lt;Class&lt;?&gt;&gt; c, ServletContext ctx)&#123;&#125; 其中的ServletContext我们已经熟悉，为Servlet的上下文，可以做web.xml里面可以做的事情 这个Set集合传入的class则需要配合一个@HandlesTypes注解了 @Target(&#123;ElementType.TYPE&#125;) @Retention(RetentionPolicy.RUNTIME) public @interface HandlesTypes &#123; Class&lt;?&gt;[] value(); &#125; 容器启动的时候会将@HandlesTypes指定的这个类型下面的子类（实现类，子接口等）传递过来。所以如果我们需要做一些额外的定制的话可以写一个这样的接口，SpringMVC的WebApplicationInitializer就是这么一个接口。 SpringMVC中使用这个机制打开Spring-Web这个jar包一看 可以看到就是利用在Servlet3.0更新的SPI机制，其中WebApplicationInitializer这个接口，就是我们用来配置无web.xml搭建springmvc项目的时候用到的类。 贴一下无web.xml配置一个最小SpringMVC项目 package com.unclezs.config; import org.springframework.web.WebApplicationInitializer; import org.springframework.web.context.support.AnnotationConfigWebApplicationContext; import org.springframework.web.servlet.DispatcherServlet; import javax.servlet.ServletException; import javax.servlet.ServletRegistration; /** * @author uncle * @date 2019.12.31 */ public class WebInit implements WebApplicationInitializer &#123; public void onStartup(javax.servlet.ServletContext servletContext) throws ServletException &#123; AnnotationConfigWebApplicationContext ctx = new AnnotationConfigWebApplicationContext(); ctx.scan(&quot;com.unclezs&quot;); ServletRegistration.Dynamic mvc = servletContext.addServlet(&quot;springmvc&quot;, new DispatcherServlet(ctx)); mvc.addMapping(&quot;/&quot;); mvc.setLoadOnStartup(1); &#125; &#125; 配置好Tomcat直接启动就可可以了，是不是贼清爽~","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"JavaEE","slug":"Java/JavaEE","permalink":"https://blog.unclezs.com/categories/Java/JavaEE/"}],"tags":[{"name":"servlet","slug":"servlet","permalink":"https://blog.unclezs.com/tags/servlet/"},{"name":"javaee","slug":"javaee","permalink":"https://blog.unclezs.com/tags/javaee/"},{"name":"springmvc","slug":"springmvc","permalink":"https://blog.unclezs.com/tags/springmvc/"}]},{"title":"Spring Aop 注解方式食用","slug":"Java/Spring/Spring-Aop-注解方式食用","date":"2020-03-20T02:44:21.000Z","updated":"2021-01-03T10:25:50.000Z","comments":true,"path":"Java/Spring/Spring-Aop-注解方式食用.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/Spring-Aop-%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F%E9%A3%9F%E7%94%A8.html","excerpt":"Aop简介Aop(Aspect-OrientedProgramming 面向切面编程)。在面向对象编程中，常用封装、多态和继承这些来建立一个层次结果，用以模拟公共行为的一个集合。当我们需要为分散的对象引入公共行为的时候。面向对象的对象就显得有些无力。因为这个时候我们通常用继承和委派来实现对重复代码的利用，但是当我们需要记录日志、和事务操作这些的时候，如果我们还采用继承的话会导致每个类都继承一个Log类，显得有些臃肿，用委派的话会显得类比较笨重，重要的是这些与我们业务无关的代码大量嵌入了进来。 所以这个时候就需要了Aop的重左到右的来实现，直接将重复的代码封装到一个切面，当然后定义一些切点来声明这些重复代码需要在哪些地方执行。定义一些连接点来标明什么时候需要执行，比如方法执行前执行后之类的。 Spring Aop一些通知的注解在环绕通知的时候，会传入一个ProceedingJoinPoint参数给环绕方法，执行其Process()方法即为调用了原来的方法，必须调用，不然会阻塞 切点的过滤及匹配的一些方式 execution的写法","text":"Aop简介Aop(Aspect-OrientedProgramming 面向切面编程)。在面向对象编程中，常用封装、多态和继承这些来建立一个层次结果，用以模拟公共行为的一个集合。当我们需要为分散的对象引入公共行为的时候。面向对象的对象就显得有些无力。因为这个时候我们通常用继承和委派来实现对重复代码的利用，但是当我们需要记录日志、和事务操作这些的时候，如果我们还采用继承的话会导致每个类都继承一个Log类，显得有些臃肿，用委派的话会显得类比较笨重，重要的是这些与我们业务无关的代码大量嵌入了进来。 所以这个时候就需要了Aop的重左到右的来实现，直接将重复的代码封装到一个切面，当然后定义一些切点来声明这些重复代码需要在哪些地方执行。定义一些连接点来标明什么时候需要执行，比如方法执行前执行后之类的。 Spring Aop一些通知的注解在环绕通知的时候，会传入一个ProceedingJoinPoint参数给环绕方法，执行其Process()方法即为调用了原来的方法，必须调用，不然会阻塞 切点的过滤及匹配的一些方式 execution的写法 当有多个条件的时候可以用 &amp;&amp; 符号或者 and 来连接 还有 not 、! 、or、||这些 通过注解方式创建的实例package com.unclezs.spring.aop; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; import java.util.Objects; /** * @author uncle * @date 2020/3/20 10:18 */ @Aspect @Component public class AopTest &#123; @Pointcut(&quot;@within(com.unclezs.spring.aop.annotation.AopPoint)&quot;) public void pointcut() &#123; &#125; @Before(&quot;pointcut()&quot;) public void before() &#123; System.out.println(&quot;before&quot;); &#125; @After(&quot;pointcut()&quot;) public void after() &#123; System.out.println(&quot;after&quot;); &#125; @AfterReturning(&quot;pointcut()&quot;) public void afterReturning() &#123; System.out.println(&quot;afterReturning&quot;); &#125; @AfterThrowing(&quot;pointcut()&quot;) public void afterThrowing() &#123; System.out.println(&quot;afterThrowing&quot;); &#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint joinPoint) &#123; try &#123; System.out.println(&quot;环绕Before&quot;); Object proceed = joinPoint.proceed(); System.out.println(&quot;环绕After&quot;); return proceed; &#125; catch (Throwable throwable) &#123; System.out.println(&quot;环绕afterThrowing&quot;); throwable.printStackTrace(); &#125; return null; &#125; &#125; 需要注意的是，在使用SpringAop的时候需要在配置类上面添加@EnableAspectJAutoProxy注解才能生效","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"aop","slug":"aop","permalink":"https://blog.unclezs.com/tags/aop/"}]},{"title":"Spring中Profiles的作用及原理浅析","slug":"Java/Spring/Spring中Profiles的作用及原理浅析","date":"2020-03-10T04:11:28.000Z","updated":"2021-01-03T10:26:18.000Z","comments":true,"path":"Java/Spring/Spring中Profiles的作用及原理浅析.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/Spring%E4%B8%ADProfiles%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%8A%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90.html","excerpt":"什么是Profileprofile是用户区别环境来执行那些代码的，在我们日常开发中经常需要由开发环境到生产环境切换，这个时候需要更改数据库、redis等等这些的连接地址和密码，改完再打包，然后再改回来，这样实在是繁琐且多余。而Profile的作用正是解决这个问题的。 Spring中使用Profile的例子 创建根据Profile配置的配置类 public class Message &#123; private String message; &#125; @Configuration @Profile(&quot;dev&quot;) public class DevConfig &#123; @Bean Message message() &#123; Message message = new Message(); message.setMessage(&quot;dev env&quot;); return message; &#125; &#125; @Configuration @Profile(&quot;pro&quot;) public class ProConfig &#123; @Bean Message message() &#123; Message message = new Message(); message.setMessage(&quot;pro env&quot;); return message; &#125; &#125; 测试根据激活的Profile来配置 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = ContextConfig.class) @ActiveProfiles(&quot;pro&quot;) public class SpringTest &#123; @Autowired private Message message; @Test public void testProfile()&#123; System.out.println(message.getMessage()); &#125; &#125; 其中ContextConfiguration是指定包扫描的，里面就配置了ComponetScan@ActiveProfile是指定激活的Profile，值可以是数组比如同时激活两个环境@ActiveProfile({“dev”,”pro”}) 运行代码测试 浅析源码用户标记在什么环境下启用，使用实示例@Profile(“dev”)。 @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(ProfileCondition.class) public @interface Profile &#123; String[] value(); &#125; 条件匹配，当满足条件的时候才使这个配置生效。value也得以证明是一个数组，可以传入多个profile,可以看到里面有一个@Conditional注解，可以跟进Conditional的源码看看 @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Conditional&#123; Class&lt;? extends Condition&gt;[] value(); &#125; 里面的需要传入实现了Condition接口，而再@Profile中的@Conditional里面传入了ProfileCondition.class，可以再看看ProfileCondition的源码","text":"什么是Profileprofile是用户区别环境来执行那些代码的，在我们日常开发中经常需要由开发环境到生产环境切换，这个时候需要更改数据库、redis等等这些的连接地址和密码，改完再打包，然后再改回来，这样实在是繁琐且多余。而Profile的作用正是解决这个问题的。 Spring中使用Profile的例子 创建根据Profile配置的配置类 public class Message &#123; private String message; &#125; @Configuration @Profile(&quot;dev&quot;) public class DevConfig &#123; @Bean Message message() &#123; Message message = new Message(); message.setMessage(&quot;dev env&quot;); return message; &#125; &#125; @Configuration @Profile(&quot;pro&quot;) public class ProConfig &#123; @Bean Message message() &#123; Message message = new Message(); message.setMessage(&quot;pro env&quot;); return message; &#125; &#125; 测试根据激活的Profile来配置 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = ContextConfig.class) @ActiveProfiles(&quot;pro&quot;) public class SpringTest &#123; @Autowired private Message message; @Test public void testProfile()&#123; System.out.println(message.getMessage()); &#125; &#125; 其中ContextConfiguration是指定包扫描的，里面就配置了ComponetScan@ActiveProfile是指定激活的Profile，值可以是数组比如同时激活两个环境@ActiveProfile({“dev”,”pro”}) 运行代码测试 浅析源码用户标记在什么环境下启用，使用实示例@Profile(“dev”)。 @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(ProfileCondition.class) public @interface Profile &#123; String[] value(); &#125; 条件匹配，当满足条件的时候才使这个配置生效。value也得以证明是一个数组，可以传入多个profile,可以看到里面有一个@Conditional注解，可以跟进Conditional的源码看看 @Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface Conditional&#123; Class&lt;? extends Condition&gt;[] value(); &#125; 里面的需要传入实现了Condition接口，而再@Profile中的@Conditional里面传入了ProfileCondition.class，可以再看看ProfileCondition的源码 class ProfileCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; MultiValueMap&lt;String, Object&gt; attrs = metadata.getAllAnnotationAttributes(Profile.class.getName()); if (attrs != null) &#123; for (Object value : attrs.get(&quot;value&quot;)) &#123; if (context.getEnvironment().acceptsProfiles(Profiles.of((String[]) value))) &#123; return true; &#125; &#125; return false; &#125; return true; &#125; &#125; 他实现了Condition接口，ConditionContext里面可以拿到当前环境的激活的Profile然后从AnnotatedTypeMetadata中拿到@Profile注解的value值，然后对比是否包含当前环境的Profile，如果有则返回true，条件生效。 激活Profile激活方式是设置spring.profiles.active的值，可以是一个数组。也可以设置spring.profiles.default来指定默认激活的profile。通常我们可以通过一下几种方式来改变profile 在spring-web中通过DispatcherServlet传入spring.profiles.default,比如： &lt;servlet&gt; &lt;servlet-name&gt;mvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;spring.profiles.default&lt;/param-name&gt; &lt;param-value&gt;dev&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; 在DispatcherServlet中可以通过super.getServletConfig().getInitParameter(“spring.profiles.default”)获取 在web应用中使用context上下问参数来指定 &lt;context-param&gt; &lt;param-name&gt;spring.profiles.default&lt;/param-name&gt; &lt;param-value&gt;dev&lt;/param-value&gt; &lt;/context-param&gt; 在Servlet中可以通过getServletConfig().getServletContext().getInitParameter(“spring.profiles.default”)获取。 作为JNDI条目，JDNI是Java 命名与目录接口(Java Naming and Directory Interface) 作为环境变量，设置一个名字为spring.active.profile的环境变量 作为JVM的参数，比如java -jar xxx.jar –spring.profile.active=dev 在测试类中可以使用@ActiveProfiles注解指定","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.unclezs.com/tags/spring/"},{"name":"profile","slug":"profile","permalink":"https://blog.unclezs.com/tags/profile/"}]},{"title":"Spring之Bean的生命周期","slug":"Java/Spring/Spring之Bean的生命周期","date":"2020-03-09T10:30:54.000Z","updated":"2021-01-03T10:26:04.000Z","comments":true,"path":"Java/Spring/Spring之Bean的生命周期.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/Spring%E4%B9%8BBean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.html","excerpt":"spring-bean与普通beanSpring创建一个Bean不像是传统的javaBean一样，简单的new一个出来，用了等着被回收就完了，Spring对Bean的创建和销毁过程都加入了一些关于Spring本身的操作，比如当Spring容器销毁的时候自动调用Bean的destory方法，如果这个Bean实现了DisposableBean接口的话。 图解Spring-Bean的生命周期 文解Spring-Bean生命周期1.Spring对Bean进行实例化2.将依赖的Bean进行注入，和传入值进行赋值到属性中。3.如果Bean实现了BeanNameAware接口，Spring将调用setBeanName将Bean的Id传入进来 public class SpringBean implements BeanNameAware &#123; private String name; public void setBeanName(String name) &#123; this.name=name; //do something &#125; &#125; 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory将BeanFactory传入进来 public class SpringBean implements BeanFactoryAware &#123; public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; //do something &#125; &#125; 5.如果Bean实现了ApplicationContextAware接口，那么Spring将会把applicationContext传入调用setApplicationContext方法，这个可以用户获取上下文对象来手动获取Bean","text":"spring-bean与普通beanSpring创建一个Bean不像是传统的javaBean一样，简单的new一个出来，用了等着被回收就完了，Spring对Bean的创建和销毁过程都加入了一些关于Spring本身的操作，比如当Spring容器销毁的时候自动调用Bean的destory方法，如果这个Bean实现了DisposableBean接口的话。 图解Spring-Bean的生命周期 文解Spring-Bean生命周期1.Spring对Bean进行实例化2.将依赖的Bean进行注入，和传入值进行赋值到属性中。3.如果Bean实现了BeanNameAware接口，Spring将调用setBeanName将Bean的Id传入进来 public class SpringBean implements BeanNameAware &#123; private String name; public void setBeanName(String name) &#123; this.name=name; //do something &#125; &#125; 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory将BeanFactory传入进来 public class SpringBean implements BeanFactoryAware &#123; public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; //do something &#125; &#125; 5.如果Bean实现了ApplicationContextAware接口，那么Spring将会把applicationContext传入调用setApplicationContext方法，这个可以用户获取上下文对象来手动获取Bean public class SpringBean implements ApplicationContextAware &#123; public void setApplicationContext(ApplicationContext applicationContext)throws BeansException &#123; //拿到ApplicationContext对象 &#125; &#125; 6.如果实现了BeanPostProcessor，则调用post-ProcessBeforeInitialization方法。7.如果Bean实现了InitializingBean，那么则调用after-PropertiesSet8.如果Bean实现了BeanPostProcessor接口，Spring将调用post-ProcessAfterInitialization方法，这个时候Bean已经加载好了，直到被销毁。9.如果Bean实现了DisposableBean接口，那么在Bean销毁的时候将会自动调用该Bean的destory方法。 一个实用的使用方式根据以上周期，可以根据其特性来创建一个Spring上下文工具类。使用范围一般在一些静态方法里面使用Spring容器里面的Bean和一些非SpringBean中调用SpringBean对象的时候。SpringContextHolder.getBean(xxx.class) 即可 public class SpringContextHolder implements ApplicationContextAware, DisposableBean &#123; private static ApplicationContext applicationContext = null; /** * 从静态变量applicationContext中取得Bean, 自动转型为所赋值对象的类型. */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getBean(String name) &#123; assertContextInjected(); return (T) applicationContext.getBean(name); &#125; /** * 从静态变量applicationContext中取得Bean, 自动转型为所赋值对象的类型. */ public static &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) &#123; assertContextInjected(); return applicationContext.getBean(requiredType); &#125; /** * 检查ApplicationContext不为空. */ private static void assertContextInjected() &#123; if (applicationContext == null) &#123; throw new IllegalStateException(&quot;applicaitonContext属性未注入, 请在applicationContext&quot; + &quot;.xml中定义SpringContextHolder或在SpringBoot启动类中注册SpringContextHolder.&quot;); &#125; &#125; /** * 清除SpringContextHolder中的ApplicationContext为Null. */ private static void clearHolder() &#123; log.debug(&quot;清除SpringContextHolder中的ApplicationContext:&quot; + applicationContext); applicationContext = null; &#125; @Override public void destroy()&#123; SpringContextHolder.clearHolder(); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; if (SpringContextHolder.applicationContext != null) &#123; log.warn(&quot;SpringContextHolder中的ApplicationContext被覆盖, 原有ApplicationContext为:&quot; + SpringContextHolder.applicationContext); &#125; SpringContextHolder.applicationContext = applicationContext; &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.unclezs.com/tags/spring/"}]},{"title":"依赖注入与松耦合","slug":"Java/Spring/理解依赖注入与松耦合","date":"2020-03-09T08:41:19.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/Spring/理解依赖注入与松耦合.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/%E7%90%86%E8%A7%A3%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E4%B8%8E%E6%9D%BE%E8%80%A6%E5%90%88.html","excerpt":"耦合耦合就是一个类依赖于其他的类才能完成其功能。耦合具有两面性，一个方面是难以测试，难以复用和难以理解，另外一个方面是我们却不得不耦合，完全没有耦合的代码几乎啥都干不了。所以耦合是必须的，但是必须得好好管理可以。 松耦合先来看看耦合的例子1-1 public class ChiFan&#123; private Kuaizi kuaizi; ChiFan()&#123; this.kuaizi=new kuaizi(); &#125; public void eat()&#123; this.kuaizi.eat(); &#125; &#125; 吃饭需要用到筷子，所以吃饭之前必须得有个筷子，但是吃饭不一定得用筷子，也可以用叉子等等。这个时候如果要改成叉子就需要改变代码了，这个时候就体现了耦合性得缺点。 再看看松耦合的例子1-2 public class ChiFan&#123; private Tool tool; ChiFan(Tool tool)&#123; this.tool=tool; &#125; public void eat()&#123; this.tool.eat(); &#125; &#125; 这里可以看到我们使用接口Tool来当作参数，要吃饭必须给一个吃饭的工具才行，而这个工具是可以有多种实现，可以用筷子实现也可以用叉子实现，这里也体现了多态性。 依赖注入(DI)","text":"耦合耦合就是一个类依赖于其他的类才能完成其功能。耦合具有两面性，一个方面是难以测试，难以复用和难以理解，另外一个方面是我们却不得不耦合，完全没有耦合的代码几乎啥都干不了。所以耦合是必须的，但是必须得好好管理可以。 松耦合先来看看耦合的例子1-1 public class ChiFan&#123; private Kuaizi kuaizi; ChiFan()&#123; this.kuaizi=new kuaizi(); &#125; public void eat()&#123; this.kuaizi.eat(); &#125; &#125; 吃饭需要用到筷子，所以吃饭之前必须得有个筷子，但是吃饭不一定得用筷子，也可以用叉子等等。这个时候如果要改成叉子就需要改变代码了，这个时候就体现了耦合性得缺点。 再看看松耦合的例子1-2 public class ChiFan&#123; private Tool tool; ChiFan(Tool tool)&#123; this.tool=tool; &#125; public void eat()&#123; this.tool.eat(); &#125; &#125; 这里可以看到我们使用接口Tool来当作参数，要吃饭必须给一个吃饭的工具才行，而这个工具是可以有多种实现，可以用筷子实现也可以用叉子实现，这里也体现了多态性。 依赖注入(DI)依赖注入的思想与传统的做法不同在于 传统做法是每个对象自己管理自己需要的相互协作的对象,如同例子1-1那样，在自己里面直接new一个出来。 依赖注入就是这个对象去请求要一个这样的对象才能完成工作，这个依赖对象可以set方法进来的也可以是构造方法进来的,一般推荐使用构造方法进来，因为你这个对象没了那些依赖对象无法进行工作，所以如果没有这些依赖对象直接不能创建类的实例才是。一句话概括就是依赖注入会将依赖关系的关系自动交给目标对象，而不是是自己去获取依赖。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.unclezs.com/tags/spring/"},{"name":"耦合","slug":"耦合","permalink":"https://blog.unclezs.com/tags/%E8%80%A6%E5%90%88/"}]},{"title":"Servlet回顾 之 源码入手","slug":"Java/javaee/Servlet回顾-之-源码入手","date":"2020-03-09T06:51:20.000Z","updated":"2021-01-03T10:25:18.000Z","comments":true,"path":"Java/javaee/Servlet回顾-之-源码入手.html","link":"","permalink":"https://blog.unclezs.com/Java/javaee/Servlet%E5%9B%9E%E9%A1%BE-%E4%B9%8B-%E6%BA%90%E7%A0%81%E5%85%A5%E6%89%8B.html","excerpt":"前言感觉用了太久的框架这Servlet写着都有点陌生了，所以打算重温下。还有一个原因就是因为Servlet当时第一次学的时候并没有学习Spring也没有刨源码学,所以在学习了SpringMVC的时候就不知道这个MVC是如何接管了。 Servlet与tomcat 与tomcat之间的交互 Servlet继承树 源码解析tomcat配置1. context.xml的配置&lt;Context&gt; &lt;WatchedResource&gt;WEB-INF/web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;WEB-INF/tomcat-web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;$&#123;catalina.base&#125;/conf/web.xml&lt;/WatchedResource&gt; &lt;/Context&gt; 可以看到tomcat服务器启动项目的时候会加载 WEB-INF 下面的xml配置，${catalina.base}代表的就是tomcat的home目录。也就是说tomcat跑起来的时候会自动加载tomcat的home目录下面的conf/web.xml里面配置了默认的Servlet，也就是我们安装tomcat后默认打开的看到的那个tomcat网页的原因。也定义了一些默认的mine-mapping用户文件访问。 2. ServletContextListener","text":"前言感觉用了太久的框架这Servlet写着都有点陌生了，所以打算重温下。还有一个原因就是因为Servlet当时第一次学的时候并没有学习Spring也没有刨源码学,所以在学习了SpringMVC的时候就不知道这个MVC是如何接管了。 Servlet与tomcat 与tomcat之间的交互 Servlet继承树 源码解析tomcat配置1. context.xml的配置&lt;Context&gt; &lt;WatchedResource&gt;WEB-INF/web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;WEB-INF/tomcat-web.xml&lt;/WatchedResource&gt; &lt;WatchedResource&gt;$&#123;catalina.base&#125;/conf/web.xml&lt;/WatchedResource&gt; &lt;/Context&gt; 可以看到tomcat服务器启动项目的时候会加载 WEB-INF 下面的xml配置，${catalina.base}代表的就是tomcat的home目录。也就是说tomcat跑起来的时候会自动加载tomcat的home目录下面的conf/web.xml里面配置了默认的Servlet，也就是我们安装tomcat后默认打开的看到的那个tomcat网页的原因。也定义了一些默认的mine-mapping用户文件访问。 2. ServletContextListenerpublic interface ServletContextListener extends EventListener &#123; default public void contextInitialized(ServletContextEvent sce) &#123;&#125; default public void contextDestroyed(ServletContextEvent sce) &#123;&#125; &#125; 如果监听器实现了这个接口，在Servlet容器初始化的时候会调用contextInitialized，在SpringMVC框架中就是实现了这个接口对XmlWebApplicationContext进行实例化创建了Spring容器在销毁的时候调用contextDestroyed方法。 ServletContextServlet的上线文对象，每个应用只有一个上下文对象，这个对像是根据web.xml来创建的，里面有addListenr、addFilter等方法，具体可以自行查看。 3. ServletConfig public interface ServletConfig &#123; public String getServletName(); public ServletContext getServletContext(); public String getInitParameter(String name); public Enumeration&lt;String&gt; getInitParameterNames(); &#125; 这个是在Servlet被创建的时候会传入一个ServletConfig对象进Servlet，可以获取到容器的Servlet的上下文，比如在web.xml里面配置的,就可以通过此获取到 Servlet public interface Servlet &#123; public void init(ServletConfig config) throws ServletException; public ServletConfig getServletConfig(); public void service(ServletRequest req, ServletResponse res)throws ServletException, IOException; public String getServletInfo(); public void destroy(); &#125; 当tomcat将servlet实例化之后将会调用Servlet的service方法，并将封装好的ServletRequest和ServletResponse方法传入 GenericServlet public abstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializable&#123; //func... &#125; 这个是一个对Servlet的增强方法，可以方便的获取到Servlet上下文信息,和上下文参数 HttpServlet public abstract class HttpServlet extends GenericServlet &#123; protected void doGet(HttpServletRequest req,HttpServletResponse resp)&#123; String protocol = req.getProtocol(); String msg = lStrings.getString(&quot;http.method_get_not_supported&quot;); if (protocol.endsWith(&quot;1.1&quot;)) &#123; resp.sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED, msg); &#125; else &#123; resp.sendError(HttpServletResponse.SC_BAD_REQUEST, msg); &#125; &#125; protected void doPost(HttpServletRequest req,HttpServletResponse resp)&#123;&#125; protected void doPut(HttpServletRequest req,HttpServletResponse resp)&#123;&#125; protected void doHead(HttpServletRequest req,HttpServletResponse resp)&#123;&#125; protected void doDelete(HttpServletRequest req,HttpServletResponse resp)&#123;&#125; protected void doOptions(HttpServletRequest req, HttpServletResponse resp)&#123;&#125; protected void doTrace(HttpServletRequest req, HttpServletResponse resp)&#123;&#125; protected void service(HttpServletRequest req, HttpServletResponse resp)&#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; &#125; 这是Servlet的Http封装，一般我们编写Servlet的时候都是继承自这个类，这里面的doXXX方法统计都是响应方法不被支持，这个是为了如果我们没有重写这个方法，那么这个接口将不支持这个请求方法。在service里面就是对这些doXXX的调用，因为Servelt被tomcat调用的只有这个Service方法。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"JavaEE","slug":"Java/JavaEE","permalink":"https://blog.unclezs.com/categories/Java/JavaEE/"}],"tags":[{"name":"servlet","slug":"servlet","permalink":"https://blog.unclezs.com/tags/servlet/"},{"name":"javaee","slug":"javaee","permalink":"https://blog.unclezs.com/tags/javaee/"},{"name":"源码解析","slug":"源码解析","permalink":"https://blog.unclezs.com/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"}]},{"title":"Spring之Bean的作用域","slug":"Java/Spring/Spring之Bean的作用域","date":"2020-03-09T06:44:00.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/Spring/Spring之Bean的作用域.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/Spring%E4%B9%8BBean%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F.html","excerpt":"在Spring中，bean作用域用于确定哪种类型的bean实例应该从Spring容器中返回给调用者。 目前Spring Bean的作用域或者说范围主要有五种。 作用域 描述 singleton 在spring IoC容器仅存在一个Bean实例，Bean以单例方式存在，bean作用域范围的默认值。 prototype 每次从容器中调用Bean时，都返回一个新的实例，即每次调用getBean()时，相当于执行newXxxBean()。 request 每次HTTP请求都会创建一个新的Bean，该作用域仅适用于web的Spring WebApplicationContext环境。 session 同一个HTTP Session共享一个Bean，不同Session使用不同的Bean。该作用域仅适用于web的Spring WebApplicationContext环境。 application 限定一个Bean的作用域为ServletContext的生命周期。该作用域仅适用于web的Spring WebApplicationContext环境。 websocket 将单个bean定义的作用域限定为的生命周期WebSocket。仅在可感知网络的Spring上下文中有效ApplicationContext。 官方文档：Bean Scopes","text":"在Spring中，bean作用域用于确定哪种类型的bean实例应该从Spring容器中返回给调用者。 目前Spring Bean的作用域或者说范围主要有五种。 作用域 描述 singleton 在spring IoC容器仅存在一个Bean实例，Bean以单例方式存在，bean作用域范围的默认值。 prototype 每次从容器中调用Bean时，都返回一个新的实例，即每次调用getBean()时，相当于执行newXxxBean()。 request 每次HTTP请求都会创建一个新的Bean，该作用域仅适用于web的Spring WebApplicationContext环境。 session 同一个HTTP Session共享一个Bean，不同Session使用不同的Bean。该作用域仅适用于web的Spring WebApplicationContext环境。 application 限定一个Bean的作用域为ServletContext的生命周期。该作用域仅适用于web的Spring WebApplicationContext环境。 websocket 将单个bean定义的作用域限定为的生命周期WebSocket。仅在可感知网络的Spring上下文中有效ApplicationContext。 官方文档：Bean Scopes","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"作用域","slug":"作用域","permalink":"https://blog.unclezs.com/tags/%E4%BD%9C%E7%94%A8%E5%9F%9F/"}]},{"title":"出生第一篇，介绍下怎么出生的","slug":"出生第一篇，介绍下怎么出生的","date":"2020-03-04T09:33:01.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"出生第一篇，介绍下怎么出生的.html","link":"","permalink":"https://blog.unclezs.com/%E5%87%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E7%AF%87%EF%BC%8C%E4%BB%8B%E7%BB%8D%E4%B8%8B%E6%80%8E%E4%B9%88%E5%87%BA%E7%94%9F%E7%9A%84.html","excerpt":"起因大一的时候在用 WordPress 搭建了一个博客，但是坚持写了几个月的博客，后来发现没有什么人看，于是就迁移到了CSDN。 CSDN也用了快两年了，但是有段时间突然没有写博客的动力，感觉自己的博客没有什么含金量，于是停下了博客，加紧提升自己去了。 现在大三快结束了，正准备参加秋招实习面试了，于是开始恶补自己的盲区与基础，但是在这个过程中觉得有些东西确实应该记录下，于是有了这个博客的诞生，于是开始选型，主要需求就是便于迁移，和使用方便，不像wordpress那样笨重，但是也需要有点颜值的，于是相中了Hexo+butterfly这套。 本来是打算使用github pages来部署的，但是发现访问实在是汗颜，于是想着去码云，发现码云居然自定义域名需要99/年的服务费，然后想着用gitlab发现还是很慢，于是自己搭建了一个gitlab，打算用CI部署到Nginx，结果给我用掉了1个多G内存。实在是伤不起，于是决定还是老实用自己的服务器上搭个Nginx来跑了。 2020-8-9 更新 对主题Maupassant进行DIY改成了现在自己还算满意的样子，主要更改是添加阅读时候的目录显示，与正文显示主题样式。 最终方案： 服务器 博客框架 博客主题 部署方式 Nginx Hexo Maupassant sftp 博客搭建过程","text":"起因大一的时候在用 WordPress 搭建了一个博客，但是坚持写了几个月的博客，后来发现没有什么人看，于是就迁移到了CSDN。 CSDN也用了快两年了，但是有段时间突然没有写博客的动力，感觉自己的博客没有什么含金量，于是停下了博客，加紧提升自己去了。 现在大三快结束了，正准备参加秋招实习面试了，于是开始恶补自己的盲区与基础，但是在这个过程中觉得有些东西确实应该记录下，于是有了这个博客的诞生，于是开始选型，主要需求就是便于迁移，和使用方便，不像wordpress那样笨重，但是也需要有点颜值的，于是相中了Hexo+butterfly这套。 本来是打算使用github pages来部署的，但是发现访问实在是汗颜，于是想着去码云，发现码云居然自定义域名需要99/年的服务费，然后想着用gitlab发现还是很慢，于是自己搭建了一个gitlab，打算用CI部署到Nginx，结果给我用掉了1个多G内存。实在是伤不起，于是决定还是老实用自己的服务器上搭个Nginx来跑了。 2020-8-9 更新 对主题Maupassant进行DIY改成了现在自己还算满意的样子，主要更改是添加阅读时候的目录显示，与正文显示主题样式。 最终方案： 服务器 博客框架 博客主题 部署方式 Nginx Hexo Maupassant sftp 博客搭建过程环境及工具问题本地 Node.js VsCode 云端 装好Nginx的服务器一台 开始搭建安装因为都是中文文档并且很详细，所以没有必要说啥安装配置教程，自己看看就能够装好了。 首先按照Hexo官网中文文档装好Hexo 然后按照maupassant官网文档装好并且配置好。 上传代码如何选择Hexo的部署方式有很多，git和ftp还有其他一些代码托管中心，当然也可以自己复制public下面的文件随便丢到一个服务器就行了。 如果你想要快并且不需要自定义域名，那么你可以选择码云的Pages服务，因为在国内访问速度还是很可观的。 我选择sftp方式，因为搭建ftp服务也会占用，而stfp是建立在ssh服务上的，如果你有装了ssh那么sftp也有了，不需要另外再去搭建了。sftp比ftp更加安全，但是效率上会低一点，因为我们的博客部署没多大的多西，所以感觉不到什么慢的。 具体操作修改hexo根目录里面的_config.yml文件，拉到最下面有个deploy，具体配置方式可以参见Hexo配置部署文档,这里面还是很详细的。这里贴下sftp部署的代码。 deploy: - type: sftp # 部署方式 host: blog.unclezs.com #主机地址 user: unclezs # 用户名 pass: unclezs # 密码 remotePath: /nignx/html/xxx #部署到的目录 port: 22 # SSH端口号 然后只需要执行一下 hexo deploy就可以部署到服务器访问自己的域名即可了。 当前已经改主题，网站下面","categories":[{"name":"博客","slug":"博客","permalink":"https://blog.unclezs.com/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.unclezs.com/tags/hexo/"}]},{"title":"前后端分离与不分离的登录方式解析","slug":"Web前端/前后端分离与不分离的登录方式解析","date":"2019-10-13T03:33:55.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Web前端/前后端分离与不分离的登录方式解析.html","link":"","permalink":"https://blog.unclezs.com/Web%E5%89%8D%E7%AB%AF/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E4%B8%8E%E4%B8%8D%E5%88%86%E7%A6%BB%E7%9A%84%E7%99%BB%E5%BD%95%E6%96%B9%E5%BC%8F%E8%A7%A3%E6%9E%90.html","excerpt":"一、序言1.1 起因现在越来越流行前后端分离的方式进行开发了，做Web开发的，逃不掉的就是登录了，因为前后端分离登录与传统的方式不再相同，所以就想总结下它们各自的实现方式 1.2 什么是前后端不分离前后端不分离也就是前端的页面是由后端进行渲染的，也就是前端的只负责写样式和JS，后端负责填充数据，前端代码里面混杂着后端代码，两者的耦合度非常高，就像JSP那样，这种实现就不容易维护，一旦除了问题前后端都得返工，开发效率低下； 1.3 什么是前后端分离为了解决不分离情况下带来的弊端，把页面渲染数据这部分从后端手中抽离出来，交由前端去做，当然这里不是直接让他去干后端的代码，而是前端所有用到的数据都是后端通过异步接口的方式提供的，前端将数据通过ajax异步请求把数据拿到，然后负责展示即可。这样的好处就是，你前端不管想怎么改样式后端都不用管，因为里面没有了后端代码，你怎么改也不关后端的事情了 1.4 完全分离–Mock上面分离确实是将前后端分离开了，但是还有一个问题，就是这样并没有提高太多效率，因为你前端开发的时候需要后端的数据接口才能完整开发，应对这样的情况，应运而生的Mock就起到了关键作用，Mock就是模拟后端的数据接口，需要什么数据都可以模拟出来，等到后面对接后端的时候只需要把Mock的接口地址换成真正的接口就地址就可以了，这样前端也就完全脱离了后端进行开发了 二、关于登录的必要概念","text":"一、序言1.1 起因现在越来越流行前后端分离的方式进行开发了，做Web开发的，逃不掉的就是登录了，因为前后端分离登录与传统的方式不再相同，所以就想总结下它们各自的实现方式 1.2 什么是前后端不分离前后端不分离也就是前端的页面是由后端进行渲染的，也就是前端的只负责写样式和JS，后端负责填充数据，前端代码里面混杂着后端代码，两者的耦合度非常高，就像JSP那样，这种实现就不容易维护，一旦除了问题前后端都得返工，开发效率低下； 1.3 什么是前后端分离为了解决不分离情况下带来的弊端，把页面渲染数据这部分从后端手中抽离出来，交由前端去做，当然这里不是直接让他去干后端的代码，而是前端所有用到的数据都是后端通过异步接口的方式提供的，前端将数据通过ajax异步请求把数据拿到，然后负责展示即可。这样的好处就是，你前端不管想怎么改样式后端都不用管，因为里面没有了后端代码，你怎么改也不关后端的事情了 1.4 完全分离–Mock上面分离确实是将前后端分离开了，但是还有一个问题，就是这样并没有提高太多效率，因为你前端开发的时候需要后端的数据接口才能完整开发，应对这样的情况，应运而生的Mock就起到了关键作用，Mock就是模拟后端的数据接口，需要什么数据都可以模拟出来，等到后面对接后端的时候只需要把Mock的接口地址换成真正的接口就地址就可以了，这样前端也就完全脱离了后端进行开发了 二、关于登录的必要概念2.1 什么是sessionsession是一次浏览器和服务器交互的会话，在jsp中，作为一个内置对象存在。我的理解，就是当用户打开网页时，程序会在浏览器中开辟一段空间来存储作为session的存储，可以对一些用户信息进行保存。session就是一个会话级别的cokkie，外加服务器内存中的一组散列表。当关闭浏览器时，cookie会消失，session也就消失了，这个cookie不写在磁盘上，而是写在浏览器的缓存中。 2.2 session和cookie的区别 cookie数据存放在客户的浏览器中，session数据放在服务器上 cookie不是很安全，别人可以轻易的获取本地的cookie并获取相关信息进行欺诈 session有时间限制，会在设置的一定时间内保存到服务器上。 cookie有限制，单个为3k，一个站点在客户端存放的cookie不能超过3k 所以一般将登陆的用户信息保存到session上，以防被盗，如果是其他信息，可以放在cookie里面，如果考虑到服务器的性能，减轻压力，应该使用cookie 三、前后端不分离的登录实现方式因为前后端不分离的情况下，我们可以基于Cookie和Session来实现登录；大致流程就是： 前端发起登录请求 后端验证是否登录成功，成功则记录一个Session，响应的时候把SessionID写入Cookie 每次请求都会带着Cookie 后端可以根据Cookie中的Session来确认你是否登录过，而保持登录状态 四、前后端分离情况下4.1 有状态登录分离的情况下，服务器也能为你写上Session到Cookie，但是对于Ajax默认对于跨域请求是不带Cookie的，这时候有两种解决方式，1.设置ajax请求默认全部带上Cookie,并且后端开启跨域支持，2.通过代理实现不跨域，开发阶段可以用Webpack的proxy，部署阶段可以用nginx的反向代理 4.2 无状态登录Token什么叫无状态，也就是服务器不保存你的登录状态，不保存登录状态那服务器怎么知道你登陆了呢，原因很简单，就是Token里面保存了你的信息，就像这样 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHBpcmVUaW1lIjoxNTQ5NTU0NDUyLCJ1c2VyTmFtZSI6IuacveacqCIsInVzZXJJZCI6IjY2NiJ9.fiQKWuMTWbkfQ3dOozoJr13pJSmKnc5El4EBnKyU42o 用户每次请求时候带上这个，这个放在请求头里面，后端根据Token就能解析出来用户信息当然生成这样的Token肯定得有时效性，一段时间自动过期保证安全 应用场景：1.在分布式系统中，每个服务部署在的服务器都不一样，所以这个时候的服务器端Session就无效了，这个时候带着Token无论去哪个服务器去请求资源都能够解析用户信息2.对于单点登录，就像京东一样，一次登录每个服务都相当于登录了","categories":[{"name":"Web前端","slug":"Web前端","permalink":"https://blog.unclezs.com/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前后端分离","slug":"前后端分离","permalink":"https://blog.unclezs.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/"},{"name":"Web前端","slug":"Web前端","permalink":"https://blog.unclezs.com/tags/Web%E5%89%8D%E7%AB%AF/"}]},{"title":"Java的Duration的时间格式解析，ISO-8601持续时间格式","slug":"Java/基础/java的Duration的时间格式解析，ISO-8601持续时间格式","date":"2019-10-03T07:25:16.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/java的Duration的时间格式解析，ISO-8601持续时间格式.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/java%E7%9A%84Duration%E7%9A%84%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90%EF%BC%8CISO-8601%E6%8C%81%E7%BB%AD%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F.html","excerpt":"一、前言 在配置springboot的配置的时候突然看到时间是Duration来配置的，上源码看到这样一个方法 /** * Obtains a &#123;@code Duration&#125; from a text string such as &#123;@code PnDTnHnMn.nS&#125;. * &lt;p&gt; * This will parse a textual representation of a duration, including the * string produced by &#123;@code toString()&#125;. The formats accepted are based * on the ISO-8601 duration format &#123;@code PnDTnHnMn.nS&#125; with days * considered to be exactly 24 hours. * &lt;p&gt; * The string starts with an optional sign, denoted by the ASCII negative * or positive symbol. If negative, the whole period is negated. * The ASCII letter &quot;P&quot; is next in upper or lower case. * There are then four sections, each consisting of a number and a suffix. * The sections have suffixes in ASCII of &quot;D&quot;, &quot;H&quot;, &quot;M&quot; and &quot;S&quot; for * days, hours, minutes and seconds, accepted in upper or lower case. * The suffixes must occur in order. The ASCII letter &quot;T&quot; must occur before * the first occurrence, if any, of an hour, minute or second section. * At least one of the four sections must be present, and if &quot;T&quot; is present * there must be at least one section after the &quot;T&quot;. * The number part of each section must consist of one or more ASCII digits. * The number may be prefixed by the ASCII negative or positive symbol. * The number of days, hours and minutes must parse to an &#123;@code long&#125;. * The number of seconds must parse to an &#123;@code long&#125; with optional fraction. * The decimal point may be either a dot or a comma. * The fractional part may have from zero to 9 digits. * &lt;p&gt; * The leading plus/minus sign, and negative values for other units are * not part of the ISO-8601 standard. * &lt;p&gt; * Examples: * &lt;pre&gt; * &quot;PT20.345S&quot; -- parses as &quot;20.345 seconds&quot; * &quot;PT15M&quot; -- parses as &quot;15 minutes&quot; (where a minute is 60 seconds) * &quot;PT10H&quot; -- parses as &quot;10 hours&quot; (where an hour is 3600 seconds) * &quot;P2D&quot; -- parses as &quot;2 days&quot; (where a day is 24 hours or 86400 seconds) * &quot;P2DT3H4M&quot; -- parses as &quot;2 days, 3 hours and 4 minutes&quot; * &quot;P-6H3M&quot; -- parses as &quot;-6 hours and +3 minutes&quot; * &quot;-P6H3M&quot; -- parses as &quot;-6 hours and -3 minutes&quot; * &quot;-P-6H+3M&quot; -- parses as &quot;+6 hours and -3 minutes&quot; * &lt;/pre&gt; * * @param text the text to parse, not null * @return the parsed duration, not null * @throws DateTimeParseException if the text cannot be parsed to a duration */ public static Duration parse(CharSequence text) &#123; ... &#125; 大致意思就是按照ISO-8601持续时间格式格式都能进行解析；那就说说这个格式怎么写 二、ISO-8601持续时间格式运行间隔以”P”开始，和上面一样也是用”T”分割日期和时间，如P1Y2M10DT2H30M15S P 开始标记1Y - 一年2M - 两个月10D - 十天T - 时间和日期分的割标记2H - 两个小时30M - 三十分钟15S 十五秒钟 例子，注意如果没有年月日，”T”也不能省略 P1DT1M - 一天一分钟执行一次P1W - 一周执行一次PT1H - 一小时执行一次PT10S - 十秒执行一次","text":"一、前言 在配置springboot的配置的时候突然看到时间是Duration来配置的，上源码看到这样一个方法 /** * Obtains a &#123;@code Duration&#125; from a text string such as &#123;@code PnDTnHnMn.nS&#125;. * &lt;p&gt; * This will parse a textual representation of a duration, including the * string produced by &#123;@code toString()&#125;. The formats accepted are based * on the ISO-8601 duration format &#123;@code PnDTnHnMn.nS&#125; with days * considered to be exactly 24 hours. * &lt;p&gt; * The string starts with an optional sign, denoted by the ASCII negative * or positive symbol. If negative, the whole period is negated. * The ASCII letter &quot;P&quot; is next in upper or lower case. * There are then four sections, each consisting of a number and a suffix. * The sections have suffixes in ASCII of &quot;D&quot;, &quot;H&quot;, &quot;M&quot; and &quot;S&quot; for * days, hours, minutes and seconds, accepted in upper or lower case. * The suffixes must occur in order. The ASCII letter &quot;T&quot; must occur before * the first occurrence, if any, of an hour, minute or second section. * At least one of the four sections must be present, and if &quot;T&quot; is present * there must be at least one section after the &quot;T&quot;. * The number part of each section must consist of one or more ASCII digits. * The number may be prefixed by the ASCII negative or positive symbol. * The number of days, hours and minutes must parse to an &#123;@code long&#125;. * The number of seconds must parse to an &#123;@code long&#125; with optional fraction. * The decimal point may be either a dot or a comma. * The fractional part may have from zero to 9 digits. * &lt;p&gt; * The leading plus/minus sign, and negative values for other units are * not part of the ISO-8601 standard. * &lt;p&gt; * Examples: * &lt;pre&gt; * &quot;PT20.345S&quot; -- parses as &quot;20.345 seconds&quot; * &quot;PT15M&quot; -- parses as &quot;15 minutes&quot; (where a minute is 60 seconds) * &quot;PT10H&quot; -- parses as &quot;10 hours&quot; (where an hour is 3600 seconds) * &quot;P2D&quot; -- parses as &quot;2 days&quot; (where a day is 24 hours or 86400 seconds) * &quot;P2DT3H4M&quot; -- parses as &quot;2 days, 3 hours and 4 minutes&quot; * &quot;P-6H3M&quot; -- parses as &quot;-6 hours and +3 minutes&quot; * &quot;-P6H3M&quot; -- parses as &quot;-6 hours and -3 minutes&quot; * &quot;-P-6H+3M&quot; -- parses as &quot;+6 hours and -3 minutes&quot; * &lt;/pre&gt; * * @param text the text to parse, not null * @return the parsed duration, not null * @throws DateTimeParseException if the text cannot be parsed to a duration */ public static Duration parse(CharSequence text) &#123; ... &#125; 大致意思就是按照ISO-8601持续时间格式格式都能进行解析；那就说说这个格式怎么写 二、ISO-8601持续时间格式运行间隔以”P”开始，和上面一样也是用”T”分割日期和时间，如P1Y2M10DT2H30M15S P 开始标记1Y - 一年2M - 两个月10D - 十天T - 时间和日期分的割标记2H - 两个小时30M - 三十分钟15S 十五秒钟 例子，注意如果没有年月日，”T”也不能省略 P1DT1M - 一天一分钟执行一次P1W - 一周执行一次PT1H - 一小时执行一次PT10S - 十秒执行一次","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"源码解析","slug":"源码解析","permalink":"https://blog.unclezs.com/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"name":"Duration","slug":"Duration","permalink":"https://blog.unclezs.com/tags/Duration/"}]},{"title":"vue-admin-template改造实现后台传入路由表动态生成权限菜单","slug":"Web前端/vue-admin-template改造实现后台传入路由表动态生成权限菜单","date":"2019-10-02T07:51:58.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Web前端/vue-admin-template改造实现后台传入路由表动态生成权限菜单.html","link":"","permalink":"https://blog.unclezs.com/Web%E5%89%8D%E7%AB%AF/vue-admin-template%E6%94%B9%E9%80%A0%E5%AE%9E%E7%8E%B0%E5%90%8E%E5%8F%B0%E4%BC%A0%E5%85%A5%E8%B7%AF%E7%94%B1%E8%A1%A8%E5%8A%A8%E6%80%81%E7%94%9F%E6%88%90%E6%9D%83%E9%99%90%E8%8F%9C%E5%8D%95.html","excerpt":"序言因为打算做前后端分离的权限控制，并且生成动态的权限菜单，但是发现vue-admin-template是前端根据角色控制页面，并且代码写死在前端，我觉得这样不好，后面用户管理的时候添加了个角色前端就得改代码，就查阅了下资料，根据后台来传入路由表，然后再通过router.addRouters()；方法将路由表添加进去； 具体1.后台传入路由表数据数据格式&#123; &quot;message&quot;: &quot;success&quot;, &quot;success&quot;: true, &quot;code&quot;: 20000, &quot;data&quot;: &#123; &quot;name&quot;: &quot;Uncle&quot;, &quot;avatar&quot;: &quot;https://wpimg.wallstcn.com/f778738c-e4f8-4870-b634-56703b4acafe.gif&quot;, &quot;roles&quot;: [&quot;admin&quot;], &quot;routers&quot;: [&#123; &quot;name&quot;: &quot;Test_It&quot;, &quot;path&quot;: &quot;/test&quot;, &quot;component&quot;: &quot;Layout&quot;, &quot;children&quot;: [&#123; &quot;name&quot;: &quot;Test_It_c&quot;, &quot;path&quot;: &quot;index&quot;, &quot;component&quot;: &quot;Test&quot;, &quot;meta&quot;: &#123; &quot;icon&quot;: &quot;example&quot;, &quot;title&quot;: &quot;后台&quot; &#125;, &#125;] &#125;] &#125; &#125; 2.前端页面将json格式化成js对象，重点是将compoent转化真实的组件对象2.1 格式化工具 import Test from &#x27;@/views/form/index&#x27; import Layout from &#x27;@/layout&#x27; export default function (routers) &#123; return filterAsyncRouter(routers) &#125; //将后台返回的json权限数据格式化（递归遍历子节点） export const filterAsyncRouter=(asyncRouterMap) =&gt;&#123; //遍历后台传来的路由字符串，转换为组件对象 const accessedRouters = asyncRouterMap.filter(route =&gt; &#123; if (route.component) &#123; if (route.component === &#x27;Layout&#x27;) &#123; //Layout组件特殊处理 route.component = Layout &#125; else &#123; route.component = Test &#125; &#125; if (route.children &amp;&amp; route.children.length) &#123; route.children = filterAsyncRouter(route.children) &#125; return true &#125;) return accessedRouters &#125; 2.2 获取路由表并且格式化 import &#123;constantRouterMap&#125; from &#x27;@/router&#x27;; const user = &#123; state: &#123; routers: constantRouterMap, addRouters: [] &#125;, mutations: &#123; SET_ROUTERS: (state, routers) =&gt; &#123; state.addRouters = routers; //路由访问 state.routers = constantRouterMap.concat(routers); //菜单显示 &#125; &#125;, actions: &#123; // 获取用户信息 GetInfo(&#123;commit,state &#125;) &#123; return new Promise((resolve, reject) =&gt; &#123; getInfo(state.token).then(response =&gt; &#123; const data = response.data commit(&#x27;SET_NAME&#x27;, data.name) commit(&#x27;SET_ROLES&#x27;, data.roles) commit(&#x27;SET_AVATAR&#x27;, data.avatar) commit(&#x27;SET_ROUTERS&#x27;, routerFormat(data.routers)) resolve(response) &#125;).catch(error =&gt; &#123; reject(error) &#125;) &#125;) &#125;, &#125;","text":"序言因为打算做前后端分离的权限控制，并且生成动态的权限菜单，但是发现vue-admin-template是前端根据角色控制页面，并且代码写死在前端，我觉得这样不好，后面用户管理的时候添加了个角色前端就得改代码，就查阅了下资料，根据后台来传入路由表，然后再通过router.addRouters()；方法将路由表添加进去； 具体1.后台传入路由表数据数据格式&#123; &quot;message&quot;: &quot;success&quot;, &quot;success&quot;: true, &quot;code&quot;: 20000, &quot;data&quot;: &#123; &quot;name&quot;: &quot;Uncle&quot;, &quot;avatar&quot;: &quot;https://wpimg.wallstcn.com/f778738c-e4f8-4870-b634-56703b4acafe.gif&quot;, &quot;roles&quot;: [&quot;admin&quot;], &quot;routers&quot;: [&#123; &quot;name&quot;: &quot;Test_It&quot;, &quot;path&quot;: &quot;/test&quot;, &quot;component&quot;: &quot;Layout&quot;, &quot;children&quot;: [&#123; &quot;name&quot;: &quot;Test_It_c&quot;, &quot;path&quot;: &quot;index&quot;, &quot;component&quot;: &quot;Test&quot;, &quot;meta&quot;: &#123; &quot;icon&quot;: &quot;example&quot;, &quot;title&quot;: &quot;后台&quot; &#125;, &#125;] &#125;] &#125; &#125; 2.前端页面将json格式化成js对象，重点是将compoent转化真实的组件对象2.1 格式化工具 import Test from &#x27;@/views/form/index&#x27; import Layout from &#x27;@/layout&#x27; export default function (routers) &#123; return filterAsyncRouter(routers) &#125; //将后台返回的json权限数据格式化（递归遍历子节点） export const filterAsyncRouter=(asyncRouterMap) =&gt;&#123; //遍历后台传来的路由字符串，转换为组件对象 const accessedRouters = asyncRouterMap.filter(route =&gt; &#123; if (route.component) &#123; if (route.component === &#x27;Layout&#x27;) &#123; //Layout组件特殊处理 route.component = Layout &#125; else &#123; route.component = Test &#125; &#125; if (route.children &amp;&amp; route.children.length) &#123; route.children = filterAsyncRouter(route.children) &#125; return true &#125;) return accessedRouters &#125; 2.2 获取路由表并且格式化 import &#123;constantRouterMap&#125; from &#x27;@/router&#x27;; const user = &#123; state: &#123; routers: constantRouterMap, addRouters: [] &#125;, mutations: &#123; SET_ROUTERS: (state, routers) =&gt; &#123; state.addRouters = routers; //路由访问 state.routers = constantRouterMap.concat(routers); //菜单显示 &#125; &#125;, actions: &#123; // 获取用户信息 GetInfo(&#123;commit,state &#125;) &#123; return new Promise((resolve, reject) =&gt; &#123; getInfo(state.token).then(response =&gt; &#123; const data = response.data commit(&#x27;SET_NAME&#x27;, data.name) commit(&#x27;SET_ROLES&#x27;, data.roles) commit(&#x27;SET_AVATAR&#x27;, data.avatar) commit(&#x27;SET_ROUTERS&#x27;, routerFormat(data.routers)) resolve(response) &#125;).catch(error =&gt; &#123; reject(error) &#125;) &#125;) &#125;, &#125; 3.添加路由表全局路由拦截器 import router from &#x27;./router&#x27; import store from &#x27;./store&#x27; import NProgress from &#x27;nprogress&#x27; // Progress 进度条 import &#x27;nprogress/nprogress.css&#x27;// Progress 进度条样式 import &#123; Message &#125; from &#x27;element-ui&#x27; import &#123; getToken &#125; from &#x27;@/utils/auth&#x27; // 验权 const whiteList = [&#x27;/login&#x27;] // 不重定向白名单 router.beforeEach((to, from, next) =&gt; &#123; NProgress.start() if (getToken()) &#123; if (to.path === &#x27;/login&#x27;) &#123; next(&#123; path: &#x27;/&#x27; &#125;) &#125; else &#123; if (store.getters.name.length === 0) &#123; store.dispatch(&#x27;GetInfo&#x27;).then(res =&gt; &#123; // 拉取用户信息 router.addRoutes(store.getters.routers)//添加后台路由表 next(&#123; ...to, replace: true &#125;) &#125;).catch(e =&gt; &#123; store.dispatch(&#x27;FedLogOut&#x27;).then(() =&gt; &#123; Message.error(&#x27;验证失败,请重新登录&#x27;+e.message) next(&#123; path: &#x27;/login&#x27; &#125;) &#125;) &#125;) &#125; else &#123; next() &#125; &#125; &#125; else &#123; if (whiteList.indexOf(to.path) !== -1) &#123; next() &#125; else &#123; next(&#x27;/login&#x27;) NProgress.done() &#125; &#125; &#125;) router.afterEach(() =&gt; &#123; NProgress.done() // 结束Progress &#125;) 4.绑定路由表路径 @/layout/componets/SideBar/index.vue刚开始发现addRouters()之后能访问但是并没有在菜单中显示，打印出来看了下router.option.router没有添加的路由，但是自己在store里面的却有，所以这里路由绑定我就换成了store里的routers，成功显示。 routes() &#123; return this.$store.getters.routers//大坑。。 &#125;, 源码地址GitHub源码地址","categories":[{"name":"Web前端","slug":"Web前端","permalink":"https://blog.unclezs.com/categories/Web%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"后台管理","slug":"后台管理","permalink":"https://blog.unclezs.com/tags/%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86/"},{"name":"前后端分离","slug":"前后端分离","permalink":"https://blog.unclezs.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/"},{"name":"动态路由","slug":"动态路由","permalink":"https://blog.unclezs.com/tags/%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1/"},{"name":"vue","slug":"vue","permalink":"https://blog.unclezs.com/tags/vue/"}]},{"title":"RabbitMQ之工作模式","slug":"中间件/RabbitMQ/RabbitMQ之工作模式","date":"2019-09-12T08:39:54.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"中间件/RabbitMQ/RabbitMQ之工作模式.html","link":"","permalink":"https://blog.unclezs.com/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/RabbitMQ%E4%B9%8B%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F.html","excerpt":"六大工作模式RabbitMQ有以下几种工作模式 ：1、Work queues2、Publish/Subscribe3、Routing4、Topics5、Header6、RPC 一、 Work queues工作队列模式，采用默认的交换机，路由名称为队列名称，有多个终端消费同一个队列的时候，交换机采用轮询发送消息，通俗点说就是给第一个发一条，另外一个发下一条 应用场景：对于 任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 测试：1、多个消费者。2、生产者发送多个消息。结果：1、一条消息只会被一个消费者接收；2、rabbit采用轮询的方式将消息是平均发送给消费者的；3、消费者在处理完某条消息后，才会收到下一条消息。 二、 Publish/subscribe发布订阅模式：1、每个消费者监听自己的队列。2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息 应用场景：用户通知，当用户充值成功或转账完成系统通知用户，通知方式有短信、邮件多种方法 。 流程：1.生产者声明fanout类型交换机。声明两个队列并且绑定到此交换机，绑定时不需要指定routingkey发送消息时不需要指定routingkey","text":"六大工作模式RabbitMQ有以下几种工作模式 ：1、Work queues2、Publish/Subscribe3、Routing4、Topics5、Header6、RPC 一、 Work queues工作队列模式，采用默认的交换机，路由名称为队列名称，有多个终端消费同一个队列的时候，交换机采用轮询发送消息，通俗点说就是给第一个发一条，另外一个发下一条 应用场景：对于 任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 测试：1、多个消费者。2、生产者发送多个消息。结果：1、一条消息只会被一个消费者接收；2、rabbit采用轮询的方式将消息是平均发送给消费者的；3、消费者在处理完某条消息后，才会收到下一条消息。 二、 Publish/subscribe发布订阅模式：1、每个消费者监听自己的队列。2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息 应用场景：用户通知，当用户充值成功或转账完成系统通知用户，通知方式有短信、邮件多种方法 。 流程：1.生产者声明fanout类型交换机。声明两个队列并且绑定到此交换机，绑定时不需要指定routingkey发送消息时不需要指定routingkey 2.消费者交换机会将信息发布给每个监听本交换机的队列，但是如果多个消费者监听了同一个队列，这个队列还是会按照轮询方式把信息发给每个消费者，一人一条（非同一个信息） 三、Routing路由模式：1、每个消费者监听自己的队列，并且设置routingkey。2、生产者将消息发给交换机，由交换机根据routingkey来转发消息到指定的队列。 流程：1.生产者声明DIRECT类型交换机。声明两个队列并且绑定到此交换机，绑定时需要指定routingkey发送消息时需要指定routingkey2.消费者消费者绑定队列的时候可以指定routingkey来只获取指定routingkey的消息说明：Routing模式要求队列在绑定交换机时要指定routingkey，消息会转发到符合routingkey的队列。 四、Topics通配符模式：同路由模式相似，但是routingkey的匹配是通过通配符决定的，路由模式是相等才匹配设置交换机类型为Topics即可 应用场景：根据用户的通知设置去通知用户，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种通知类型都接收的则两种通知都有效。 通配符使用： [#],匹配一个或者多个词，比如 uncle.# ,可以匹配uncle.sms、uncle.email、uncle.sms.email [* ],匹配一个词，比如 uncle.*,可以匹配uncle.sms、uncle.email 例子： uncle.#.sms.# 能匹配 uncle.sms、uncle.email.sms,不能匹配 uncle.email 五、Headerheader模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。 六、RPCRPC即客户端远程调用服务端的方法 ，使用MQ可以实现RPC的异步调用，基于Direct交换机实现，流程如下：1、客户端即是生产者就是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列。2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果3、服务端将RPC方法 的结果发送到RPC响应队列4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabbitMQ","slug":"中间件/RabbitMQ","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/"}],"tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.unclezs.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabitMQ","slug":"RabitMQ","permalink":"https://blog.unclezs.com/tags/RabitMQ/"}]},{"title":"RabbitMQ入门程序之HelloWorld","slug":"中间件/RabbitMQ/RabbitMQ入门程序之HelloWorld","date":"2019-09-12T04:25:08.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"中间件/RabbitMQ/RabbitMQ入门程序之HelloWorld.html","link":"","permalink":"https://blog.unclezs.com/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/RabbitMQ%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F%E4%B9%8BHelloWorld.html","excerpt":"一、环境搭建1.下载RabbitMQRabbitMQ由Erlang语言开发，Erlang语言用于并发及分布式系统的开发，在电信领域应用广泛，OTP（OpenTelecom Platform）作为Erlang语言的一部分，包含了很多基于Erlang开发的中间件及工具库，安装RabbitMQ需要安装Erlang/OTP，并保持版本匹配，如下图：RabbitMQ的下载地址：http://www.rabbitmq.com/download.html 2.下载erlang地址如下：http://erlang.org/download/otp_win64_20.3.exe 3.安装先安装erlang再安装RabbitMQ 4.启动管理插件rabbitmq-plugins.bat enable rabbitmq_management访问 http://localhost:15672/#/登录用户名密码都是guest 二、创建工程","text":"一、环境搭建1.下载RabbitMQRabbitMQ由Erlang语言开发，Erlang语言用于并发及分布式系统的开发，在电信领域应用广泛，OTP（OpenTelecom Platform）作为Erlang语言的一部分，包含了很多基于Erlang开发的中间件及工具库，安装RabbitMQ需要安装Erlang/OTP，并保持版本匹配，如下图：RabbitMQ的下载地址：http://www.rabbitmq.com/download.html 2.下载erlang地址如下：http://erlang.org/download/otp_win64_20.3.exe 3.安装先安装erlang再安装RabbitMQ 4.启动管理插件rabbitmq-plugins.bat enable rabbitmq_management访问 http://localhost:15672/#/登录用户名密码都是guest 二、创建工程两个工程一个Consumer一个Producer，生产者负责发送消息，消费者负责监听队列取消息 1.导入依赖&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.7.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.Producerpublic class Producer01 &#123; private static final String QUEUE = &quot;HelloWorld&quot;;//队列名称 public static void main(String[] args) throws IOException, TimeoutException &#123; //创建连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置工厂 connectionFactory.setHost(&quot;127.0.0.1&quot;); connectionFactory.setPort(5672); connectionFactory.setUsername(&quot;root&quot;); connectionFactory.setPassword(&quot;root&quot;); connectionFactory.setVirtualHost(&quot;/&quot;); Connection connection = null; Channel channel = null; try &#123; //创建连接 connection = connectionFactory.newConnection(); //建立管道 channel = connection.createChannel(); //声明队列 //1.队列名称 //2.是否持久化 //3.是否独占队列 //4.是否自动删除 //5.参数 channel.queueDeclare(QUEUE, true, false, false, null); //发送消息 String message = &quot;我是Uncle哎哎，你好RabbitMQ &quot; + System.currentTimeMillis(); //1.交换机名称 //2.队列名称 //3.参数 //4.消息 channel.basicPublish(&quot;&quot;, QUEUE, null, message.getBytes()); System.out.println(&quot;发送信息：&quot; + message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //释放连接 if (channel != null) &#123; channel.close(); &#125; if (connection != null) &#123; connection.close(); &#125; &#125; &#125; &#125; 3.Consumerpublic class Consumer01&#123; private static final String QUEUE = &quot;HelloWorld&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; //连接工厂 ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(&quot;127.0.0.1&quot;); connectionFactory.setPort(5672); Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); //声明队列 channel.queueDeclare(QUEUE, true, false, false, null); //创建消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; super.handleDelivery(consumerTag, envelope, properties, body); System.out.println(&quot;收到消息：&quot; + new String(body, &quot;UTF-8&quot;)); &#125; &#125;; //绑定队列，消费者 channel.basicConsume(QUEUE, true, consumer); &#125; &#125; 4.测试 三、总结1、发送端操作流程1）创建连接2）创建通道3）声明队列4）发送消息 2、接收端1）创建连接2）创建通道3）声明队列4）监听队列5）接收消息6）ack回复","categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabbitMQ","slug":"中间件/RabbitMQ","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/"}],"tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.unclezs.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabitMQ","slug":"RabitMQ","permalink":"https://blog.unclezs.com/tags/RabitMQ/"}]},{"title":"JavaFX程序通过exe4j和FXLauncher实现打包exe加自动更新","slug":"Java/javaFX/JavaFX程序通过exe4j和FXLauncher实现打包exe加自动更新","date":"2019-07-18T14:00:47.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/javaFX/JavaFX程序通过exe4j和FXLauncher实现打包exe加自动更新.html","link":"","permalink":"https://blog.unclezs.com/Java/javaFX/JavaFX%E7%A8%8B%E5%BA%8F%E9%80%9A%E8%BF%87exe4j%E5%92%8CFXLauncher%E5%AE%9E%E7%8E%B0%E6%89%93%E5%8C%85exe%E5%8A%A0%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0.html","excerpt":"写在前面因为用JavaFX做了个PC的小说下载阅读软件，所以想实现下自动更新,每次手动下载更新实在太麻烦了，后来就百度了一下看看有没有现成的结果找到的FXLauncher，这个东西的官方文档实在是太过简洁了。不过好在弄出来了 操作过程1.首先下载官方的domo，然后分析他的配置引入依赖 &lt;dependency&gt; &lt;groupId&gt;no.tornado&lt;/groupId&gt; &lt;artifactId&gt;fxlauncher&lt;/artifactId&gt; &lt;version&gt;1.0.20&lt;/version&gt; &lt;/dependency&gt; 首先是properties &lt;properties&gt; &lt;app.filename&gt;Uncle小说&lt;/app.filename&gt; &lt;!--运行的主类--&gt; &lt;app.mainClass&gt;com.unclezs.UI.App.Main&lt;/app.mainClass&gt; &lt;!--FXLauncher运行后文件下载的位置--&gt; &lt;app.cacheDir&gt;./lib&lt;/app.cacheDir&gt; &lt;!--FXLauncher运行时候的参数，比如什么更新失败后继续打开程序之类的，有哪些看官方的Readme里面--&gt; &lt;app.parameters&gt;&lt;/app.parameters&gt; &lt;app.vendor&gt;Acme Inc&lt;/app.vendor&gt; &lt;app.version&gt;3.3&lt;/app.version&gt; &lt;!--更新文件的服务器地址，在这里可以打开下载你的更新jar包就行，tomcat和apache都行--&gt; &lt;app.url&gt;http://114.115.208.62/&lt;/app.url&gt; &lt;!--编译后的位置，这个位置在Idea里面是target下面的app目录--&gt; &lt;app.dir&gt;$&#123;project.build.directory&#125;/app&lt;/app.dir&gt; &lt;!--打包exe程序后的目录位置target/install--&gt; &lt;app.installerdir&gt;$&#123;project.build.directory&#125;/installer&lt;/app.installerdir&gt; &lt;!--是否接受版本降级--&gt; &lt;app.acceptDowngrade&gt;false&lt;/app.acceptDowngrade&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; 然后是build &lt;build&gt; &lt;plugins&gt; &lt;!-- 编译执行文件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;app.dir&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 拷贝依赖jar包到编译目录 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.10&lt;/version&gt; &lt;configuration&gt; &lt;excludeScope&gt;provided&lt;/excludeScope&gt; &lt;outputDirectory&gt;$&#123;app.dir&#125;&lt;/outputDirectory&gt; &lt;stripVersion&gt;true&lt;/stripVersion&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;!-- 生成 app.xml manifest --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;create-manifest&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;mainClass&gt;fxlauncher.CreateManifest&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;$&#123;app.url&#125;&lt;/argument&gt; &lt;argument&gt;$&#123;app.mainClass&#125;&lt;/argument&gt; &lt;argument&gt;$&#123;app.dir&#125;&lt;/argument&gt; &lt;argument&gt;--cache-dir=$&#123;app.cacheDir&#125;&lt;/argument&gt; &lt;argument&gt;--accept-downgrade=$&#123;app.acceptDowngrade&#125;&lt;/argument&gt; &lt;!--这里可以放你想要更新文件打包进去的文件 比如dll，db之类的，可以事先放在app目录下--&gt; &lt;argument&gt;--include-extensions=jpg&lt;/argument&gt; &lt;argument&gt;$&#123;app.parameters&#125;&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- 把app.xml打包进fxlauncher.xml,这样就启动器就不需要依赖app.xml来启动了 --&gt; &lt;execution&gt; &lt;id&gt;embed-manifest-in-launcher&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;exec&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;executable&gt;jar&lt;/executable&gt; &lt;workingDirectory&gt;$&#123;app.dir&#125;&lt;/workingDirectory&gt; &lt;arguments&gt; &lt;argument&gt;uf&lt;/argument&gt; &lt;argument&gt;fxlauncher.jar&lt;/argument&gt; &lt;argument&gt;app.xml&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;","text":"写在前面因为用JavaFX做了个PC的小说下载阅读软件，所以想实现下自动更新,每次手动下载更新实在太麻烦了，后来就百度了一下看看有没有现成的结果找到的FXLauncher，这个东西的官方文档实在是太过简洁了。不过好在弄出来了 操作过程1.首先下载官方的domo，然后分析他的配置引入依赖 &lt;dependency&gt; &lt;groupId&gt;no.tornado&lt;/groupId&gt; &lt;artifactId&gt;fxlauncher&lt;/artifactId&gt; &lt;version&gt;1.0.20&lt;/version&gt; &lt;/dependency&gt; 首先是properties &lt;properties&gt; &lt;app.filename&gt;Uncle小说&lt;/app.filename&gt; &lt;!--运行的主类--&gt; &lt;app.mainClass&gt;com.unclezs.UI.App.Main&lt;/app.mainClass&gt; &lt;!--FXLauncher运行后文件下载的位置--&gt; &lt;app.cacheDir&gt;./lib&lt;/app.cacheDir&gt; &lt;!--FXLauncher运行时候的参数，比如什么更新失败后继续打开程序之类的，有哪些看官方的Readme里面--&gt; &lt;app.parameters&gt;&lt;/app.parameters&gt; &lt;app.vendor&gt;Acme Inc&lt;/app.vendor&gt; &lt;app.version&gt;3.3&lt;/app.version&gt; &lt;!--更新文件的服务器地址，在这里可以打开下载你的更新jar包就行，tomcat和apache都行--&gt; &lt;app.url&gt;http://114.115.208.62/&lt;/app.url&gt; &lt;!--编译后的位置，这个位置在Idea里面是target下面的app目录--&gt; &lt;app.dir&gt;$&#123;project.build.directory&#125;/app&lt;/app.dir&gt; &lt;!--打包exe程序后的目录位置target/install--&gt; &lt;app.installerdir&gt;$&#123;project.build.directory&#125;/installer&lt;/app.installerdir&gt; &lt;!--是否接受版本降级--&gt; &lt;app.acceptDowngrade&gt;false&lt;/app.acceptDowngrade&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; 然后是build &lt;build&gt; &lt;plugins&gt; &lt;!-- 编译执行文件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;app.dir&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 拷贝依赖jar包到编译目录 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.10&lt;/version&gt; &lt;configuration&gt; &lt;excludeScope&gt;provided&lt;/excludeScope&gt; &lt;outputDirectory&gt;$&#123;app.dir&#125;&lt;/outputDirectory&gt; &lt;stripVersion&gt;true&lt;/stripVersion&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;!-- 生成 app.xml manifest --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;create-manifest&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;mainClass&gt;fxlauncher.CreateManifest&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;$&#123;app.url&#125;&lt;/argument&gt; &lt;argument&gt;$&#123;app.mainClass&#125;&lt;/argument&gt; &lt;argument&gt;$&#123;app.dir&#125;&lt;/argument&gt; &lt;argument&gt;--cache-dir=$&#123;app.cacheDir&#125;&lt;/argument&gt; &lt;argument&gt;--accept-downgrade=$&#123;app.acceptDowngrade&#125;&lt;/argument&gt; &lt;!--这里可以放你想要更新文件打包进去的文件 比如dll，db之类的，可以事先放在app目录下--&gt; &lt;argument&gt;--include-extensions=jpg&lt;/argument&gt; &lt;argument&gt;$&#123;app.parameters&#125;&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- 把app.xml打包进fxlauncher.xml,这样就启动器就不需要依赖app.xml来启动了 --&gt; &lt;execution&gt; &lt;id&gt;embed-manifest-in-launcher&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;exec&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;executable&gt;jar&lt;/executable&gt; &lt;workingDirectory&gt;$&#123;app.dir&#125;&lt;/workingDirectory&gt; &lt;arguments&gt; &lt;argument&gt;uf&lt;/argument&gt; &lt;argument&gt;fxlauncher.jar&lt;/argument&gt; &lt;argument&gt;app.xml&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2.配置分析完了可以看看怎么用了打开控制台输入：mvn package编译完成后会在target/app下面出现我们的jar包和依赖文件全部复制到tomcat的root目录下，这个时候要能通过tomcat下载你的jar文件 &lt;app.url&gt;http:&#x2F;&#x2F; 202.202.144.134:8080&#x2F;&lt;&#x2F;app.url&gt; 如果这个url+你的jar包名字拼接出来的URL，能够在浏览器下载这个jar包，那这个时候就可以了这个时候复制出fxlauncher.jar，随便到一个文件夹，这个时候就能够自动下载依赖并且自动更新了更新的时候你只需要把新的依赖在服务器更新就行了，app启动的时候会自动更新 exe4j打包exe1.打开exe4j，选择打包方式 2.输入软件名字和打包后的exe文件放在哪里 3.选择图标，选择打包程序类型，应用名字 4.选择哪种运行方式，勾了就是64，不勾就是32 5.选择fxlauncher.jar和运行主类，fxlauncher.Laucnher 6.这里配置jre，是搜索自带的环境变量或者添加本地的jre都可以 7.然后点完成就可以了双击exe可以自动更新的exe程序出炉，上张图此软件源码地址：https://github.com/unclezs/NovelHarvester","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"JavaFX","slug":"Java/JavaFX","permalink":"https://blog.unclezs.com/categories/Java/JavaFX/"}],"tags":[{"name":"JavaFX","slug":"JavaFX","permalink":"https://blog.unclezs.com/tags/JavaFX/"},{"name":"exe4j","slug":"exe4j","permalink":"https://blog.unclezs.com/tags/exe4j/"},{"name":"打包","slug":"打包","permalink":"https://blog.unclezs.com/tags/%E6%89%93%E5%8C%85/"}]},{"title":"JavaFX实现像安卓一样的Toast","slug":"Java/javaFX/JavaFX实现像安卓一样的Toast","date":"2019-07-06T05:18:50.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/javaFX/JavaFX实现像安卓一样的Toast.html","link":"","permalink":"https://blog.unclezs.com/Java/javaFX/JavaFX%E5%AE%9E%E7%8E%B0%E5%83%8F%E5%AE%89%E5%8D%93%E4%B8%80%E6%A0%B7%E7%9A%84Toast.html","excerpt":"JAVAFX消息弹窗一个像安卓的Toast弹窗小说，定时消失 import javafx.application.Application; import javafx.application.Platform; import javafx.geometry.Pos; import javafx.scene.Scene; import javafx.scene.control.Label; import javafx.scene.paint.Color; import javafx.scene.text.Font; import javafx.stage.Stage; import javafx.stage.StageStyle; import java.util.Timer; import java.util.TimerTask; /* *@author unclezs.com *@date 2019.07.06 12:46 */ public class ToastUtil &#123; private static Stage stage=new Stage(); private static Label label=new Label(); static &#123; stage.initStyle(StageStyle.TRANSPARENT);//舞台透明 &#125; //默认3秒 public static void toast(String msg) &#123; toast(msg,3000); &#125; /** * 指定时间消失 * @param msg * @param time */ public static void toast(String msg, int time) &#123; label.setText(msg); TimerTask task= new TimerTask() &#123; @Override public void run() &#123; Platform.runLater(()-&gt;stage.close()); &#125; &#125;; init(msg); Timer timer=new Timer(); timer.schedule(task,time); stage.show(); &#125; //设置消息 private static void init(String msg) &#123; Label label=new Label(msg);//默认信息 label.setStyle(&quot;-fx-background: rgba(56,56,56,0.7);-fx-border-radius: 25;-fx-background-radius: 25&quot;);//label透明,圆角 label.setTextFill(Color.rgb(225,255,226));//消息字体颜色 label.setPrefHeight(50); label.setPadding(new Insets(15)); label.setAlignment(Pos.CENTER);//居中 label.setFont(new Font(20));//字体大小 Scene scene=new Scene(label); scene.setFill(null);//场景透明 stage.setScene(scene); &#125; &#125; 效果图","text":"JAVAFX消息弹窗一个像安卓的Toast弹窗小说，定时消失 import javafx.application.Application; import javafx.application.Platform; import javafx.geometry.Pos; import javafx.scene.Scene; import javafx.scene.control.Label; import javafx.scene.paint.Color; import javafx.scene.text.Font; import javafx.stage.Stage; import javafx.stage.StageStyle; import java.util.Timer; import java.util.TimerTask; /* *@author unclezs.com *@date 2019.07.06 12:46 */ public class ToastUtil &#123; private static Stage stage=new Stage(); private static Label label=new Label(); static &#123; stage.initStyle(StageStyle.TRANSPARENT);//舞台透明 &#125; //默认3秒 public static void toast(String msg) &#123; toast(msg,3000); &#125; /** * 指定时间消失 * @param msg * @param time */ public static void toast(String msg, int time) &#123; label.setText(msg); TimerTask task= new TimerTask() &#123; @Override public void run() &#123; Platform.runLater(()-&gt;stage.close()); &#125; &#125;; init(msg); Timer timer=new Timer(); timer.schedule(task,time); stage.show(); &#125; //设置消息 private static void init(String msg) &#123; Label label=new Label(msg);//默认信息 label.setStyle(&quot;-fx-background: rgba(56,56,56,0.7);-fx-border-radius: 25;-fx-background-radius: 25&quot;);//label透明,圆角 label.setTextFill(Color.rgb(225,255,226));//消息字体颜色 label.setPrefHeight(50); label.setPadding(new Insets(15)); label.setAlignment(Pos.CENTER);//居中 label.setFont(new Font(20));//字体大小 Scene scene=new Scene(label); scene.setFill(null);//场景透明 stage.setScene(scene); &#125; &#125; 效果图","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"JavaFX","slug":"Java/JavaFX","permalink":"https://blog.unclezs.com/categories/Java/JavaFX/"}],"tags":[{"name":"JavaFX","slug":"JavaFX","permalink":"https://blog.unclezs.com/tags/JavaFX/"},{"name":"弹窗","slug":"弹窗","permalink":"https://blog.unclezs.com/tags/%E5%BC%B9%E7%AA%97/"}]},{"title":"jdk源码分析-TreeMap红黑树插入删除过程","slug":"Java/基础/jdk源码分析-TreeMap红黑树插入删除过程","date":"2019-06-17T02:13:05.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/jdk源码分析-TreeMap红黑树插入删除过程.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/jdk%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-TreeMap%E7%BA%A2%E9%BB%91%E6%A0%91%E6%8F%92%E5%85%A5%E5%88%A0%E9%99%A4%E8%BF%87%E7%A8%8B.html","excerpt":"一、红-黑树的性质1.简述jdk中的TreeMap是由红黑树实现的，所以本文记录下我分析的红黑树红黑树实际是实现二叉排序树的实现自平衡的算法之一，所以可以叫红黑树为高级二叉查找树。如果不了解排序树请先学习排序树 2.性质1.每个节点不是红色就是黑色的；2.根节点总是黑色的；3.如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；4.从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 二、平衡化的旋转为了达到树的平衡我们需要对其进行旋转，下面说的是左右旋的基本概念 1.左旋以5为节点进行左旋转以E为节点进行左旋转示意图 2.右旋","text":"一、红-黑树的性质1.简述jdk中的TreeMap是由红黑树实现的，所以本文记录下我分析的红黑树红黑树实际是实现二叉排序树的实现自平衡的算法之一，所以可以叫红黑树为高级二叉查找树。如果不了解排序树请先学习排序树 2.性质1.每个节点不是红色就是黑色的；2.根节点总是黑色的；3.如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；4.从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 二、平衡化的旋转为了达到树的平衡我们需要对其进行旋转，下面说的是左右旋的基本概念 1.左旋以5为节点进行左旋转以E为节点进行左旋转示意图 2.右旋以20为节点进行右旋转 以s为节点，右旋转示意图 三、插入过程插入的时候为保证红黑树性质不被改变，插入后应该对其旋转操作，需要修复红黑树结构的情况为父节点为红色的时候 1.情况分析我按照两种情况来分析需要旋转的情况新插入的节点默认都为红色 1.1.父亲在左边1.1.1 .叔叔为红色这里不需要旋转，只需要换色即可，（父亲,叔叔）&lt;—&gt;（祖父），再将祖父当作根节点判断是否满足红黑树结构再进行操作 1.1.2 叔叔为黑色、我在左这里只需要进行以父为节点右旋转，然后父亲-&gt;黑色，祖父-&gt;红色 1.1.3 叔叔为黑色、我在右边这里要先对父节点做一次左旋，再以祖为节点右旋转 1.2.父亲在右边1.2.1 叔叔为红色和1.1.1一样1.2.2 叔叔为黑色，我在左这里需要以父为节点进行一次左旋，再以祖父为节点进行左旋转即可1.2.1 叔叔为黑色，我在右这里只需要以祖为节点左旋一次即可达到平衡 2.源码分析回到java源码中对TreeMap中插入时修复红黑树的方法为fixAfterInsertion源码： private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; me.color=RED; //x为根节点时候不需要操作，x父亲为黑色时为正确红黑树，不需要修复 while (me!=null&amp;&amp;me!=root&amp;&amp;me.parent.color==RED)&#123; //分两大种情况处理，父亲在左边或者右边时 if(parentOf(me)==leftOf(parentOf(parentOf(me))))&#123;//父亲在左边的时候 Node&lt;E&gt; uncle = rightOf(parentOf(parentOf(me)));//获取叔叔(在右) if(colorOf(uncle)==BLACK)&#123;//叔叔为黑色 //此时父左，叔右，若我为左则以祖父为根R旋转，若我在右边则以我为根进行LR转 if(rightOf(parentOf(me))==me)&#123;//我在右边 me=parentOf(me); leftRotate(me); &#125; setColor(parentOf(me),BLACK); setColor(parentOf(parentOf(me)),RED); rightRotate(parentOf(parentOf(me))); &#125;else &#123;//叔叔为红色,交换颜色（父亲,叔叔）&lt;-&gt;（祖父），再将祖父接着前操作 setColor(parentOf(uncle),RED);//祖父红色 setColor(parentOf(me),BLACK);//父亲黑色 setColor(uncle,BLACK);//叔叔黑色 me=parentOf(uncle);//祖父为节点接着修复 &#125; &#125; else &#123;//父亲在右边的时候 Node&lt;E&gt; uncle = leftOf(parentOf(parentOf(me)));//获取叔叔(在左) if(colorOf(uncle)==BLACK)&#123;//叔叔为黑色 //此时父右，叔左，若我为左则以我为根RL旋转，若我在右边则以祖父为根进行L转 if(leftOf(parentOf(me))==me)&#123;//我在左边 me=parentOf(me); rightRotate(me); &#125; setColor(parentOf(me),BLACK); setColor(parentOf(parentOf(me)),RED); leftRotate(parentOf(parentOf(me))); &#125;else &#123;//叔叔为红色,交换颜色（父亲,叔叔）&lt;-&gt;（祖父），再将祖父接着前操作 setColor(parentOf(uncle),RED);//祖父红色 setColor(parentOf(me),BLACK);//父亲黑色 setColor(uncle,BLACK);//叔叔黑色 me=parentOf(uncle);//祖父为节点接着修复 &#125; &#125; &#125; root.color=BLACK; &#125; 删除过程Todo","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"源码分析","slug":"源码分析","permalink":"https://blog.unclezs.com/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"红黑树","slug":"红黑树","permalink":"https://blog.unclezs.com/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"TreeMap","slug":"TreeMap","permalink":"https://blog.unclezs.com/tags/TreeMap/"}]},{"title":"Spring给util类注入bean","slug":"Java/Spring/spring给util类注入bean","date":"2019-05-26T13:17:37.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/Spring/spring给util类注入bean.html","link":"","permalink":"https://blog.unclezs.com/Java/Spring/spring%E7%BB%99util%E7%B1%BB%E6%B3%A8%E5%85%A5bean.html","excerpt":"问题在用SSM写东西的时候遇到的，spring因为不能够给静态对象自动注入，所以加上@Autowired注解也无用 @Component public class JedisUtil &#123; @Autowired private static JedisPool pool; 这样是注入不进来pool的 解决1.先检查注解扫描是否正确spring-context.xml 和spring-mvc.xml &lt;context:component-scan base-package=&quot;com.unclezs&quot;/&gt; 2.检查web.xml加载顺序，先加载spring-context.xml才行3.修改工具类 @Component public class JedisUtil &#123; @Autowired private JedisPool pool; private static JedisUtil jedisUtil; @PostConstruct public void init()&#123; jedisUtil=this; jedisUtil.pool= this.pool; &#125; &#125; 问题这样就完美解决了","text":"问题在用SSM写东西的时候遇到的，spring因为不能够给静态对象自动注入，所以加上@Autowired注解也无用 @Component public class JedisUtil &#123; @Autowired private static JedisPool pool; 这样是注入不进来pool的 解决1.先检查注解扫描是否正确spring-context.xml 和spring-mvc.xml &lt;context:component-scan base-package=&quot;com.unclezs&quot;/&gt; 2.检查web.xml加载顺序，先加载spring-context.xml才行3.修改工具类 @Component public class JedisUtil &#123; @Autowired private JedisPool pool; private static JedisUtil jedisUtil; @PostConstruct public void init()&#123; jedisUtil=this; jedisUtil.pool= this.pool; &#125; &#125; 问题这样就完美解决了","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.unclezs.com/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"}]},{"title":"Docker入门初体验","slug":"容器化/Docker入门初体验","date":"2019-04-15T14:34:51.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"容器化/Docker入门初体验.html","link":"","permalink":"https://blog.unclezs.com/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker%E5%85%A5%E9%97%A8%E5%88%9D%E4%BD%93%E9%AA%8C.html","excerpt":"一、简介Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 二、安装如需安装 Docker CE，您需要 64 位版本的 CentOS 7 卸载旧版本Docker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。 $ sudo yum remove docker \\ docker-common \\ docker-selinux \\ docker-engine 更新yum到最新 sudo yum update 安装依赖 yum install -y yum-utils device-mapper-persistent-data lvm2","text":"一、简介Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 二、安装如需安装 Docker CE，您需要 64 位版本的 CentOS 7 卸载旧版本Docker 的早期版本称为 docker 或 docker-engine。如果安装了这些版本，请卸载它们及关联的依赖资源。 $ sudo yum remove docker \\ docker-common \\ docker-selinux \\ docker-engine 更新yum到最新 sudo yum update 安装依赖 yum install -y yum-utils device-mapper-persistent-data lvm2 设置镜像 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新 yum 软件包索引。 sudo yum makecache fast 安装最新版本的 Docker CE，或者转至下一步以安装特定版本。 sudo yum install docker-ce 查看版本、信息 docker -v docker info 启动、停止、重启，开启自启docker systemctl start/stop/restart/enable docker 三、常用指令1.镜像相关1.1查看镜像docker images 1.2.删除镜像docker rmi 镜像名字或者id docker rmi `docker images -q` //删除所有 1.3.搜搜镜像docker search 镜像名字 1.4.拉取镜像docker pull 镜像名字 2.容器相关2.1.查看容器 查看所有，运行+没运行的 docker ps //正在运行的容器 docker ps -a //全部容器 docker ps -l //最后一次运行的容器 docker ps -f status=exited //查看停止的容器 2.2.创建容器 参数 作用 -i 表示运行容器 -t 表示启动后进入其命令行。加入这个参数后，肉哦容器创建就能进入一个伪终端 –name 容器名字 -v 目录映射，‘:’分割前面是宿主目录，后者是容器目录，可以多个-v创建多个映射目录 -d 守护式创建容器，即创建后不会进去命令行 -p 端口映射，‘:’分割，前者是主机端口，后者是容器端口 1.交互式方式创建容器 docker run -it --name=容器名称 镜像名称:标签 /bin/bash exit //退出容器 2.守护式方式创建容器 docker run -di --name=容器名称 镜像名称:标签 docker exec -it 容器名称(或者id) /bin/bash 3.停止启动容器 docker stop 容器名称(或者id) docker start 容器名称(或者id) 4.主机与容器文件互相拷贝 docker cp 主机目录 容器名称:容器目录 //主机到容器 docker cp 容器名称:容器目录 主机目录 //容器到主机 5.目录挂载 docker run -di -v 主机目录:容器目录 --name=容器名称 镜像名称 6.查看容器信息、ip docker inspect 容器名称（id） docker inspect --format=&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27; 容器名称（id） 7.删除容器 docker rm 容器名称（id） 四、搭建环境1.mysqldocker run -di --name=con_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123 centos/mysql-57-centos7 2.tomcatrun -di --name=tomcat7 -p 8888:8080 -v /usr/local/webapps:/usr/local/webapps tomcat:7-jre7 3.tomcatdocker run -di --name=mynginx -p 8889:80 nginx 4.redisdocker run -di --name=myredis -p 16379:6379 redis 四、保存备份4.1 容器保存为镜像docker commit 容器名字 镜像名字 4.2 镜像备份docker save -o 名字.tar 镜像名字 4.3镜像恢复docker load -i 镜像名字.tar 五、Dockerfile5.1常用指令 命令 容器 FROM image_name:tag 定义了从哪个镜像启动构建流程 MAINTAINER username 声明创作者 ENV key value 定义环境变量,可以多条 RUN cmd 核心部分，可以写多条 ADD 宿主目录文件 容器目录文件 重宿主机添加文件到容器，会自动解压 COPY 宿主目录文件 容器目录文件 重宿主机添加文件到容器,不解压 WORKDIR 容器目录 工作目录 #### 5.2 例子 FROM centos:7 MAINTAINER Uncle WORKDIR /usr RUN mkdir /usr/local ADD jdk1.8.tar.gz /usr/local ENV PATH /usr/local/jdk1.8/bin:$PATH 5.3 构建docker build -t=&#x27;镜像名称&#x27; Dockerfile所在目录","categories":[{"name":"容器化","slug":"容器化","permalink":"https://blog.unclezs.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.unclezs.com/tags/docker/"}]},{"title":"ElasticSearch-Head安装配置","slug":"问题教程/ElasticSearch-Head安装配置","date":"2019-04-11T13:34:13.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"问题教程/ElasticSearch-Head安装配置.html","link":"","permalink":"https://blog.unclezs.com/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/ElasticSearch-Head%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html","excerpt":"简介ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 安装1.elasticSearch安装在官网下载https://www.elastic.co/cn/节压后点击elasticSearch.bat即可运行，注意对应java版本访问127.0.0.1:9200看到json数据则成功 2.图形化工具安装：图形化工具https://github.com/mobz/elasticsearch-head node.js环境，下载node.js安装 1.行npm install -g grunt-cli 2.然后npm install 开启在bin目录执行grunt server； http://localhost:9100/即可访问 解决跨域问题 在elasticSearch下的config/elasticsearch.yml添加 http.cors.enabled: truehttp.cors.allow-origin: “*”重启即可","text":"简介ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 安装1.elasticSearch安装在官网下载https://www.elastic.co/cn/节压后点击elasticSearch.bat即可运行，注意对应java版本访问127.0.0.1:9200看到json数据则成功 2.图形化工具安装：图形化工具https://github.com/mobz/elasticsearch-head node.js环境，下载node.js安装 1.行npm install -g grunt-cli 2.然后npm install 开启在bin目录执行grunt server； http://localhost:9100/即可访问 解决跨域问题 在elasticSearch下的config/elasticsearch.yml添加 http.cors.enabled: truehttp.cors.allow-origin: “*”重启即可","categories":[{"name":"问题教程","slug":"问题教程","permalink":"https://blog.unclezs.com/categories/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"搜索","slug":"搜索","permalink":"https://blog.unclezs.com/tags/%E6%90%9C%E7%B4%A2/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.unclezs.com/tags/ElasticSearch/"}]},{"title":"Lucen入门使用","slug":"Java/其他/Lucen入门使用","date":"2019-04-11T12:22:31.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/其他/Lucen入门使用.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%85%B6%E4%BB%96/Lucen%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8.html","excerpt":"一、简介Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。 二、lucene实现全文检索流程1、绿色表示索引过程，对要搜索的原始内容进行索引构建一个索引库，索引过程包括：确定原始内容即要搜索的内容 =&gt; 采集文档 =&gt; 创建文档=&gt;分析文档=&gt;索引文档 2、红色表示搜索过程，从索引库中搜索内容，搜索过程包括：用户通过搜索界面=&gt;创建查询=&gt;执行搜索，从索引库搜索=&gt;渲染搜索结果 三、基本使用3.1 jar包lucene-analyzers-common.jarlucene-core.jarikAnalyzer.jarlucene-queryparser.jar 3.2 创建索引@Test public void create() throws IOException &#123; //指定索引库存放的路径 FSDirectory fsDirectory = FSDirectory.open(new File(&quot;D:\\\\java\\\\IDEA_WORKSPACE\\\\LuceneDomo\\\\index&quot;).toPath()); //使用IKAnalyzer分析器 IndexWriterConfig config=new IndexWriterConfig(new IKAnalyzer()); //创建indexwriter对象 IndexWriter writer=new IndexWriter(fsDirectory,config); //原始文档 File[] files=new File(&quot;H:\\\\searchsource&quot;).listFiles(); for (File f:files)&#123; String name = f.getName(); String path = f.getPath(); String content= FileUtils.readFileToString(f, &quot;utf-8&quot;); long size = FileUtils.sizeOf(f); //创建域 Field fName=new TextField(&quot;name&quot;,name,Field.Store.YES); Field fPath=new StoredField(&quot;path&quot;,path); Field fContent=new TextField(&quot;content&quot;,content,Field.Store.YES); Field lSize=new LongPoint(&quot;size&quot;,size); Field fSize=new StoredField(&quot;size&quot;,size); //存入域 Document doc=new Document(); doc.add(fName); doc.add(fContent); doc.add(fPath); doc.add(fSize); doc.add(lSize); writer.addDocument(doc); &#125; writer.close(); &#125;","text":"一、简介Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。 二、lucene实现全文检索流程1、绿色表示索引过程，对要搜索的原始内容进行索引构建一个索引库，索引过程包括：确定原始内容即要搜索的内容 =&gt; 采集文档 =&gt; 创建文档=&gt;分析文档=&gt;索引文档 2、红色表示搜索过程，从索引库中搜索内容，搜索过程包括：用户通过搜索界面=&gt;创建查询=&gt;执行搜索，从索引库搜索=&gt;渲染搜索结果 三、基本使用3.1 jar包lucene-analyzers-common.jarlucene-core.jarikAnalyzer.jarlucene-queryparser.jar 3.2 创建索引@Test public void create() throws IOException &#123; //指定索引库存放的路径 FSDirectory fsDirectory = FSDirectory.open(new File(&quot;D:\\\\java\\\\IDEA_WORKSPACE\\\\LuceneDomo\\\\index&quot;).toPath()); //使用IKAnalyzer分析器 IndexWriterConfig config=new IndexWriterConfig(new IKAnalyzer()); //创建indexwriter对象 IndexWriter writer=new IndexWriter(fsDirectory,config); //原始文档 File[] files=new File(&quot;H:\\\\searchsource&quot;).listFiles(); for (File f:files)&#123; String name = f.getName(); String path = f.getPath(); String content= FileUtils.readFileToString(f, &quot;utf-8&quot;); long size = FileUtils.sizeOf(f); //创建域 Field fName=new TextField(&quot;name&quot;,name,Field.Store.YES); Field fPath=new StoredField(&quot;path&quot;,path); Field fContent=new TextField(&quot;content&quot;,content,Field.Store.YES); Field lSize=new LongPoint(&quot;size&quot;,size); Field fSize=new StoredField(&quot;size&quot;,size); //存入域 Document doc=new Document(); doc.add(fName); doc.add(fContent); doc.add(fPath); doc.add(fSize); doc.add(lSize); writer.addDocument(doc); &#125; writer.close(); &#125; 3.3 检索@Test public void search() throws IOException &#123; //指定索引库存放的路径 FSDirectory fsDirectory = FSDirectory.open(new File(&quot;D:\\\\java\\\\IDEA_WORKSPACE\\\\LuceneDomo\\\\index&quot;).toPath()); IndexReader reader= DirectoryReader.open(fsDirectory); IndexSearcher searcher=new IndexSearcher(reader); Query query=new TermQuery(new Term(&quot;content&quot;,&quot;spring&quot;)); TopDocs docs = searcher.search(query, 10); System.out.println(&quot;共记录：&quot;+docs.totalHits); for (ScoreDoc doc:docs.scoreDocs)&#123; int id=doc.doc; Document document = searcher.doc(id); System.out.println(document.get(&quot;name&quot;)); System.out.println(document.get(&quot;path&quot;)); &#125; reader.close(); &#125; 四、分析器4.1. IkAnalyzer中文分析器（第三方）对中文支持比好，扩展性也好 @Test public void analyzer() throws IOException &#123; Analyzer analyzer=new IKAnalyzer(); TokenStream tokenStream = analyzer.tokenStream(&quot;name&quot;, &quot;们都是一些公开给别人尝试破解的小程序，制作 Crackme 的人可能是程序员，想测试一下自己的软件保护技术 &quot;); CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class); tokenStream.reset(); while (tokenStream.incrementToken())&#123; System.out.println(charTermAttribute.toString()); &#125; tokenStream.close(); &#125; 4.2 StandardAnalyzer（自带）对英文支持比较好，对中文分析不行，就是按照中文一个字一个字地进行分词。如：“我爱中国”，效果：“我”、“爱”、“中”、“国”。 4.3 SmartChineseAnalyzer（自带）对中文支持较好，但扩展性差，扩展词库，禁用词库和同义词库等不好处理 五、索引库的维护 Field类 数据类型 Analyzed是否分析 Indexed是否索引 Stored是否存储 说明 StringField(FieldName, FieldValue,Store.YES)) 字符串 N Y Y或N 这个Field用来构建一个字符串Field，但是不会进行分析，会将整个串存储在索引中，比如(订单号,姓名等)是否存储在文档中用Store.YES或Store.NO决定 LongPoint(String name, long… point) Long型 Y Y N 可以使用LongPoint、IntPoint等类型存储数值类型的数据。让数值类型可以进行索引。但是不能存储数据，如果想存储数据还需要使用StoredField。 StoredField(FieldName, FieldValue) 重载方法，支持多种类型 N N Y 这个Field用来构建不同类型Field不分析，不索引，但要Field存储在文档中 TextField(FieldName, FieldValue, Store.NO)或TextField(FieldName, reader) 字符串或流 Y Y Y或N 如果是一个Reader, lucene猜测内容比较多,会采用Unstored的策略. 5.1 添加文档@Test public void addDocument() throws Exception &#123; //索引库存放路径 Directory directory = FSDirectory.open(new File(&quot;C://index&quot;).toPath()); IndexWriterConfig config = new IndexWriterConfig(new IKAnalyzer()); //创建一个indexwriter对象 IndexWriter indexWriter = new IndexWriter(directory, config); //创建一个Document对象 Document document = new Document(); //向document对象中添加域。 //不同的document可以有不同的域，同一个document可以有相同的域。 document.add(new TextField(&quot;filename&quot;, &quot;新添加的文档&quot;, Field.Store.YES)); document.add(new TextField(&quot;content&quot;, &quot;新添加的文档的内容&quot;, Field.Store.NO)); //LongPoint创建索引 document.add(new LongPoint(&quot;size&quot;, 1000l)); //StoreField存储数据 document.add(new StoredField(&quot;size&quot;, 1000l)); //不需要创建索引的就使用StoreField存储 document.add(new StoredField(&quot;path&quot;, &quot;d:/temp/1.txt&quot;)); //添加文档到索引库 indexWriter.addDocument(document); //关闭indexwriter indexWriter.close(); &#125; 5.2 索引库删除说明：将索引目录的索引信息全部删除，直接彻底删除，无法恢复 @Test public void deleteAllIndex() throws Exception &#123; //getIndexWriter重复代码省略为方法 IndexWriter indexWriter = getIndexWriter(); //删除全部索引 indexWriter.deleteAll(); //关闭indexwriter indexWriter.close(); 5.3 指定查询条件删除@Test public void deleteIndexByQuery() throws Exception &#123; IndexWriter indexWriter = getIndexWriter(); //创建一个查询条件 Query query = new TermQuery(new Term(&quot;filename&quot;, &quot;apache&quot;)); //根据查询条件删除 indexWriter.deleteDocuments(query); //关闭indexwriter indexWriter.close(); &#125; 5.4 7.3 索引库的修改原理就是先删除后添加。 //修改索引库 @Test public void updateIndex() throws Exception &#123; IndexWriter indexWriter = getIndexWriter(); //创建一个Document对象 Document document = new Document(); //向document对象中添加域。 //不同的document可以有不同的域，同一个document可以有相同的域。 document.add(new TextField(&quot;filename&quot;, &quot;要更新的文档&quot;, Field.Store.YES)); document.add(new TextField(&quot;content&quot;, &quot; Lucene 简介 Lucene 是一个基于 Java 的全文信息检索&quot;, Field.Store.YES)); indexWriter.updateDocument(new Term(&quot;content&quot;, &quot;java&quot;), document); //关闭indexWriter indexWriter.close(); &#125; 六、Lucene索引库查询对要搜索的信息创建Query查询对象，Lucene会根据Query查询对象生成最终的查询语法，类似关系数据库Sql语法一样Lucene也有自己的查询语法，比如：“name:lucene”表示查询Field的name为“lucene”的文档信息。 可通过两种方法创建查询对象： 1）使用Lucene提供Query子类 2）使用QueryParse解析查询表达式 6.1 TermQueryTermQuery，通过项查询，TermQuery不使用分析器所以建议匹配不分词的Field域查询，比如订单号、分类ID号等。指定要查询的域和要查询的关键词。上面入门例子即是 6.2 数值范围查询size为LongPoint类型 @Test public void testRangeQuery() throws Exception &#123; IndexSearcher indexSearcher = getIndexSearcher(); Query query = LongPoint.newRangeQuery(&quot;size&quot;, 0L, 10000L); printResult(query, indexSearcher); &#125; 6.3 使用queryparser查询@Test public void testQueryParser() throws Exception &#123; //指定索引库存放的路径 FSDirectory fsDirectory = FSDirectory.open(new File(&quot;D:\\\\java\\\\IDEA_WORKSPACE\\\\LuceneDomo\\\\index&quot;).toPath()); //指定索引库存放的路径 IndexReader reader= DirectoryReader.open(fsDirectory); IndexSearcher searcher=new IndexSearcher(reader); QueryParser queryParser=new QueryParser(&quot;content&quot;,new IKAnalyzer()); Query query = queryParser.parse(&quot;Lucene是java开发的&quot;); printResult(query,searcher); &#125; private void printResult(Query query, IndexSearcher indexSearcher) throws Exception &#123; //执行查询 TopDocs topDocs = indexSearcher.search(query, 10); //共查询到的document个数 System.out.println(&quot;查询结果总数量：&quot; + topDocs.totalHits); //遍历查询结果 for (ScoreDoc scoreDoc : topDocs.scoreDocs) &#123; Document document = indexSearcher.doc(scoreDoc.doc); System.out.println(document.get(&quot;name&quot;)); //System.out.println(document.get(&quot;content&quot;)); System.out.println(document.get(&quot;path&quot;)); System.out.println(document.get(&quot;size&quot;)); &#125; //关闭indexreader indexSearcher.getIndexReader().close(); &#125; 最后贴下pom.xml方便使用 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;8.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;8.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--自己安装得--&gt; &lt;dependency&gt; &lt;groupId&gt;com.lucene&lt;/groupId&gt; &lt;artifactId&gt;ikAnalyzer&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;8.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"其他","slug":"Java/其他","permalink":"https://blog.unclezs.com/categories/Java/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"Lucen","slug":"Lucen","permalink":"https://blog.unclezs.com/tags/Lucen/"}]},{"title":"PageHelper入门初体验","slug":"Java/工具/PageHelper入门初体验","date":"2019-04-09T09:47:52.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/工具/PageHelper入门初体验.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%B7%A5%E5%85%B7/PageHelper%E5%85%A5%E9%97%A8%E5%88%9D%E4%BD%93%E9%AA%8C.html","excerpt":"一、简介PageHelper是国内非常优秀的一款开源的mybatis分页插件，它支持基本主流与常用的数据库，例如mysql、oracle、mariaDB、DB2、SQLite、Hsqldb等。 github 的项目地址：https://github.com/pagehelper/Mybatis-PageHelpergitosc 的项目地址：http://git.oschina.net/free/Mybatis_PageHelper 二、简单使用2.1 准备2.2.1 导入jar包方式PageHelper最新下载地址由于使用了sql 解析工具，你还需要下载jsqlparser.jar 2.2.2 Maven依赖坐标 &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt;","text":"一、简介PageHelper是国内非常优秀的一款开源的mybatis分页插件，它支持基本主流与常用的数据库，例如mysql、oracle、mariaDB、DB2、SQLite、Hsqldb等。 github 的项目地址：https://github.com/pagehelper/Mybatis-PageHelpergitosc 的项目地址：http://git.oschina.net/free/Mybatis_PageHelper 二、简单使用2.1 准备2.2.1 导入jar包方式PageHelper最新下载地址由于使用了sql 解析工具，你还需要下载jsqlparser.jar 2.2.2 Maven依赖坐标 &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; 2.2 配置特别注意，新版拦截器是 com.github.pagehelper.PageInterceptor。com.github.pagehelper.PageHelper 现在是一个特殊的 dialect 实现类，是分页插件的默认实现类，提供了和以前相同的用法。 2.2.1 Mybatis的xml配置中配置&lt;plugins&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;property name=&quot;param1&quot; value=&quot;value1&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 2.2.2. 在 Spring 配置文件中配置拦截器插件&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 配置pageHelper --&gt; &lt;property name=&quot;plugins&quot;&gt; &lt;array&gt; &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;helperDialect&quot;&gt;oracle&lt;/prop&gt; &lt;prop key=&quot;reasonable&quot;&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 2.3 参数介绍 helperDialect ：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect 属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值： oracle , mysql , mariadb , sqlite , hsqldb , postgresql , db2 , sqlserver , informix , h2 , sqlserver2012 , derby特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012 ，否则会使用 SqlServer2005 的方式进行分页。也可以实现 AbstractHelperDialect ，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 offsetAsPageNum ：默认值为 false ，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。 rowBoundsWithCount ：默认值为 false ，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero ：默认值为 false ，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable ：分页合理化参数，默认值为 false 。当该参数设置为 true 时， pageNum&lt;=0 时会查询第一页， pageNum&gt;pages （超过总数时），会查询最后一页。默认 false 时，直接根据参数进行查询。 params ：为了支持 startPage(Object params) 方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable ，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments ：支持通过 Mapper 接口参数来传递分页参数，默认值 false ，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest 。 autoRuntimeDialect ：默认值为 false 。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择 sqlserver2012 ，只能使用 sqlserver ），用法和注意事项参考下面的场景五。 closeConn ：默认值为 true 。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认 true 关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 2.4 两种常用使用方式PageHelper的基本使用有6种，大家可以查看文档，最常用的有两种 2.4.1. RowBounds方式的调用（了解）List&lt;Country&gt; list = sqlSession.selectList(&quot;x.y.selectIf&quot;, null, new RowBounds(1, 10)); 使用这种调用方式时，你可以使用RowBounds参数进行分页，这种方式侵入性最小，我们可以看到，通过RowBounds方式调用只是使用了这个参数，并没有增加其他任何内容。 分页插件检测到使用了RowBounds参数时，就会对该查询进行物理分页。 关于这种方式的调用，有两个特殊的参数是针对 RowBounds 的，你可以参看上面的分页插件参数介绍 注：不只有命名空间方式可以用RowBounds，使用接口的时候也可以增加RowBounds参数，例如： //这种情况下也会进行物理分页查询 List&lt;Country&gt; selectAll(RowBounds rowBounds); 注意： 由于默认情况下的 RowBounds 无法获取查询总数，分页插件提供了一个继承自 RowBounds 的PageRowBounds ，这个对象中增加了 total 属性，执行分页查询后，可以从该属性得到查询总数。 2.4.2. PageHelper.startPage 静态方法调用（重点）这种方式是我们要掌握的 在你需要进行分页的 MyBatis 查询方法前调用PageHelper.startPage 静态方法即可，紧跟在这个方法后的第一个MyBatis 查询方法会被进行分页。 PageHelper.startPage(page,pagesize); dao.findAll(pagesize,page); 三、例子主要使用的参数都在PageInfo中 @Service public class OrderServiceImpl implements IOrderService &#123; @Autowired OrderDao dao; @Override public List&lt;Orders&gt; findAll(Integer pagesize, Integer page) throws Exception &#123; PageHelper.startPage(page,pagesize); return dao.findAll(pagesize,page); &#125; &#125; @Controller @RequestMapping(&quot;/orders&quot;) public class OrderController &#123; @Autowired IOrderService service; @RequestMapping(&quot;/findAll.do&quot;) public ModelAndView findAll(@RequestParam(name=&quot;page&quot;,required = true,defaultValue =&quot;1&quot;) Integer page, @RequestParam(name=&quot;pageSize&quot;,required = true,defaultValue =&quot;10&quot;) Integer pageSize) throws Exception &#123; ModelAndView mv=new ModelAndView(); List&lt;Orders&gt; ordersList = service.findAll(pageSize, page); PageInfo pageInfo=new PageInfo(ordersList,3); mv.addObject(&quot;pageInfo&quot;,pageInfo); mv.setViewName(&quot;orders-list&quot;); return mv; &#125; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://blog.unclezs.com/categories/Java/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"PageHelper","slug":"PageHelper","permalink":"https://blog.unclezs.com/tags/PageHelper/"}]},{"title":"plsql简单入门","slug":"数据库/oracle/plsql简单入门","date":"2019-04-06T13:53:41.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/oracle/plsql简单入门.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/oracle/plsql%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8.html","excerpt":"一、PL/SQL简介PL/SQL（Procedural Language/SQL）是甲骨文公司专有的SQL扩展语言，应用在甲骨文公司的Oracle数据库系统。一些的SQL数据库管理系统也提供了类似的扩展SQL语言。PL/SQL的的语法非常类似于Ada，而且像1980年代的Ada编译器一样，PL/SQL的运作系统使用Diana作为中介语言。 二、基本语法测试表 2.1基本语法骨架declare 声明区 begin 核心代码 end; 2.1.1 输出hello worlddeclare s varchar2(11) :=&#x27;hello world&#x27;; begin dbms_output.put_line(s); end; 2.1.2声明变量、赋值1.声明格式： 变量名 数据类型及长度","text":"一、PL/SQL简介PL/SQL（Procedural Language/SQL）是甲骨文公司专有的SQL扩展语言，应用在甲骨文公司的Oracle数据库系统。一些的SQL数据库管理系统也提供了类似的扩展SQL语言。PL/SQL的的语法非常类似于Ada，而且像1980年代的Ada编译器一样，PL/SQL的运作系统使用Diana作为中介语言。 二、基本语法测试表 2.1基本语法骨架declare 声明区 begin 核心代码 end; 2.1.1 输出hello worlddeclare s varchar2(11) :=&#x27;hello world&#x27;; begin dbms_output.put_line(s); end; 2.1.2声明变量、赋值1.声明格式： 变量名 数据类型及长度 i number(10) := 10; name varchar2(10) :=abc; --根据emp表中的ename的数据类型来声明 name2 emp.ename%type; 2.sql赋值||符号是字符连接符号 declare name emp.ename%type; msal emp.sal%type; begin select ename,sal into name,msal from emp where empno=7369; dbms_output.put_line(name || &#x27;--&#x27; || msal); end; 2.2流程控制&amp;inNum 读入一个数,名字随意 2.2.1 if判断读入一个数，根据数值判断哪个年代 declare i number(2) :=&amp;inNum; begin if i&lt;18 then dbms_output.put_line(&#x27;未成年&#x27;); elsif i&lt;40 then dbms_output.put_line(&#x27;不惑之年&#x27;); else dbms_output.put_line(&#x27;老了老了&#x27;); end if; end; 2.2.2 while循环打印1到10 declare i number(2) :=1; begin while i&lt;11 loop dbms_output.put_line(i); i := i+1; end loop; end; 2.2.3 exit 循环打印1到10 declare i number(2) :=1; begin loop exit when i&gt;10; dbms_output.put_line(i); i := i+1; end loop; end; 2.2.3 for 循环打印1到10 declare begin for i in 1..10 loop dbms_output.put_line(i); end loop; end; 2.3 游标可以记录多个对象，多行记录 declare --无参游标 cursor c1 is select * from emp; empRow emp%rowtype; --一行数据类型 --带参游标 cursor c2(dno emp.deptno%type) is select empno from emp where deptno=dno; eno emp.empno%type; begin --无参遍历 open c1; loop fetch c1 into empRow; exit when c1%notfound; dbms_output.put_line(empRow.ename||&#x27;--&#x27;||empRow.sal); end loop; close c1; --带参遍历 open c2(10); loop fetch c2 into eno; exit when c2%notfound; dbms_output.put_line(eno); end loop; close c2; end; 三、存储过程、函数3.1存储过程存储过程的就是提前编译好的一段pl/sql语言，放置在数据库中，可以直接被调用，这一段pl/sql一般都是固定步骤的业务注意：参数和返回值的数据类型不能带长度 3.1.1 创建语法create [or replace] procedure 过程名字（参数 in/out 数据类型） as/is begin 程序体 end; 3.1.2 例子create or replace procedure findNameById(eno in emp.empno%type,sname out emp.ename%type) is begin select ename into sname from emp where empno=eno; end; --调用 declare sname emp.ename%type; begin findNameById(7782,sname); dbms_output.put_line(sname); end; 3.2存储函数3.2.1创建语法create [or replace] function 函数名字（参数 数据类型） return 数据类型 as/is begin 程序体 end; 3.2.2 例子create or replace function findNameByEid(eno emp.empno%type) return emp.ename%type is sname emp.ename%type; begin select ename into sname from emp where empno=eno; return sname; end; --调用 declare begin dbms_output.put_line(findNameByEid(7782)); end; 四、触发器数据库触发器是一个与表相关联的、存储的 PL/SQL 程序。每当一个特定的数据操作语句(Insert,update,delete)在指定的表上发出时，Oracle自动地执行触发器中定义的语句序列。 4.1 作用及器类型4.1.1 触发器可用于 数据确认 实施复杂的安全性检查 做审计，跟踪表上所做的数据操作等 数据的备份和同步 4.1.2 触发器的类型 :语句级触发器 ：在指定的操作语句操作之前或之后执行一次，不管这条语句影响了多少行 。行级触发器(FOR EACH ROW)：触发语句作用的每一条记录都被触发。在行级触 发器中使用old和new伪记录变量, 识别值的状态。 在触发器中触发语句与伪记录变量的值 4.2基本语法CREATE [or REPLACE] TRIGGER 触发器名 {BEFORE | AFTER} {DELETE | INSERT | UPDATE [OF 列名]} ON 表名 [FOR EACH ROW [WHEN(条件) ] ]declarebegin PLSQL 块End； 4.3 例子实现主键自增长,user_k是自定义的序列，每次执行insert语句都会自动增长id了 create or replace trigger myAutoAdd before insert on c##user for each row declare begin select user_k.nextval into :new.id from dual; end;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://blog.unclezs.com/tags/Oracle/"},{"name":"PLSQL","slug":"PLSQL","permalink":"https://blog.unclezs.com/tags/PLSQL/"}]},{"title":"oracle的查询、视图、索引","slug":"数据库/oracle/oracle的查询、视图、索引","date":"2019-04-06T12:55:20.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/oracle/oracle的查询、视图、索引.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/oracle/oracle%E7%9A%84%E6%9F%A5%E8%AF%A2%E3%80%81%E8%A7%86%E5%9B%BE%E3%80%81%E7%B4%A2%E5%BC%95.html","excerpt":"所有表来自oracle的scott用户的默认表 一、查询1.1分组查询查询平均工资大于2000的部门t.deptno 部门t.sal 工资 select t.deptno ,avg(t.sal) from emp t group by t.deptno having avg(t.sal)&gt;2000; 1.2多表查询1.2.1 内连接select * from emp e,dept d where e.deptno=d.deptno; select * from emp e inner join dept d on e.deptno=d.deptno; 1.2.2 外连接--左外连接 select * from emp e left join dept d on e.deptno=d.deptno; select * from emp e, dept d where e.deptno(+)=d.deptno; --右外连接 select * from emp e right join dept d on e.deptno=d.deptno; select * from emp e, dept d where e.deptno=d.deptno(+);","text":"所有表来自oracle的scott用户的默认表 一、查询1.1分组查询查询平均工资大于2000的部门t.deptno 部门t.sal 工资 select t.deptno ,avg(t.sal) from emp t group by t.deptno having avg(t.sal)&gt;2000; 1.2多表查询1.2.1 内连接select * from emp e,dept d where e.deptno=d.deptno; select * from emp e inner join dept d on e.deptno=d.deptno; 1.2.2 外连接--左外连接 select * from emp e left join dept d on e.deptno=d.deptno; select * from emp e, dept d where e.deptno(+)=d.deptno; --右外连接 select * from emp e right join dept d on e.deptno=d.deptno; select * from emp e, dept d where e.deptno=d.deptno(+); 1.2.3 自连接select e1.ename as 员工,e2.ename as 上级 from emp e1,emp e2 where e1.mgr=e2.empno; 1.2.4子查询1.如果返回一个值则使用where ？=(sql)2.返回一个列表则使用 where ? in (sql)3.返回一张表 -- 查询部分最低工资，最低工资员工姓名，所在部门名字 select t.msal,e.ename,d.dname from (select deptno,min(sal) msal from emp group by deptno) t,emp e,dept d where t.msal=e.sal and t.deptno=d.deptno; 1.2.5分页查询oracle的分页查询依靠rownum,select每查询一条记录就会加个rownum,rownum初始为1，依次递增，不能跳着走；当查询时加入order by的时候就可能导致rownum错乱比如: select rownum,e.* from emp e order by sal desc; 结果集：select 先执行完了再排序的，所以，rownum乱了 分页查询模板： select * from (select rownum rn,e1.* from (select e.* from emp e order by sal desc) e1 where rownum &lt;10) where rn&gt;5; 二、视图2.1创建视图create view v_emp as select ename,sal from emp; --只读视图 create view v_emp as select ename,sal from emp with read only; 2.2查询视图select * from v_emp; 2.3修改视图内容修改后对应表的值也会变 update v_emp set sal=1000.00 where ename=&#x27;SMITH&#x27; 三、索引索引就是在表的列上构建一个二叉树，达到大幅度提高查询效率的目的，但是索引影响增删改的效率 3.1单列索引3.1.1创建单列索引create index index_ename on emp(ename); 3.1.2触发单列索引触发规则是，查询条件必须是索引中的原始值,比如模糊查询和单行函数都会影响索引触发；而且在or语句中，如果不包含触发原始值的条件则不触发索引； select * from emp where ename=&#x27;SCOTT&#x27;; ---触发 表中有ename=SCOTT select * from emp where ename=&#x27;abc&#x27;; ---不触发 表中无ename=abc select * from emp where ename=&#x27;SCOTT&#x27; or sal=1000; ---不触发 3.2多列索引3.2.1创建多列索引create index index_ename_sal on emp(ename,job); 3.2.1触发多列索引优先检索列：索引的第一列触发规则:查询条件必须包含优先检索列中的原始值 select * from emp where ename=&#x27;SCOTT&#x27; and sal=1234; --触发多列索引 select * from emp where ename=&#x27;abc&#x27; and sal=&#x27;asx&#x27;; --不触发多列索引 表中无ename=abc --表中既有单列索引又有多列索引时 select * from emp where ename=&#x27;SCOTT&#x27;; --触发单列索引","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://blog.unclezs.com/tags/Oracle/"}]},{"title":"oracle的表空间，用户管理，表操作，函数","slug":"数据库/oracle/oracle的表空间，用户管理，表操作，函数","date":"2019-04-04T15:59:49.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/oracle/oracle的表空间，用户管理，表操作，函数.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/oracle/oracle%E7%9A%84%E8%A1%A8%E7%A9%BA%E9%97%B4%EF%BC%8C%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%EF%BC%8C%E8%A1%A8%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%87%BD%E6%95%B0.html","excerpt":"基于oracle 12c 1.表空间1.1 创建表空间create tablespace uncle datafile &#x27;c:\\oracle\\unclez.dbf&#x27; size 100m autoextend on --自动扩容 next 10m; --每次扩容10M 1.2 删除表空间drop tablespace uncle; 2.用户管理2.1创建用户create user root identified by 123 default tablespace uncle; 2.2授权","text":"基于oracle 12c 1.表空间1.1 创建表空间create tablespace uncle datafile &#x27;c:\\oracle\\unclez.dbf&#x27; size 100m autoextend on --自动扩容 next 10m; --每次扩容10M 1.2 删除表空间drop tablespace uncle; 2.用户管理2.1创建用户create user root identified by 123 default tablespace uncle; 2.2授权grant dba to root; 常用角色： connect:连接角色，基本角色 resource:开发者角色 dba:超级管理员角色 2.3解锁用户alter user 用户名 account unlock; 3.表操作3.1创建、删除表create table user( id number(10), name varchar2(20) ); drop table 表名 3.2 表结构1.添加一列 alter table 表名 add (字段名 类型) 2.删除一列 alter table 表名 drop column 字段名 3.修改列 alter table 表名 modify 字段名 类型 4.重命名一列 alter table 表名 rename column 字段名 to 新字段名 3.3.CRUD事务需要自己手动提交3.1.插入数据 insert into c##user (id,name) values(1,&#x27;uncle&#x27;); 3.2.查询数据 select* from c##user; 3.3修改数据 update c##user set sex=&#x27;男&#x27; where id=1; 3.4.删除数据 delete from c##user where id=1; 3.5重建表 truncate table 表名 3.4 序列3.4.1 创建序列 create sequence user_k; 3.4.2 查询序列 select user_k.nextval from dual; --下一前值,自增 select user_k.currentfrom dual; --当前值 3.4.2 使用序列 insert into user (id,name) values (uesr_k.nextval,&#x27;uncle&#x27;); 4.函数4.1单行函数接收字符输入返回字符或者数值，dual是伪表1.upper、lower大小写转换 select upper(&#x27;smith&#x27;) from dual; select lower(&#x27;SMITH&#x27;) from dual; 2.四舍五入函数：ROUND()默认情况下ROUND四舍五入取整，可以自己指定保留的位数。参数一是数据，参数二是保留几位 select round(51.56,2) from dual; 3.获得两个时间段中的月数：MONTHS_BETWEEN() select ename,round(months_between(date1,date2)) from emp; 4.TO_CHAR:字符串转换函数年：y, 年是四位使用yyyy月：m, 月是两位使用mm日：d, 日是两位使用dd select empno,ename, to_char(date,&#x27;yyyy&#x27;)年, to_char(date,&#x27;mm&#x27;)月, to_char(date,&#x27;dd&#x27;)日 from emp; 5.TO_DATE:日期转换函数 TO_DATE可以把字符串的数据转换成日期类型 select to_date(&#x27;2019-04-04&#x27;,&#x27;yyyy-mm-dd&#x27;) from dual; 6.空值处理nvlnvl(值,为NULL时候要赋的值) select total_money nav(reward,0)+money from emp; 7.条件函数case when select sal , sal , case when sal&lt;1500 then &#x27;低工资&#x27; when sal&gt;2500 then &#x27;高工资&#x27; else &#x27;中等工资&#x27; end from emp t; 4.2多行函数1.统计记录数 count()2.最小值查询 min()3.最大值查询 max()4.查询平均值 avg()5.求和函数 sum()","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://blog.unclezs.com/tags/Oracle/"}]},{"title":"VirtualBox下win7安装oracle12c问题解决","slug":"问题教程/VirtualBox下win7安装oracle12c问题解决","date":"2019-04-03T14:49:05.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"问题教程/VirtualBox下win7安装oracle12c问题解决.html","link":"","permalink":"https://blog.unclezs.com/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/VirtualBox%E4%B8%8Bwin7%E5%AE%89%E8%A3%85oracle12c%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3.html","excerpt":"一、主机无法ping通虚拟机NAT模式选择了NAT模式后，查看ipconfig只能看到一个10.0.2.15的地址，放到主机上，ping不通。但是虚拟机能连接网络 host-only模式设置后，虚拟机无法上网，关闭虚拟机和主机防火墙后可以互ping，我用的这种，但是因为数据库使用只要主机连接虚拟机就行了，所以我还是把主机防火墙打开了。 二、连接时显示No Lisenter原因：未配置oracle的lisener，监听主机，找到C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\network\\admin\\listener.asr 编辑listener.ora改host为0.0.0.0 # listener.ora Network Configuration File: C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\network\\admin\\listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = CLRExtProc) (ORACLE_HOME = C:\\app\\oracle\\product\\12.2.0\\dbhome_1) (PROGRAM = extproc) (ENVS = &quot;EXTPROC_DLLS=ONLY:C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\bin\\oraclr12.dll&quot;) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 0.0.0.0)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) ) 三、sqlplus在cmd下连接时中文乱码","text":"一、主机无法ping通虚拟机NAT模式选择了NAT模式后，查看ipconfig只能看到一个10.0.2.15的地址，放到主机上，ping不通。但是虚拟机能连接网络 host-only模式设置后，虚拟机无法上网，关闭虚拟机和主机防火墙后可以互ping，我用的这种，但是因为数据库使用只要主机连接虚拟机就行了，所以我还是把主机防火墙打开了。 二、连接时显示No Lisenter原因：未配置oracle的lisener，监听主机，找到C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\network\\admin\\listener.asr 编辑listener.ora改host为0.0.0.0 # listener.ora Network Configuration File: C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\network\\admin\\listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = CLRExtProc) (ORACLE_HOME = C:\\app\\oracle\\product\\12.2.0\\dbhome_1) (PROGRAM = extproc) (ENVS = &quot;EXTPROC_DLLS=ONLY:C:\\app\\oracle\\product\\12.2.0\\dbhome_1\\bin\\oraclr12.dll&quot;) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 0.0.0.0)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) ) 三、sqlplus在cmd下连接时中文乱码连接上orcle，输入 select userenv(&#x27;language&#x27;) from dual; 查询编码集，如果是 SIMPLIFIED CHINESE_CHINA.AL32UTF8那么在环境变量里面添加NLS_LANG值就是你查出来的值这时重新打开cmd，如果还是乱码，那么就退出连接（Ctrl +c）;然后如果你查出来的时UTF-8编码的就在连接前输入CHCP 65001;然后连接数据库如果是GBK就输入CHCP 936；然后连接就没乱码了 四、创建用户要带C##安装时不勾选此项","categories":[{"name":"问题教程","slug":"问题教程","permalink":"https://blog.unclezs.com/categories/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://blog.unclezs.com/tags/oracle/"},{"name":"问题解决","slug":"问题解决","permalink":"https://blog.unclezs.com/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"}]},{"title":"步道乐跑位置模拟刷步数","slug":"玩机/杂记/步道乐跑位置模拟刷步数","date":"2019-03-30T08:41:35.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"玩机/杂记/步道乐跑位置模拟刷步数.html","link":"","permalink":"https://blog.unclezs.com/%E7%8E%A9%E6%9C%BA/%E6%9D%82%E8%AE%B0/%E6%AD%A5%E9%81%93%E4%B9%90%E8%B7%91%E4%BD%8D%E7%BD%AE%E6%A8%A1%E6%8B%9F%E5%88%B7%E6%AD%A5%E6%95%B0.html","excerpt":"前言因为学校突然来了个需要跑步打卡，每学期要跑60多次，宅男心塞，所以就想着弄个位置模拟器来代劳了 需要工具Fake Locationroot的安卓手机一部步道乐跑软件 步骤1.过检测打开Fake location授予它root权限,左边侧滑有个反检测，进入点 “〉”这个符号，点那个Fake location软件一栏点击“√”然后返回出来后你可以看到一个“+”号，点击找到步道乐跑，然后点√，返回，开启反检测，主界面右上角有个“…”点击后进入setting找到增强反检测，点击，增强隐藏root，返回后，侧滑找到一个“root隐藏”点击加号，选择步道乐跑，点击√ 2.模拟位置在Fake Location里面定位到自己开始跑步的位置，然后开启摇杆，这个悬浮窗权限要开，然后点击开始模拟，进入步道乐跑，开始跑步，然后返回到Fake Location，打开地图，选择调整为真实地图，定位会在你选择的位置出现，操作摇杆开始在操场上跑圈圈，记得位置设置为跑步，步长3、4/s差不多；跑完几圈差不多了，我们是2公里，所以5圈； 现在","text":"前言因为学校突然来了个需要跑步打卡，每学期要跑60多次，宅男心塞，所以就想着弄个位置模拟器来代劳了 需要工具Fake Locationroot的安卓手机一部步道乐跑软件 步骤1.过检测打开Fake location授予它root权限,左边侧滑有个反检测，进入点 “〉”这个符号，点那个Fake location软件一栏点击“√”然后返回出来后你可以看到一个“+”号，点击找到步道乐跑，然后点√，返回，开启反检测，主界面右上角有个“…”点击后进入setting找到增强反检测，点击，增强隐藏root，返回后，侧滑找到一个“root隐藏”点击加号，选择步道乐跑，点击√ 2.模拟位置在Fake Location里面定位到自己开始跑步的位置，然后开启摇杆，这个悬浮窗权限要开，然后点击开始模拟，进入步道乐跑，开始跑步，然后返回到Fake Location，打开地图，选择调整为真实地图，定位会在你选择的位置出现，操作摇杆开始在操场上跑圈圈，记得位置设置为跑步，步长3、4/s差不多；跑完几圈差不多了，我们是2公里，所以5圈； 现在 写在最后如果觉得每次都得手动控制跑步麻烦，浪费时间，可以设置路线模拟，释放双手，用法简单，自己看看就会了；","categories":[{"name":"玩机","slug":"玩机","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/"},{"name":"杂记","slug":"玩机/杂记","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"破解","slug":"破解","permalink":"https://blog.unclezs.com/tags/%E7%A0%B4%E8%A7%A3/"},{"name":"步道乐跑","slug":"步道乐跑","permalink":"https://blog.unclezs.com/tags/%E6%AD%A5%E9%81%93%E4%B9%90%E8%B7%91/"}]},{"title":"C语言成员变量--栈与堆","slug":"C语言/C语言成员变量-栈与堆","date":"2019-03-28T14:11:01.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"C语言/C语言成员变量-栈与堆.html","link":"","permalink":"https://blog.unclezs.com/C%E8%AF%AD%E8%A8%80/C%E8%AF%AD%E8%A8%80%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F-%E6%A0%88%E4%B8%8E%E5%A0%86.html","excerpt":"一、写在前面最近学数据结构打算重新学一遍c语言，c语言函数返回值不像是java一样，java在定义一个成员变量后给其赋值，直接返回还是能拿到他的值，c却不一样了，成员变量放在栈内存中，栈内存中的成员变量会在方法执行后会释放，所以在成员变量赋值后返回是拿不到数据的 二、栈中的成员变量1.不能取得值1例子看看这个例子： char * testJB() &#123; char a=&#x27;H&#x27;; return &amp;a; &#125; void main() &#123; char p=testJB(); putchar(p); &#125; 这个打印的时候你会发现没看到想要的’H’ 分析当testJB执行完成后，a执行的栈内存区域将自动被释放，这时候再返回a的地址已经拿不到数据了","text":"一、写在前面最近学数据结构打算重新学一遍c语言，c语言函数返回值不像是java一样，java在定义一个成员变量后给其赋值，直接返回还是能拿到他的值，c却不一样了，成员变量放在栈内存中，栈内存中的成员变量会在方法执行后会释放，所以在成员变量赋值后返回是拿不到数据的 二、栈中的成员变量1.不能取得值1例子看看这个例子： char * testJB() &#123; char a=&#x27;H&#x27;; return &amp;a; &#125; void main() &#123; char p=testJB(); putchar(p); &#125; 这个打印的时候你会发现没看到想要的’H’ 分析当testJB执行完成后，a执行的栈内存区域将自动被释放，这时候再返回a的地址已经拿不到数据了 2.不能取得值2例子char * test() &#123; char arr[]=&quot;hello world&quot;; return arr; &#125; void main() &#123; char *p=test(); puts(p); &#125; 运行结果：乱码输出； 分析char arr[]=&quot;hello world&quot;; 内存过程:首先将“hello world” 放入常量区，然后再把其重常量区拷贝到arr的栈内存中，函数执行完成后，arr的栈内存被自动释放，返回的arr首地址也拿不到数据了； 二、堆内存1.可以取得值1例子char * test() &#123; char *p = malloc(sizeof(char)*10); *p = &quot;hello word&quot;; return p; &#125; void main() &#123; char *p=test(); puts(p); free(p); &#125; 运行结果:hello word； 分析：malloc 函数是在堆内存中开辟一块空间，并且不会自动释放,需要用完后手动释放；因此，当函数执行完成后，堆内存不被释放，返回首地址仍然可以取得数据，注意用完后手动释放； 2.不可取得值1例子void test(char *num) &#123; num = malloc(sizeof(char) * 10); num=&quot;hello word&quot;; &#125; void main() &#123; char *p=NULL; testCY(p); puts(p); &#125; 运行结果：报错； 分析：test函数中的num指针和main函数中的p指针不是同一个指针,因为形参也可以看作成员变量；在test函数开辟的空间是给num指针开辟的，而不是给p指针开辟的，这时候的p指针一直为NULL；所以这时候报错； 3.可以取得值2例子void testCY(char **num) &#123; char *tmp = malloc(100); memset(tmp,0,100); strcpy(tmp,&quot;hello word&quot;); *num = tmp; &#125; void main() &#123; char *p=NULL; testCY(&amp;p); puts(p); free(p); &#125; 运行结果：hello word 分析首先将二级指针num的值赋值为一级指针p的地址值，再创建临时指针tmp，在堆中开辟一块空间,tmp指针指向这块内存，将“hello world”从常量区拷贝到这块内存，再将一级指针p指向tmp指向的地址，这样在函数结束后，二级指针num、一级指针tmp会被销毁，但是一级指针p已经指向了开辟的堆内存； 优化：不需要tmp也可以做到，用num代替tmp；","categories":[{"name":"C","slug":"C","permalink":"https://blog.unclezs.com/categories/C/"}],"tags":[{"name":"c语言","slug":"c语言","permalink":"https://blog.unclezs.com/tags/c%E8%AF%AD%E8%A8%80/"}]},{"title":"C语言笔记","slug":"C语言/C语言笔记","date":"2019-03-27T05:41:30.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"C语言/C语言笔记.html","link":"","permalink":"https://blog.unclezs.com/C%E8%AF%AD%E8%A8%80/C%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0.html","excerpt":"一、常用字符串处理函数1.读入字符fgets(字符指针，大小，输入流)； 可以读入文件gets(字符指针，大小) ；控制台读入 2.输出字符fputs(字符指针，大小，输出流); 可以输入到文件puts（字符指针）；控制台输出 3.字符操作strlen(字符指针)； 字符有效长度（\\0结束）sizeof(字符指针)；字符真实长度；strcpy(目标字符指针,源字符指针)；字符串拷贝strncpy(目标字符指针,源字符指针,拷贝长度)；字符串拷贝strcat(char *a1,char *a2);字符拼接，后会加\\0strncat(char *a1,char *a2,int len);同上strcmp(char *a1,char *a2) 字符串比较，比较ASCLL，返回a1与a2的ASCLL差值strcmp(char *a1,char *a2,int len) 字符串比较，比较ASCLL，返回a1与a2的ASCLL差值strchr(char *a,int index);查找字符，找到返回其地址，否则nullstrstr(char *src,char *find); 在src中查找find字符串，找到返回其地址，否则nullstrtok(char *str,char c);字符串分割，以c来分割字符串streg: char arr[] = &quot;www.unclezs.com&quot;; char *p = strtok(arr,&quot;.&quot;); while (p!=NULL) &#123; printf(&quot;%s\\n&quot;, p); p = strtok(NULL, &quot;.&quot;); &#125; 4.格式化输入输出sprintf(char c,”%d+%d”,a,b);读入a,b,的值格式化后存入c*eg:**","text":"一、常用字符串处理函数1.读入字符fgets(字符指针，大小，输入流)； 可以读入文件gets(字符指针，大小) ；控制台读入 2.输出字符fputs(字符指针，大小，输出流); 可以输入到文件puts（字符指针）；控制台输出 3.字符操作strlen(字符指针)； 字符有效长度（\\0结束）sizeof(字符指针)；字符真实长度；strcpy(目标字符指针,源字符指针)；字符串拷贝strncpy(目标字符指针,源字符指针,拷贝长度)；字符串拷贝strcat(char *a1,char *a2);字符拼接，后会加\\0strncat(char *a1,char *a2,int len);同上strcmp(char *a1,char *a2) 字符串比较，比较ASCLL，返回a1与a2的ASCLL差值strcmp(char *a1,char *a2,int len) 字符串比较，比较ASCLL，返回a1与a2的ASCLL差值strchr(char *a,int index);查找字符，找到返回其地址，否则nullstrstr(char *src,char *find); 在src中查找find字符串，找到返回其地址，否则nullstrtok(char *str,char c);字符串分割，以c来分割字符串streg: char arr[] = &quot;www.unclezs.com&quot;; char *p = strtok(arr,&quot;.&quot;); while (p!=NULL) &#123; printf(&quot;%s\\n&quot;, p); p = strtok(NULL, &quot;.&quot;); &#125; 4.格式化输入输出sprintf(char c,”%d+%d”,a,b);读入a,b,的值格式化后存入c*eg:** sprintf(arr, &quot;%d+%d=%d&quot;,a,b,a+b); //打印arr输出10+20=30 sscanf(arr, “%d+%d=”,&amp;a,&amp;b);根据arr的字符串格式化读出字符；eg： char arr[100]=“100+200=”; int a, b; sscanf(arr, &quot;%d+%d=&quot;,&amp;a,&amp;b); //打印a,b输出100，200 5.字符串转换类型atoi转换成intatol 转换成longatof 转换成float、double 二、内存操作函数注意：成员变量的栈区内存会被用完后自动释放，堆区则不会1.malloc在内存的动态存储区(堆区)中分配一块长度为size字节的连续区域格式：malloc(分配大小) 2.strcopy 拷贝strcopy操作对空间，会将拷贝的字符串全都放到堆空间中，这样就会导致超出堆空间 使程序出现错误； 3.memset重置 memset(src,des, int len) 参数：目标 值 字节大小 4.memcpy拷贝 拷贝src所指的内存内容的前n个字节到dest所值的内存地址上 可以从栈区拷贝到堆区 也可以从堆区拷贝到栈区 注意：源地址与目标地址不能发生重叠strcpy 与mencpy的不同:①函数参数不同②strcpy拷贝字符串 memcpy 可以拷贝一块内存③strcpy与memcpy拷贝结束标志不同 5.memmove功能用法和memcpy()一样，区别在于：dest和src所指的内存空间重叠时，memmove()仍然能处理，不过执行效率比memcpy()低些。 6.memcmp比较s1和s2所指向内存区域的前n个字节,类型不同，但在内存中存的ASCII码相同，比较的内容相同注意：不限类型比对 7.free释放内存 8.realloc 重新申请内存realloc(p,size);在原有地址上重新申请内存，当p传入NULL时候和malloc功能一致 9.calloccalloc(几块，一块的大小)；按照快来分配内存空间，且会自动初始化为0 三、结构体struct student &#123; char *name; int age; char *gender; char* tel; &#125;stus; /*结构体*/ void strtuctTest() &#123; //赋值方式一 struct student stu1 = &#123; &quot;uncle&quot;,19,&quot;男&quot;,&quot;15023814323&quot;&#125;; //方式二 struct student stu2 = &#123; .name=&quot;uncle&quot;,.age=19,.gender=&quot;男&quot;,.tel=&quot;15023814323&quot; &#125;; //方式3 struct student stu; stu.age = 19; stu.gender = &quot;男&quot;; stu.name = &quot;unclezs&quot;; stu.tel = &quot;15023814323&quot;; //strcpy(stu.tel,&quot;85&quot;);数组需这样赋值 //指针操作结构体 struct student *stu = (struct student *)malloc(sizeof(stus)); stu-&gt;name = &quot;unclezs&quot;; stu-&gt;age = 19; stu-&gt;gender = &quot;男&quot;; stu-&gt;tel = &quot;133337000&quot;; printf(&quot;姓名%s\\n年龄:%d\\n性别:%s\\n电话号码:%s\\n&quot;,stu-&gt;name,stu-&gt;age,stu-&gt;gender,stu-&gt;tel); free(stu); &#125; 四、IO1、输入流fgets(char src,len,file);读字符串fgetc(file);读一个字符fread(src,len,number,file);读文件，以二进制fscanf(file,*des,&amp;a,&amp;b);文件格式化读取，和sscanf差不多 2、输出流fputs(char,file)fputc(char,file)fwrite(char *)fprintf(char,*file);文件格式化输出，和sprintf差不多 3、文件指针rewind(file);重置文件指针ftell(fiel): 获取光标当前为位置 返回值是long类型 -1代表失败fseek(file,move_count,*mode);**mode:SEEK_SET:开始位置移动SEEK_END:结束位置移动SEEK_CUR:当前位置移动 4.其他feof 判断文件流是否到结尾， eof判断字符是否到结尾fclose(file):关闭文件流fflush(file);文件缓冲区更新remove(path);删除文件rename(oldParh,*newPath);重命名 五、细节知识全局const和局部const区别全局常量：不能直接修改，指针操作地址也不能修改局部常量：不能直接修改，指针操作地址能修改; static和extern区别static:全局：其修饰的变量函数，都只能在本个文件中使用，且全局使用，在运行区都有效；局部：其修饰的变量函数，仅限函数内，在运行区都有效；extern:局部：只能在本文件中使用全局：所有文件都能使用；","categories":[{"name":"C","slug":"C","permalink":"https://blog.unclezs.com/categories/C/"}],"tags":[{"name":"c语言","slug":"c语言","permalink":"https://blog.unclezs.com/tags/c%E8%AF%AD%E8%A8%80/"}]},{"title":"Linux基本操作指令记录","slug":"linux/Linux基本操作指令记录","date":"2019-03-26T12:01:45.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"linux/Linux基本操作指令记录.html","link":"","permalink":"https://blog.unclezs.com/linux/Linux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E6%8C%87%E4%BB%A4%E8%AE%B0%E5%BD%95.html","excerpt":"Linux常用命令集合1.man 查看指令帮助 和- -help差不多 2.ls当前目录列出文件名字参数：-h: 以KB、M等来显示文件目录大小-l: 以列表形式显示文件目录-a:显示目录 及隐藏目录 3.cd 【切换工作目录】格式：cd 目录cd 切换到用户主目录cd ~ 切换到当前用户的主目录cd .. 切换到上级目录cd . 切换到当前目录cd - 切换到上一次目录 4.mkdir 创建目录mkdir 目录名 -p 递归创建rmdir 目录名 目录一定是空的rm 文件 -i询问 -r 递归删除 5.ln 链接","text":"Linux常用命令集合1.man 查看指令帮助 和- -help差不多 2.ls当前目录列出文件名字参数：-h: 以KB、M等来显示文件目录大小-l: 以列表形式显示文件目录-a:显示目录 及隐藏目录 3.cd 【切换工作目录】格式：cd 目录cd 切换到用户主目录cd ~ 切换到当前用户的主目录cd .. 切换到上级目录cd . 切换到当前目录cd - 切换到上一次目录 4.mkdir 创建目录mkdir 目录名 -p 递归创建rmdir 目录名 目录一定是空的rm 文件 -i询问 -r 递归删除 5.ln 链接格式：ln 源文件 链接文件 硬链接ln -s 源文件 链接文件 软连接硬链接文件占磁盘空间 但是删除源文件不会影响硬链接文件软链接文件不占磁盘空间 但是删除源文件会影响软链接文件 6.grep 文本搜索格式：grep ‘搜索内容’ 文件名参数：-n 显示行号-v 反选-i 忽略大小写 7.find 文件搜索格式：find 目录 参数 文件名（可以使用通配符）参数：-name 文件名（通配符支持）-size 大小 eg:-size +2M -size -5M (大于2M小于5M的)-perm rwx eg:-perm 777 9.tar 归档(未压缩)归档： tar -cvf 归档文件名.tar 文件1 文件2 目录1 目录2解归档： tar -xvf 归档文件名.tar -C 路径一步归档压缩： tar -czvf 文件名.tar.gz 文件1 文件2 目录1 目录2一步解归档压缩： tar -xzvf 文件名.tar.gz -C 路径 10.gzip、bzip2、zip 压缩、解压缩gzip压缩：gzip 归档文件名.tar 生成了一个文件 归档文件名.tar.gz 文件大小小于归档文件大小 归档文件名.tar不存在了gzip解压缩：gzip -d 归档文件名.tar.gz 生成了一个文件 归档文件名.tarbzip2压缩：tar -cjvf 文件名.tar.bz2 文件1 文件2 目录1 目录2bzip2解压缩：tar -xjvf 文件名.tar.bz2 -C 路径zip压缩：zip 文件名 文件1 文件2 目录1 目录2 生成一个文件为：文件名.zipunzip解压缩：unzip 文件名.zip -C 路径 11.su 用户权限：su 切换用户账户格式：【su 用户名 】【su】 切换到root【su root】 切换到root【su -】 切换到root用户 同时切换到root目录 12.用户管理 添加组：【groupadd 组名】 添加组 需要用户权限 删除组【groupdel 组名】 删除组 需要用户权限和清空组成员 修改用户所在组：【usermod -g 组名 用户名1 用户名2】需要用户权限 添加用户：【useradd -d /home/目录 用户名 -g 组名 -m】新建用户 设置用户主目录和设置组名 并自动创建 需要用户权限 设置密码：【passwd 用户名】设置密码 需要用户权限 删除用户：【userdel -r 用户名】 删除用户递归删除该用户所有文件 需要用户权限 13.chmod 修改文件权限字符法格式：【chmod -u|g|o|a +|- rwc 文件1 文件2】参数： d rwx r-x r-x u user +|- rwx g group +|- rwx o other +|- rwx a all +|- rwx 文件权限数字：rwx rwx rwx421 421 421 14.vi 文本编辑器VI编辑器有两个模式：文本编辑模式 命令行处理模式进入编辑器：1、vi 文件名 2、vim操作编辑器：【i】在光标当前位置插入【a】在光标右侧位置插入【o】在光标下一行位置开启新的一行插入【O】在光标上一行位置开启新的一行插入【I】在光标当前行行首插入【A】在光标当前行行尾插入 退出编辑器：【ZZ】保存退出【:wq】保存退出【:x】保存退出【:w 文件名】保存到指定文件中【:q】 保存退出 针对未修改的文件 注意：未保存文件会提示 无法退出【:q!】 强制退出 退出 不保存【:! 命令】暂时离开vi 执行其他命令编辑器操作：【[n]x】删除光标位置后面n个字符【[n]X】删除光标位置前面n个字符【D】删除光标所在位置后面到行尾的所有字符【[n]dd】删除光标所在行及下面n行 剪切【p】在光标下一行粘贴【[n]yy】复制光标所在行及下面n行【dG】删除光标所在行到文件结尾【J】合并光标所在行和下一行 中间用空格连接【.】执行上一次命令行操作【u】撤销 编辑器定位：【ctrl+b】回滚 行号减小【ctrl+f】前滚 行号增加【gg】定位在文件第一行行首【G】定位在文件最后一行行首【:$】定位在文件最后一行行首【[n]G | [n]gg】定位在m行注意：在查找一些特殊含义的字符时，需要加上转义字符【/内容】查找【n】查找下一个【N】查找上一个【?】查找上一次的所搜内容【/^word】 查找以word开头的内容【/word$】 查找以word结尾的内容【/.】查找任意一个字符【/*】查找任意多个字符 编辑器替换：【r】替换光标所在位置的字符【:r 文件名】在光标当前行的下一行插入一个文件 每次添加只能添加一个文件【: s/a/b/g】将光标所在行的a替换为b【:g/a/s//b/g】将文件中所有a替换为b【:n1,n2s/a/b/g】将行区间n1到n2的行中所有的a替换为b 编辑器设置：【:set ic】搜索时不区分大小写【:set noic】搜索时区分大小写","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.unclezs.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.unclezs.com/tags/Linux/"}]},{"title":"NetKeeper批处理一键开启热点","slug":"玩机/杂记/NetKeeper批处理一键开启热点","date":"2019-03-25T14:26:53.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"玩机/杂记/NetKeeper批处理一键开启热点.html","link":"","permalink":"https://blog.unclezs.com/%E7%8E%A9%E6%9C%BA/%E6%9D%82%E8%AE%B0/NetKeeper%E6%89%B9%E5%A4%84%E7%90%86%E4%B8%80%E9%94%AE%E5%BC%80%E5%90%AF%E7%83%AD%E7%82%B9.html","excerpt":"Netkeeper（创意）问题因为寝室网速比较慢，一个追求网速的我实在受不了，就办了个学校的50M的宽带，结果发现居然不能开热点。 解决工具netkeeper 、 360随身wifi（其他热点工具应该通用） 流程不能开热点这我就受不了了啊，打开万能的goole，搜索了一下，说杀死netkeeper后台进程就可以绕过netkeeper的检测热点软件，而且不会断网，我就打开任务管理器试了一下，发现真的还行，不过好景不长，一会就断网了。后面才发现需要结束进程树，试了试，还真的可以，不断网了。 一键化每次开机都需要这么操作一次，这是真的麻烦啊，所以我就想着，这个能不能一键化，想着就开始干吧，我就用到了平时没事的时候学的点批处理。1、首先杀死netkeeper进程树taskkill /im NK.exe /f /t2、检测热点软件是否打开，打开则关闭taskkill /im 360AP.exe /f /t3、打开热点软件（我是用的快捷方式，可以试试exe可执行文件）cd C:\\Users\\uncle\\Desktop 360WIFI.lnk","text":"Netkeeper（创意）问题因为寝室网速比较慢，一个追求网速的我实在受不了，就办了个学校的50M的宽带，结果发现居然不能开热点。 解决工具netkeeper 、 360随身wifi（其他热点工具应该通用） 流程不能开热点这我就受不了了啊，打开万能的goole，搜索了一下，说杀死netkeeper后台进程就可以绕过netkeeper的检测热点软件，而且不会断网，我就打开任务管理器试了一下，发现真的还行，不过好景不长，一会就断网了。后面才发现需要结束进程树，试了试，还真的可以，不断网了。 一键化每次开机都需要这么操作一次，这是真的麻烦啊，所以我就想着，这个能不能一键化，想着就开始干吧，我就用到了平时没事的时候学的点批处理。1、首先杀死netkeeper进程树taskkill /im NK.exe /f /t2、检测热点软件是否打开，打开则关闭taskkill /im 360AP.exe /f /t3、打开热点软件（我是用的快捷方式，可以试试exe可执行文件）cd C:\\Users\\uncle\\Desktop 360WIFI.lnk 以上的根据自己的文件路径改就行 贴下我的完整的 @echo off &gt;nul 2&gt;&amp;1 &quot;%SYSTEMROOT%\\system32\\cacls.exe&quot; &quot;%SYSTEMROOT%\\system32\\config\\system&quot; if &#39;%errorlevel%&#39; NEQ &#39;0&#39; ( goto UACPrompt ) else ( goto gotAdmin ) :UACPrompt echo Set UAC &#x3D; CreateObject^(&quot;Shell.Application&quot;^) &gt; &quot;%temp%\\getadmin.vbs&quot; echo UAC.ShellExecute &quot;%~s0&quot;, &quot;&quot;, &quot;&quot;, &quot;runas&quot;, 1 &gt;&gt; &quot;%temp%\\getadmin.vbs&quot; &quot;%temp%\\getadmin.vbs&quot; exit &#x2F;B :gotAdmin if exist &quot;%temp%\\getadmin.vbs&quot; ( del &quot;%temp%\\getadmin.vbs&quot; ) pushd &quot;%CD%&quot; CD &#x2F;D &quot;%~dp0&quot; title OneLine NKiller taskkill &#x2F;im NK.exe &#x2F;f &#x2F;t taskkill &#x2F;im unclez.exe &#x2F;f &#x2F;t cd C:\\Users\\uncle\\Desktop 360WIFI.lnk :: taskkill 结束进程的DOS命令; :: &#x2F;im 指通过指定进程名方式结束进程，后面紧跟进程名，如 NK.exe； :: &#x2F;f 强制终止；&#x2F;t 结束进程树。 复制代码到文本改自己的路径，然后改后缀为bat，每次开机netkeeper连接上后，直接执行bat文件即可开启热点。方便快捷。 最新解决方案（当前使用中）这个方案比较简单，是最近在吾爱破解上面看到个热点开启软件。就是调用Win10的系统API开启了系统自带的热点 经我测试不会断网原文链接：点击前往 使用步骤很简单 就是链接netkeeper然后打开这个软件输入热点账号密码，点击开启热点然后关闭软件就可以了。是不是很简单，不用什么结束什么进程之类的了。 %1 mshta vbscript:CreateObject(&quot;Shell.Application&quot;).ShellExecute(&quot;cmd.exe&quot;,&quot;/c %~s0 ::&quot;,&quot;&quot;,&quot;runas&quot;,1)(window.close)&amp;&amp;exit taskkill /F /IM NK.exe E: cd E:\\Program Files\\NetKeeper rd /s /q run/ exit 对了仅支持win10 软件地址：可以去论坛直接下载，也可以关注公众号【书虫无书荒】回复【热点软件】获取下载链接。","categories":[{"name":"玩机","slug":"玩机","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/"},{"name":"杂记","slug":"玩机/杂记","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/%E6%9D%82%E8%AE%B0/"}],"tags":[{"name":"破解","slug":"破解","permalink":"https://blog.unclezs.com/tags/%E7%A0%B4%E8%A7%A3/"},{"name":"小工具","slug":"小工具","permalink":"https://blog.unclezs.com/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"}]},{"title":"MySQL常用指令集","slug":"数据库/mysql/MySql常用指令集","date":"2019-03-25T14:24:57.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/MySql常用指令集.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/MySql%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E9%9B%86.html","excerpt":"1、创建（Create）1.数据库- create database if not exists name; 创建数据库 - create database character set gbk; 指定编码创建数据库 2.数据表- create table if not exists tablename(id int(10) primary key auto_increment,name varchar(20) ,age int(3)); 创建表 - create tablename like tablename2；复制表 - insert into 表名 （列名1，列名2） values (值1，值2); 插入数据 2、查询(Retrieve)1.数据库 show create database name 查看创建信息","text":"1、创建（Create）1.数据库- create database if not exists name; 创建数据库 - create database character set gbk; 指定编码创建数据库 2.数据表- create table if not exists tablename(id int(10) primary key auto_increment,name varchar(20) ,age int(3)); 创建表 - create tablename like tablename2；复制表 - insert into 表名 （列名1，列名2） values (值1，值2); 插入数据 2、查询(Retrieve)1.数据库 show create database name 查看创建信息 2.数据表 - show tables; 显示表 - describe tablename;或者 desc tablename； 查看表结构 - select 中加上distinct去除重复字段 - select 列名1，列名2 from 表名字；查询 - select 列名1，列名2 from 表名字 order by 列名1 ASC,列名 DESC； 排序查询（列名1升序，相同则按列名2降序） - select count(列名或*) from tablename; 查询有多少条数据（排除null） - select count(IFNULL(列名，值)) from wxxs;把值赋给null，然后统计数据条数 - select max(列名或*) from tablename;列最大值 - select min(列名或*) from tablename;列最小值 - select avg(列名或*) from tablename;列平均值 - select sum(列名或*) from tablename;列的和 - select sex,avg(age) from tablename group by sex;按照性别分组查询，男女平均年龄 - select sex,avg(age),count(id) from tablename group by sex where age&gt;20 having count(id)&gt;2;按照性别分组查询，男女平均年龄,除去年龄大于20岁的，分组后现在数量大于2个的；where用在分组前（不可跟聚合函数（sum之类）），having用在分租后； - select sex,avg(age),count(id) **num** from tablename group by sex where age&gt;20 having **num**&gt;2; 别名 - select * from 表名 limit 开始索引，一页显示条数;分页查询； - select * from 表名 where id between 5 and 10;查询id为5到10的 - select * from 表名 where id in (5,10);查询id为5和10的数据 - select * from 表名 where id is (not) null;查询id为（非）空的数据 - select * from 表名 where name like &#x27;_张%&#x27;；_匹配一个字符，%匹配多个字符； 3、删除(Delete)1.数据库- drop database name ;直接删除数据库，不提醒 - drop datebase name if exists; 存在则删除数据库 - mysqladmin drop databasename 删除数据库前，有提示。 2.数据表- delete from 表名字 where 条件；删除满足条件的数据 - delete from 表名; 删除所有数据（效率低） - truncate table 表名字；清空表数据（实际是删除再创建，效率高） 4、修改（Update）1.数据库 alter datebase name character set utf8; 修改编码 2.数据表 - alter table tablename rename to NewName;修改表名字 - alter table tablename character set utf8; 修改编码 - alter table tablename add 列名 数据类型;增加一列 - alter table tablename change 列名 新列名 新数据类型; 修改列 - alter table tablename modify 列名 数据类型; 修改列数据类型 - alter table tablename drop 列名； 删除列 - uptate tablename set 行名=值，行名=值 where 条件; 修改满足条件的值 - uptate tablename set 行名=值；修改指定列名的所有数据位指定值 5、使用数据库 use databasename; 选择数据库 select database(); 查看当前使用的数据库 select version(),current_date; 显示当前mysql版本和当前日期 6、约束非空约束 not null；创建表时添加，或者使用alter添加/删除（alter table 表名 modify 列名 数据类型 not null），删除时不加not null即可；唯一约束 unique；可以有多个null，创建表时添加，或者使用alter添加/删除（alter table 表名 drop index 列名），添加和非空约束一样；主键约束 primary key；添加auto——increment可实现自增长，alter添加/删除与not null一样格式；外键约束 foreign key； a.创建表时添加 constraint 外健名称 foreign key 外键列名称 references 主表名称（主表列名称）； b.创建后alter添加 alter table tablename constraint 外健名称 foreign key 外键列名称 references 主表名称（主表列名称）; c.删除 alter table tablename drop foreign key 外键名字； d.级联 更新/删除 alter table tablename constraint 外健名称 foreign key 外键列名称 references 主表名称（主表列名称）on update cascade on delete cascade; 主表删除从表数据也被删除，更新同理 7、多表查询A、内连接查询 a.隐式内连接select * from 表一名，表二名 where 条件； b.显示内连接select * from 表一名 别名1 (inner) join 表二名 别名2 on 条件;select * from table1 w (inner) join table2 m on w.id=m.id;B、外连接查询 a.左外连接select 字段列表 from 表一名 left （outer） join 表二 on 条件；查询左表全部，加上右表与左边交集； b.又外连接select 字段列表 from 表一名 right （outer） join 表二 on 条件；查询又表全部，加上左表与右边交集；C、子查询把查询语句当成条件使用来进行查询a。子查询结果是单行单列的b。子查询结果是单行多列的c。子查询的结果是多行多列的 8、事务a.基本操作事务开启（start transaction），执行sql，发现错误回滚事务(rollback)，没出错提交事务(commit)；select @@autocommit;查看自动提交， 1为自动0为手动；set @@autocommit=0;设置为手动提交 b.事务的四大特征 隔离性：多个事务之间，相互隔离。 原子性：是不可分割的，要么同时成功，要么同时失败。 持久性：事务提交或者回滚之后，数据会持久化保存。 一致性：数据总量不变。例如转账 c.事务的隔离级别 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。 幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 查询隔离级别：select @@tx_isolation;设置隔离级别：set global transaction isolation level 级别名； 9、用户模块1.用户管理1.添加用户create user ‘用户名‘@’主机名’ identified by ‘密码’; 2.删除用户drop user ‘用户名‘@’主机名’; 3.修改密码update user set passward=passward(‘新密码’) where user=’用户名’;set password for ‘用户名‘@’localhost’= password(‘新密码’); 4.重置root密码停止mysql服务（net stop mysql）-&gt;管理员执行（mysqld -skip-grant-tables）-&gt;新开窗口cmd（mysql）-&gt;修改密码； 5.查询用户select (host,user,passeword) from user; 2.权限管理1.查询权限show grants for ‘用户名‘@’主机名’ 2.授予权限grant 权限列表 on 数据库名.数据表名 to ‘用户名‘@’主机名’grant ALL on . to ‘用户名‘@’主机名’;给全部权限；grant update,select on 数据库名.数据表名 to ‘用户名‘@’主机名’;给特定表更新查询权限； 3.撤销权限revoke 权限列表 on 数据库名.数据表名 from ‘用户名‘@’主机名’revoke ALL on . from ‘用户名‘@’主机名’;撤销全部权限；revoke update,select on 数据库名.数据表名 from ‘用户名‘@’主机名’;撤销特定表更新查询权限；","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"指令集","slug":"指令集","permalink":"https://blog.unclezs.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"}]},{"title":"通用小说爬虫思路及JAVA实现","slug":"Java/其他/通用小说爬虫思路及JAVA实现","date":"2019-03-20T00:01:14.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/其他/通用小说爬虫思路及JAVA实现.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%85%B6%E4%BB%96/%E9%80%9A%E7%94%A8%E5%B0%8F%E8%AF%B4%E7%88%AC%E8%99%AB%E6%80%9D%E8%B7%AF%E5%8F%8AJAVA%E5%AE%9E%E7%8E%B0.html","excerpt":"前面不是写了个小说爬虫吗，然后就觉得维护起来比较麻烦。想弄一个通用的经过我的构想，觉得还是用正则匹配才行。首先用正则提取了正文，记过我在多个网站的测试，已经差不多可以适配大多数了贴下正则 //正则抓取内容 @Test void test12() &#123; //String pinyin=&quot;āáǎàēéěèīíǐìōóǒA8B0òūúǔùǖǘǚǜüê&quot;; String ch_punctuation=&quot;~。\\\\u000A\\\\u0009\\\\u00A0\\\\u0020\\\\u3000&quot;; //String punctuation=&quot;[\\\\-,\\\\/,\\\\|,\\\\$,\\\\+,\\\\%,\\\\&amp;,\\\\&#x27;,\\\\(,\\\\),\\\\*,\\\\x20-\\\\x2f,\\\\x3a-\\\\x40,\\\\x5b-\\\\x60,\\\\x7b-\\\\x7e,\\\\x80-\\\\xff,\\\\u3000-\\\\u3002,\\\\u300a,\\\\u300b,\\\\u300e-\\\\u3011,\\\\u2014,\\\\u2018,\\\\u2019,\\\\u201c,\\\\u201d,\\\\u2026,\\\\u203b,\\\\u25ce,\\\\uff01-\\\\uff5e,\\\\uffe5]&quot;; //String eh_punctuation=&quot;\\\\u003A\\\\u0028\\\\u201C\\\\uFF0C\\\\uFF1F\\\\u3001\\\\u201D\\\\uFF01\\\\uFF1A\\\\u223C\\\\u003D\\\\u2026&quot;; String unicode_azAZ09=&quot;\\\\uFF41-\\\\uFF5a\\\\uFF21-\\\\uFF3a\\\\uFF10-\\\\uFF19&quot;; String chinese=&quot;\\\\u4E00-\\\\u9FFF&quot;; String html = &quot;&quot;; try &#123; html = SpiderUtils.getSource(&quot;https://www.88dush.com/xiaoshuo/37/37125/20723618.html&quot;); //System.out.println(html); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Pattern compile = Pattern.compile(&quot;[pvr/\\&quot;]&gt;[^字\\\\w&lt;*][\\\\pP\\\\w\\\\pN\\\\pL\\\\pM&quot; +unicode_azAZ09+chinese+ch_punctuation + &quot;]&#123;3,&#125;[^字\\\\w&gt;]&#123;0,2&#125;(&lt;br|&lt;/p|&lt;/d|&lt;p)&quot;); Matcher m=compile.matcher(html); while(m.find()) String reString=m.group(0).replace(&quot;\\r\\n&quot;, &quot;&quot;).replace(&quot;&lt;br&quot;, &quot;\\n&quot;).replace(&quot;&lt;/p&quot;, &quot;\\n&quot;) .replace(&quot;p&gt;&quot;, &quot;\\n&quot;).replaceAll(&quot;&amp;[a-z]&#123;3,6&#125;;&quot;, &quot;&quot;).replace(&quot;\\n&quot;, &quot;&quot;).replace(&quot;&lt;p&quot;, &quot;\\n&quot;) .replace(&quot;/&gt;&quot;, &quot;&quot;).replace(&quot;r&gt;&quot;, &quot;&quot;).replace(&quot; &quot;,&quot;&quot;).replace(&quot;&lt;/d&quot;,&quot;&quot;).replace(&quot;v&gt;&quot;,&quot;&quot;) .replace(&quot;\\&quot;&gt;&quot;, &quot;&quot;).replace(&quot; &quot;, &quot;&quot;).trim(); if(reString.length()&gt;0) &#123; System.out.println(reString); &#125; &#125; &#125; 基本实现了提取小说正文的功能，然后就是提取小说目录链接了 //抓Chapter @Test void TestEncode() &#123; String html = &quot;&quot;; String chinese=&quot;\\\\u4E00-\\\\u9FFF&quot;; String url=&quot;https://www.88dush.com/xiaoshuo/37/37125/&quot;; try &#123; html = SpiderUtils.getSource(url); // System.out.println(html); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Pattern compile = Pattern.compile(&quot;\\&lt;\\a href=\\&quot;([\\\\w./-]+?)\\&quot;.*?&gt;([&quot;+chinese+&quot; \\\\d\\\\pP]+?)&lt;/a&quot;); Matcher m=compile.matcher(html); while(m.find()) &#123; // String reString=m.group(0).trim(); String re1=m.group(1).trim(); String re2=m.group(2).trim(); if(re1.length()&gt;5&amp;&amp;re2.length()&gt;5) &#123; System.out.println(SpiderUtils.GetAbsUrl(url,re1)+&quot;--------&quot;+re2); &#125; &#125; &#125; 这个提取没有正文那么精细了，还可以改进这样就基本实现了，给一个小说目录就可以爬取整本小说的目的这是我的思路，就是匹配汉字来筛选正文匹配a标签加标题来实现目录链接提取","text":"前面不是写了个小说爬虫吗，然后就觉得维护起来比较麻烦。想弄一个通用的经过我的构想，觉得还是用正则匹配才行。首先用正则提取了正文，记过我在多个网站的测试，已经差不多可以适配大多数了贴下正则 //正则抓取内容 @Test void test12() &#123; //String pinyin=&quot;āáǎàēéěèīíǐìōóǒA8B0òūúǔùǖǘǚǜüê&quot;; String ch_punctuation=&quot;~。\\\\u000A\\\\u0009\\\\u00A0\\\\u0020\\\\u3000&quot;; //String punctuation=&quot;[\\\\-,\\\\/,\\\\|,\\\\$,\\\\+,\\\\%,\\\\&amp;,\\\\&#x27;,\\\\(,\\\\),\\\\*,\\\\x20-\\\\x2f,\\\\x3a-\\\\x40,\\\\x5b-\\\\x60,\\\\x7b-\\\\x7e,\\\\x80-\\\\xff,\\\\u3000-\\\\u3002,\\\\u300a,\\\\u300b,\\\\u300e-\\\\u3011,\\\\u2014,\\\\u2018,\\\\u2019,\\\\u201c,\\\\u201d,\\\\u2026,\\\\u203b,\\\\u25ce,\\\\uff01-\\\\uff5e,\\\\uffe5]&quot;; //String eh_punctuation=&quot;\\\\u003A\\\\u0028\\\\u201C\\\\uFF0C\\\\uFF1F\\\\u3001\\\\u201D\\\\uFF01\\\\uFF1A\\\\u223C\\\\u003D\\\\u2026&quot;; String unicode_azAZ09=&quot;\\\\uFF41-\\\\uFF5a\\\\uFF21-\\\\uFF3a\\\\uFF10-\\\\uFF19&quot;; String chinese=&quot;\\\\u4E00-\\\\u9FFF&quot;; String html = &quot;&quot;; try &#123; html = SpiderUtils.getSource(&quot;https://www.88dush.com/xiaoshuo/37/37125/20723618.html&quot;); //System.out.println(html); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Pattern compile = Pattern.compile(&quot;[pvr/\\&quot;]&gt;[^字\\\\w&lt;*][\\\\pP\\\\w\\\\pN\\\\pL\\\\pM&quot; +unicode_azAZ09+chinese+ch_punctuation + &quot;]&#123;3,&#125;[^字\\\\w&gt;]&#123;0,2&#125;(&lt;br|&lt;/p|&lt;/d|&lt;p)&quot;); Matcher m=compile.matcher(html); while(m.find()) String reString=m.group(0).replace(&quot;\\r\\n&quot;, &quot;&quot;).replace(&quot;&lt;br&quot;, &quot;\\n&quot;).replace(&quot;&lt;/p&quot;, &quot;\\n&quot;) .replace(&quot;p&gt;&quot;, &quot;\\n&quot;).replaceAll(&quot;&amp;[a-z]&#123;3,6&#125;;&quot;, &quot;&quot;).replace(&quot;\\n&quot;, &quot;&quot;).replace(&quot;&lt;p&quot;, &quot;\\n&quot;) .replace(&quot;/&gt;&quot;, &quot;&quot;).replace(&quot;r&gt;&quot;, &quot;&quot;).replace(&quot; &quot;,&quot;&quot;).replace(&quot;&lt;/d&quot;,&quot;&quot;).replace(&quot;v&gt;&quot;,&quot;&quot;) .replace(&quot;\\&quot;&gt;&quot;, &quot;&quot;).replace(&quot; &quot;, &quot;&quot;).trim(); if(reString.length()&gt;0) &#123; System.out.println(reString); &#125; &#125; &#125; 基本实现了提取小说正文的功能，然后就是提取小说目录链接了 //抓Chapter @Test void TestEncode() &#123; String html = &quot;&quot;; String chinese=&quot;\\\\u4E00-\\\\u9FFF&quot;; String url=&quot;https://www.88dush.com/xiaoshuo/37/37125/&quot;; try &#123; html = SpiderUtils.getSource(url); // System.out.println(html); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Pattern compile = Pattern.compile(&quot;\\&lt;\\a href=\\&quot;([\\\\w./-]+?)\\&quot;.*?&gt;([&quot;+chinese+&quot; \\\\d\\\\pP]+?)&lt;/a&quot;); Matcher m=compile.matcher(html); while(m.find()) &#123; // String reString=m.group(0).trim(); String re1=m.group(1).trim(); String re2=m.group(2).trim(); if(re1.length()&gt;5&amp;&amp;re2.length()&gt;5) &#123; System.out.println(SpiderUtils.GetAbsUrl(url,re1)+&quot;--------&quot;+re2); &#125; &#125; &#125; 这个提取没有正文那么精细了，还可以改进这样就基本实现了，给一个小说目录就可以爬取整本小说的目的这是我的思路，就是匹配汉字来筛选正文匹配a标签加标题来实现目录链接提取","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"其他","slug":"Java/其他","permalink":"https://blog.unclezs.com/categories/Java/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://blog.unclezs.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"一些娱乐代码","slug":"一些娱乐代码","permalink":"https://blog.unclezs.com/tags/%E4%B8%80%E4%BA%9B%E5%A8%B1%E4%B9%90%E4%BB%A3%E7%A0%81/"}]},{"title":"解决MySQL不到中文数据","slug":"数据库/mysql/解决MySQL不到中文数据","date":"2019-03-19T23:59:32.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"数据库/mysql/解决MySQL不到中文数据.html","link":"","permalink":"https://blog.unclezs.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E8%A7%A3%E5%86%B3MySQL%E4%B8%8D%E5%88%B0%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE.html","excerpt":"查询数据库编码show variables like ‘%char%’如果其中含有Latin1而不是utf-8则不是正确的 解决方法修改mysql配置文件vim /etc/my.cnf 如果没有就手动加入[mysqld]下加入datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysqlsymbolic-links=0character-set-server=utf8init_connect=’SET NAMES utf8’ [client]default-character-set=utf8 [mysql]no-auto-rehashdefault-character-set=utf8 [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid systemctl restart mysqld 然后再查询数据库的编码 以前的latin1都变成了utf-8的格式","text":"查询数据库编码show variables like ‘%char%’如果其中含有Latin1而不是utf-8则不是正确的 解决方法修改mysql配置文件vim /etc/my.cnf 如果没有就手动加入[mysqld]下加入datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysqlsymbolic-links=0character-set-server=utf8init_connect=’SET NAMES utf8’ [client]default-character-set=utf8 [mysql]no-auto-rehashdefault-character-set=utf8 [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid systemctl restart mysqld 然后再查询数据库的编码 以前的latin1都变成了utf-8的格式","categories":[{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"}],"tags":[{"name":"问题解决","slug":"问题解决","permalink":"https://blog.unclezs.com/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"}]},{"title":"JavaFX的GridPane实现自适应","slug":"Java/javaFX/JavaFX的GridPane实现自适应","date":"2018-12-29T13:05:23.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/javaFX/JavaFX的GridPane实现自适应.html","link":"","permalink":"https://blog.unclezs.com/Java/javaFX/JavaFX%E7%9A%84GridPane%E5%AE%9E%E7%8E%B0%E8%87%AA%E9%80%82%E5%BA%94.html","excerpt":"起因因为最近想做一个书架一样得东西所以需要用到这个，有没有找到合适的，索性自己写一个 实现package top.unclez.ui.view; import javafx.application.Application; import javafx.fxml.FXMLLoader; import javafx.scene.Scene; import javafx.scene.control.Label; import javafx.scene.layout.*; import javafx.stage.Stage; import top.unclez.ui.util.StageUtil; public class BookMark extends Application &#123; public static void main(String[] args) &#123; launch(args); &#125; @Override public void start(Stage stage) &#123; stage.setTitle(&quot;GRIDPANE 自适应&quot;); FXMLLoader loader = new FXMLLoader(); GridPane pane= new GridPane(); pane.setHgap(10); pane.setVgap(10); for(int i=0;i&lt;10;i++) for (int j=0;j&lt;10;j++)&#123; Label label=new Label(&quot;UNCLE&quot;); GridPane.setHgrow(label,Priority.ALWAYS); GridPane.setVgrow(label,Priority.ALWAYS); pane.add(label,i,j); &#125; StageUtil.showStage(stage,new Scene(pane)); &#125; &#125; 这样就实现了自适应布局","text":"起因因为最近想做一个书架一样得东西所以需要用到这个，有没有找到合适的，索性自己写一个 实现package top.unclez.ui.view; import javafx.application.Application; import javafx.fxml.FXMLLoader; import javafx.scene.Scene; import javafx.scene.control.Label; import javafx.scene.layout.*; import javafx.stage.Stage; import top.unclez.ui.util.StageUtil; public class BookMark extends Application &#123; public static void main(String[] args) &#123; launch(args); &#125; @Override public void start(Stage stage) &#123; stage.setTitle(&quot;GRIDPANE 自适应&quot;); FXMLLoader loader = new FXMLLoader(); GridPane pane= new GridPane(); pane.setHgap(10); pane.setVgap(10); for(int i=0;i&lt;10;i++) for (int j=0;j&lt;10;j++)&#123; Label label=new Label(&quot;UNCLE&quot;); GridPane.setHgrow(label,Priority.ALWAYS); GridPane.setVgrow(label,Priority.ALWAYS); pane.add(label,i,j); &#125; StageUtil.showStage(stage,new Scene(pane)); &#125; &#125; 这样就实现了自适应布局","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"JavaFX","slug":"Java/JavaFX","permalink":"https://blog.unclezs.com/categories/Java/JavaFX/"}],"tags":[{"name":"JavaFX","slug":"JavaFX","permalink":"https://blog.unclezs.com/tags/JavaFX/"},{"name":"GridPane","slug":"GridPane","permalink":"https://blog.unclezs.com/tags/GridPane/"},{"name":"自适应","slug":"自适应","permalink":"https://blog.unclezs.com/tags/%E8%87%AA%E9%80%82%E5%BA%94/"}]},{"title":"Java中final关键词详解","slug":"Java/基础/Java中final关键词详解","date":"2018-05-17T08:47:30.000Z","updated":"2018-05-17T08:47:30.000Z","comments":true,"path":"Java/基础/Java中final关键词详解.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E4%B8%ADfinal%E5%85%B3%E9%94%AE%E8%AF%8D%E8%AF%A6%E8%A7%A3.html","excerpt":"简介final 关键字看上去简单，但是真正深入理解的人可以说少之又少，读完本文你就知道我在说什么了。本文将常规的用法简化，提出一些用法和深入的思考。可能 不同的作用域作用与类当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不允许别人这么做。即这个类是不能有子类的。 注意： final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。 作用于方法 private 方法是隐式的final final方法是可以被重载的 修饰参数Java允许在参数列表中以声明的方式将参数指明为final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。","text":"简介final 关键字看上去简单，但是真正深入理解的人可以说少之又少，读完本文你就知道我在说什么了。本文将常规的用法简化，提出一些用法和深入的思考。可能 不同的作用域作用与类当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不允许别人这么做。即这个类是不能有子类的。 注意： final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。 作用于方法 private 方法是隐式的final final方法是可以被重载的 修饰参数Java允许在参数列表中以声明的方式将参数指明为final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。 修饰变量 常规的用法比较简单，这里通过下面三个问题进一步说明。 1. 编译期常量和非编译期常量 public class Test &#123; //编译期常量 final int i = 1; final static int J = 1; final int[] a = &#123;1,2,3,4&#125;; //非编译期常量 Random r = new Random(); final int k = r.nextInt(); public static void main(String[] args) &#123; &#125; &#125; k的值由随机数对象决定，所以不是所有的final修饰的字段都是编译期常量，只是k的值在被初始化后无法被更改。 2. static final 一个既是static又是final 的字段只占据一段不能改变的存储空间，它必须在定义的时候进行赋值，或者在静态代码块进行赋值，否则编译器将不予通过。 3. blank final Java允许生成空白final，也就是说被声明为final但又没有给出定值的字段，但是必须在该字段被使用之前被赋值，这给予我们两种选择： 在定义处进行赋值(这不叫空白final) 在构造器中进行赋值，保证了该值在被使用前赋值。 这增强了final的灵活性。 final域重排序规则按照final修饰的数据类型分类： 基本数据类型 final域写：禁止final域写与构造方法重排序，即禁止final域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的final域全部已经初始化过。 final域读：禁止初次读对象的引用与读该对象包含的final域的重排序。 引用数据类型额外增加约束：禁止在构造函数对一个final修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量 重排序 final的实现原理写final域会要求编译器在final域写之后，构造函数返回前插入一个StoreStore屏障。读final域的重排序规则会要求编译器在读final域的操作前插入一个LoadLoad屏障。 很有意思的是，如果以X86处理为例，X86不会对写-写重排序，所以StoreStore屏障可以省略。由于不会对有间接依赖性的操作重排序，所以在X86处理器中，读final域需要的LoadLoad屏障也会被省略掉。也就是说，以X86为例的话，对final域的读/写的内存屏障都会被省略！具体是否插入还是得看是什么处理器","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"}],"author":"Unclezs"},{"title":"Java集合之HashMap与ConcurrentHashMap","slug":"Java/基础/Java集合之HashMap与ConcurrentHashMap","date":"2018-05-15T01:58:33.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/Java集合之HashMap与ConcurrentHashMap.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E9%9B%86%E5%90%88%E4%B9%8BHashMap%E4%B8%8EConcurrentHashMap.html","excerpt":"HashMap介绍在JDK1.7时，底层是由数组+链表与拉链法解决冲突的。 在JDK1.8时，底层是由数组+链表与拉链法+链表长度为8时转为红黑树。但是红黑树节点少于6时退化为链表。 添加元素的时间复杂度put操作的流程： 第一步：key.hashcode()，时间复杂度O(1)。 第二步：找到桶以后，判断桶里是否有元素，如果没有，直接new一个entey节点插入到数组中。时间复杂度O(1)。","text":"HashMap介绍在JDK1.7时，底层是由数组+链表与拉链法解决冲突的。 在JDK1.8时，底层是由数组+链表与拉链法+链表长度为8时转为红黑树。但是红黑树节点少于6时退化为链表。 添加元素的时间复杂度put操作的流程： 第一步：key.hashcode()，时间复杂度O(1)。 第二步：找到桶以后，判断桶里是否有元素，如果没有，直接new一个entey节点插入到数组中。时间复杂度O(1)。 第三步：如果桶里有元素，并且元素个数小于6，则调用equals方法，比较是否存在相同名字的key，不存在则new一个entry插入都链表尾部。时间复杂度O(1)+O(n)=O(n)。 第四步：如果桶里有元素，并且元素个数大于6，则调用equals方法，比较是否存在相同名字的key，不存在则new一个entry插入都链表尾部。时间复杂度O(1)+O(logn)=O(logn)。红黑树查询的时间复杂度是logn。 通过上面的分析，我们可以得出结论，HashMap新增元素的时间复杂度是不固定的，可能的值有O(1)、O(logn)、O(n)。最好情况是O(1)，最坏情况是O(n) 扩容机制扩容条件就是当threshold=loadFactory*capacity大于等于hash表当前的节点个数，HashMap采用2倍扩容。 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //旧的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //旧的阈值 int oldThr = threshold; //新的容量与阈值 int newCap, newThr = 0; //如果初始化过了 if (oldCap &gt; 0) &#123; //如果旧的容量大于了最大的容量 2的30次方，装不下了，不再扩容了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //设置为最大，后续不再进入此方法了 threshold = Integer.MAX_VALUE; return oldTab; &#125; //两倍扩容 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //未初始化的时候 //初始阈值大于0则将新的容量设置为旧的阈值 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //否则使用默认的容量进行初始化新的容量 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; //计算新的阈值 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //计算新的阈值，如果新的阈值为0的话 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //更新新的阈值 threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历每个桶，拷贝到新的hash数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果桶不为空 if ((e = oldTab[j]) != null) &#123; //释放以前节点的空间 oldTab[j] = null; //这个桶只有这一个节点 if (e.next == null) //直接把这个节点放到新的桶里 newTab[e.hash &amp; (newCap - 1)] = e; //不只有一个节点 //是树节点的时候 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //为链表的时候 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //遍历桶的所有节点 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; JDK7并发情况的成环问题在 JDK7 版本下，很多人都知道 HashMap 会有链表成环的问题，但大多数人只知道，是多线程引起的，至于具体细节的原因，和 JDK8 中如何解决这个问题，很少有人说的清楚，百度也几乎看不懂，本文就和大家聊清楚两个问题： JDK7 中 HashMap 成环原因，2 JDK8 中是如何解决的。 成环核心原因在JDK7的transfer方法。 void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; //e为空时循环结束 while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); // 成环的代码主要是在这三行代码 // 首先插入是从头开始插入的 e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; JDK8中的扩容方法，重新写了，为resize，链表扩容的核心代码： // loHead 表示老值,老值的意思是扩容后，该链表中计算出索引位置不变的元素 // hiHead 表示新值，新值的意思是扩容后，计算出索引位置发生变化的元素 // 举个例子，数组大小是 8 ，在数组索引位置是 1 的地方挂着一个链表，链表有两个值，两个值的 hashcode 分别是是9和33。 // 当数组发生扩容时，新数组的大小是 16，此时 hashcode 是 33 的值计算出来的数组索引位置仍然是 1，我们称为老值 // hashcode 是 9 的值计算出来的数组索引位置是 9，就发生了变化，我们称为新值。 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // (e.hash &amp; oldCap) == 0 表示老值链表 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // (e.hash &amp; oldCap) != 0 表示新值链表 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 老值链表赋值给原来的数组索引位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 新值链表赋值到新的数组索引位置 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; 总的来说，就是将每个桶的节点的hash值遍历出来，如果hash与oldCap取模为0，则表示数据不需要移动桶位置，如果不为0，则在桶的位置为 当前桶的索引+oldCap，举例解释： oldCap=16，新的容量2倍扩容为32，遍历每个桶，当两个hashcode分别为5和21，在容量为16的时候，都在索引为5的桶，扩容为32时，相当于高位补了1，所以如果hashcode与olcCap取模后不再是以前的位置了则代表新位置为oldcap+oldIndex 总结 JDK7 是在 while 循环里面，单个计算好数组索引位置后，单个的进行头插法插入数组中，在多线程情况下，会有成环问题 JDK8 ，改用尾插法，是等链表整个 while 循环结束后，才给数组赋值，所以多线程情况下，也不会成环 推荐阅读：HashMap链表成环的原因和解决方案 hashCode方法static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 可以看到把hashcode的高16位与低16位进行了异或运算，这样做的好处就是让低16位中包含了高16位的特征，尽量避免了hash冲突。 之所以只取16位还有一个原因，那就是因为最终取模运算使用的是 （n-1）&amp; hashcode方式代替%，之所以能够代替是因为n为2^x方。所以在容量比较少的时候，都是取的低16位的结果。 转化为红黑树及退化成链表原因链表长度为8转化为红黑树原因HashMap源码中可以看到： 这个其实就是泊松分布，节点的分布频率会遵循泊松分布，链表长度达到8个元素的概率为0.00000006，几乎是不可能事件。 还有就是红黑树的平均查找长度为O(logn)而链表为O(n) 节点个数少于6退化链表原因 为什么转化为红黑树的阈值8和转化为链表的阈值6不一样，是为了避免频繁来回转化。 退化是为了节省空间，红黑树占用的空间是链表的两倍。 首先得注意，网上说的到小于6退化为链表是分时机的，在移除节点的时候并不会判断小于6进行退化成链表，这个退化过程发生在resize中，为树节点的时候调用的spilt方法中进行的。 在remove的时候，通过红黑树根节点及其子节点是否为空来判断是否需要退化。 final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,boolean movable) &#123; //只贴核心代码 if (root == null || (movable &amp;&amp; (root.right == null || (rl = root.left) == null|| rl.left == null))) &#123; tab[index] = first.untreeify(map); // too small return; &#125; &#125; resize的时候，对红黑树进行了拆分 final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; //在这之前的逻辑是将红黑树每个节点的hash和一个bit进行&amp;运算， //根据运算结果将树划分为两棵红黑树，lc表示其中一棵树的节点数 if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; 这里才用到了 UNTREEIFY_THRESHOLD 的判断，当红黑树节点元素小于等于6时，才调用untreeify方法转换回链表 ConcurrentHashMap JDK7底层实现线程线程安全是通过分段锁Segment，继承自ReentrantLock。 JDK8底层改为CAS+Synchronized实现。 首先使用添加一个元素的时候，发现这个元素对应的Buket是空的，则通过CAS进行添加Buket的第一个元素。如果元素的对应的Buket的不为空则通过同步代码块进行并发同步控制。 升级原因： 减少内存开销:如果使用ReentrantLock则需要节点继承AQS来获得同步支持，增加内存开销，而1.8中只有头节点需要进行同步。 synchronized则是JVM直接支持的，JVM能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等等。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"集合","slug":"集合","permalink":"https://blog.unclezs.com/tags/%E9%9B%86%E5%90%88/"},{"name":"HashMap","slug":"HashMap","permalink":"https://blog.unclezs.com/tags/HashMap/"}]},{"title":"Java8新特性之函数式接口","slug":"Java/基础/Java8新特性之函数式接口","date":"2018-05-14T07:05:43.000Z","updated":"2018-05-14T07:05:43.000Z","comments":true,"path":"Java/基础/Java8新特性之函数式接口.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java8%E6%96%B0%E7%89%B9%E6%80%A7%E4%B9%8B%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3.html","excerpt":"什么是函数式接口如果一个接口中，只声明了一个抽象方法，则此接口就称为函数式接口。可以通过增加@FunctionalInterface注解进行编译时判断。 JDK提供的函数式接口 可以看到JDK提供了大量的函数式接口 Consumer故名思意就是提供给你一个对象然后你只需要做对应的处理，也可以说是消费即可。 @FunctionalInterface public interface Consumer&lt;T&gt; &#123; void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125; &#125; Supplier可以当作一个供应商一样，只负责传值","text":"什么是函数式接口如果一个接口中，只声明了一个抽象方法，则此接口就称为函数式接口。可以通过增加@FunctionalInterface注解进行编译时判断。 JDK提供的函数式接口 可以看到JDK提供了大量的函数式接口 Consumer故名思意就是提供给你一个对象然后你只需要做对应的处理，也可以说是消费即可。 @FunctionalInterface public interface Consumer&lt;T&gt; &#123; void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125; &#125; Supplier可以当作一个供应商一样，只负责传值 @FunctionalInterface public interface Supplier&lt;T&gt; &#123; T get(); &#125; Predicate断言，也就是传入一个值返回对应的true/false，也可以链式调用 @FunctionalInterface public interface Predicate&lt;T, R&gt; &#123; boolean test(T t); &#125; public class FunctionTest &#123; public static void main(String[] args) &#123; System.out.println(aAndB(n -&gt; n &lt; 101, n -&gt; n &gt; 10)); &#125; public static boolean aAndB(Predicate&lt;Integer&gt; a, Predicate&lt;Integer&gt; b)&#123; return a.and(b).test(100); &#125; &#125; Function也就是通过接受一个值，处理过后返回一个值 @FunctionalInterface public interface Function&lt;T, R&gt; &#123; R apply(T t); &#125; 自定义函数式接口在JDK中，只要接口只有一个抽象方法即可当作函数式接口，也就是说我们可以不加@FunctionalInterface public interface MyConsumer &#123; void doIt(); &#125; 当然如果加上了则会在编译的时候自动判断是否定义正确的。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"lamda","slug":"lamda","permalink":"https://blog.unclezs.com/tags/lamda/"}],"author":"Unclezs"},{"title":"Java中注解Annotation概念及原理","slug":"Java/基础/Java中注解Annotation概念及原理","date":"2018-05-13T12:22:06.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/Java中注解Annotation概念及原理.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/Java%E4%B8%AD%E6%B3%A8%E8%A7%A3Annotation%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%8E%9F%E7%90%86.html","excerpt":"概念Annontation是Java5开始引入的新特征，中文名称叫注解。它提供了一种安全的类似注释的机制，用来将任何的信息或元数据（metadata）与程序元素（类、方法、成员变量等）进行关联。为程序的元素（类、方法、成员变量）加上更直观更明了的说明，这些说明信息是与程序的业务逻辑无关，并且供指定的工具或框架使用。Annontation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的声明语句中。 Java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。包含在 java.lang.annotation 包中。 注解的用处 生成文档。这是最常见的，也是java 最早提供的注解。常用的有@param @return 等 跟踪代码依赖性，实现替代配置文件功能。 在编译时进行格式检查。如@override 放在方法前，如果你这个方法并不是覆盖了超类方法，则编译时就能检查出。 原理注解本质是一个继承了Annotation 的特殊接口，其具体实现类是Java 运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java 运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler 的invoke 方法。该方法会从memberValues 这个Map 中索引出对应的值。而memberValues 的来源是Java 常量池。 使用java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）：@Documented – 注解是否将包含在JavaDoc中@Retention – 什么时候使用该注解@Target – 注解用于什么地方@Inherited – 是否允许子类继承该注解 @Retention","text":"概念Annontation是Java5开始引入的新特征，中文名称叫注解。它提供了一种安全的类似注释的机制，用来将任何的信息或元数据（metadata）与程序元素（类、方法、成员变量等）进行关联。为程序的元素（类、方法、成员变量）加上更直观更明了的说明，这些说明信息是与程序的业务逻辑无关，并且供指定的工具或框架使用。Annontation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的声明语句中。 Java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。包含在 java.lang.annotation 包中。 注解的用处 生成文档。这是最常见的，也是java 最早提供的注解。常用的有@param @return 等 跟踪代码依赖性，实现替代配置文件功能。 在编译时进行格式检查。如@override 放在方法前，如果你这个方法并不是覆盖了超类方法，则编译时就能检查出。 原理注解本质是一个继承了Annotation 的特殊接口，其具体实现类是Java 运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java 运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler 的invoke 方法。该方法会从memberValues 这个Map 中索引出对应的值。而memberValues 的来源是Java 常量池。 使用java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）：@Documented – 注解是否将包含在JavaDoc中@Retention – 什么时候使用该注解@Target – 注解用于什么地方@Inherited – 是否允许子类继承该注解 @Retention定义该注解的生命周期 RetentionPolicy.SOURCE : 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。 RetentionPolicy.CLASS : 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式 RetentionPolicy.RUNTIME : 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。 Target表示该注解用于什么地方。默认值为任何元素，表示该注解用于什么地方。可用的ElementType 参数包括 ElementType.CONSTRUCTOR: 用于描述构造器 ElementType.FIELD: 成员变量、对象、属性（包括enum实例） ElementType.LOCAL_VARIABLE: 用于描述局部变量 ElementType.METHOD: 用于描述方法 ElementType.PACKAGE: 用于描述包 ElementType.PARAMETER: 用于描述参数 ElementType.TYPE: 用于描述类、接口(包括注解类型) 或enum声明 @Documented一个简单的Annotations 标记注解，表示是否将注解信息添加在java 文档中。 @Inherited定义该注释和子类的关系@Inherited 元注解是一个标记注解，@Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited 修饰的annotation 类型被用于一个class，则这个annotation 将被用于该class 的子类。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"注解","slug":"注解","permalink":"https://blog.unclezs.com/tags/%E6%B3%A8%E8%A7%A3/"}]},{"title":"浅谈Java反射原理","slug":"Java/基础/浅谈Java反射原理","date":"2018-05-12T05:00:18.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/浅谈Java反射原理.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/%E6%B5%85%E8%B0%88Java%E5%8F%8D%E5%B0%84%E5%8E%9F%E7%90%86.html","excerpt":"简介通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 重点：是运行时而不是编译时 优缺点反射的优点 可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点","text":"简介通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 重点：是运行时而不是编译时 优缺点反射的优点 可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。 性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。 反射原理以下内容只供参考，不一定官方。 反射原理就是将类的.class文件进行类加载进入JVM，得到了对应的Class对象，然后通过class对象及参数个数获得方法、属性、成员之类的，再通过invoke方法调用。invoke方法是一个Native方法。 推荐阅读：深入分析Java方法反射的实现原理","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"反射","slug":"反射","permalink":"https://blog.unclezs.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"面向对象的思想OOP","slug":"Java/基础/面向对象的思想OOP","date":"2018-05-01T02:13:36.000Z","updated":"2021-01-02T08:43:30.000Z","comments":true,"path":"Java/基础/面向对象的思想OOP.html","link":"","permalink":"https://blog.unclezs.com/Java/%E5%9F%BA%E7%A1%80/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%80%9D%E6%83%B3OOP.html","excerpt":"介绍OOP(Object Oriented Programming)，面向对象程序设计(Object Oriented Programming)作为一种新方法，其本质是以建立模型体现出来的抽象思维过程和面向对象的方法。模型是用来反映现实世界中事物特征的。任何一个模型都不可能反映客观事物的一切具体特征，只能对事物特征和变化规律的一种抽象，且在它所涉及的范围内更普遍、更集中、更深刻地描述客体的特征。通过建立模型而达到的抽象是人们对客体认识的深化。 三大特性封装隐藏对象的属性和实现细节，仅对外提供公共访问方式，将变化隔离，便于使用，提高复用性和安全性。 继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为向上转型 。","text":"介绍OOP(Object Oriented Programming)，面向对象程序设计(Object Oriented Programming)作为一种新方法，其本质是以建立模型体现出来的抽象思维过程和面向对象的方法。模型是用来反映现实世界中事物特征的。任何一个模型都不可能反映客观事物的一切具体特征，只能对事物特征和变化规律的一种抽象，且在它所涉及的范围内更普遍、更集中、更深刻地描述客体的特征。通过建立模型而达到的抽象是人们对客体认识的深化。 三大特性封装隐藏对象的属性和实现细节，仅对外提供公共访问方式，将变化隔离，便于使用，提高复用性和安全性。 继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为向上转型 。 Animal animal = new Cat(); 多态多态分为编译时多态和运行时多态: 编译时多态主要指方法的重载 运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定 运行时多态有三个条件: 继承 覆盖(重写) 向上转型 五大基本原则单一职责原则SRP(Single Responsibility Principle)类的功能要单一，不能包罗万象，跟杂货铺似的。 开放封闭原则OCP(Open－Close Principle)一个模块对于拓展是开放的，对于修改是封闭的，想要增加功能热烈欢迎，想要修改，哼，一万个不乐意。 里式替换原则LSP(the Liskov Substitution Principle LSP)子类可以替换父类出现在父类能够出现的任何地方。比如你能代表你爸去你姥姥家干活。哈哈~~ 依赖倒置原则DIP(the Dependency Inversion Principle DIP)高层次的模块不应该依赖于低层次的模块，他们都应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。就是你出国要说你是中国人，而不能说你是哪个村子的。比如说中国人是抽象的，下面有具体的xx省，xx市，xx县。你要依赖的是抽象的中国人，而不是你是xx村的。 接口分离原则ISP(the Interface Segregation Principle ISP)设计时采用多个与特定客户类有关的接口比采用一个通用的接口要好。就比如一个手机拥有打电话，看视频，玩游戏等功能，把这几个功能拆分成不同的接口，比在一个接口里要好的多。 OOP与面向过程（POP）的区别？面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。 优点：性能比面向对象好，因为类调用时需要实例化，开销比较大，比较消耗资源。缺点：不易维护、不易复用、不易扩展. 面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。 优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护。 缺点：性能比面向过程差","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"https://blog.unclezs.com/tags/OOP/"},{"name":"面向对象","slug":"面向对象","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"}]}],"categories":[{"name":"玩机","slug":"玩机","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/"},{"name":"效率工具","slug":"玩机/效率工具","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"},{"name":"爬虫","slug":"爬虫","permalink":"https://blog.unclezs.com/categories/%E7%88%AC%E8%99%AB/"},{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://blog.unclezs.com/categories/Java/%E5%9F%BA%E7%A1%80/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://blog.unclezs.com/categories/Java/Java%E5%9F%BA%E7%A1%80/"},{"name":"并发","slug":"Java/并发","permalink":"https://blog.unclezs.com/categories/Java/%E5%B9%B6%E5%8F%91/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://blog.unclezs.com/categories/Java/Maven/"},{"name":"工具","slug":"Java/工具","permalink":"https://blog.unclezs.com/categories/Java/%E5%B7%A5%E5%85%B7/"},{"name":"Logback","slug":"Java/Logback","permalink":"https://blog.unclezs.com/categories/Java/Logback/"},{"name":"性能调优","slug":"性能调优","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"name":"其他","slug":"性能调优/其他","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/%E5%85%B6%E4%BB%96/"},{"name":"设计模式","slug":"Java/设计模式","permalink":"https://blog.unclezs.com/categories/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Java","slug":"性能调优/Java","permalink":"https://blog.unclezs.com/categories/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/Java/"},{"name":"后端研发","slug":"后端研发","permalink":"https://blog.unclezs.com/categories/%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91/"},{"name":"中间件","slug":"中间件","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Zookeeper","slug":"中间件/Zookeeper","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/"},{"name":"服务器","slug":"服务器","permalink":"https://blog.unclezs.com/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Nginx","slug":"服务器/Nginx","permalink":"https://blog.unclezs.com/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/Nginx/"},{"name":"数据库","slug":"数据库","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"数据库/MySQL","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"操作系统","slug":"操作系统","permalink":"https://blog.unclezs.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://blog.unclezs.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"Redis","slug":"数据库/Redis","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"},{"name":"Jvm","slug":"Java/Jvm","permalink":"https://blog.unclezs.com/categories/Java/Jvm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"问题教程","slug":"问题教程","permalink":"https://blog.unclezs.com/categories/%E9%97%AE%E9%A2%98%E6%95%99%E7%A8%8B/"},{"name":"JavaEE","slug":"Java/JavaEE","permalink":"https://blog.unclezs.com/categories/Java/JavaEE/"},{"name":"Spring","slug":"Java/Spring","permalink":"https://blog.unclezs.com/categories/Java/Spring/"},{"name":"博客","slug":"博客","permalink":"https://blog.unclezs.com/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"Web前端","slug":"Web前端","permalink":"https://blog.unclezs.com/categories/Web%E5%89%8D%E7%AB%AF/"},{"name":"RabbitMQ","slug":"中间件/RabbitMQ","permalink":"https://blog.unclezs.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/"},{"name":"JavaFX","slug":"Java/JavaFX","permalink":"https://blog.unclezs.com/categories/Java/JavaFX/"},{"name":"容器化","slug":"容器化","permalink":"https://blog.unclezs.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"},{"name":"其他","slug":"Java/其他","permalink":"https://blog.unclezs.com/categories/Java/%E5%85%B6%E4%BB%96/"},{"name":"Oracle","slug":"数据库/Oracle","permalink":"https://blog.unclezs.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Oracle/"},{"name":"杂记","slug":"玩机/杂记","permalink":"https://blog.unclezs.com/categories/%E7%8E%A9%E6%9C%BA/%E6%9D%82%E8%AE%B0/"},{"name":"C","slug":"C","permalink":"https://blog.unclezs.com/categories/C/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.unclezs.com/categories/Linux/"}],"tags":[{"name":"powershell","slug":"powershell","permalink":"https://blog.unclezs.com/tags/powershell/"},{"name":"爬虫","slug":"爬虫","permalink":"https://blog.unclezs.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"PhantomJs","slug":"PhantomJs","permalink":"https://blog.unclezs.com/tags/PhantomJs/"},{"name":"引用类型","slug":"引用类型","permalink":"https://blog.unclezs.com/tags/%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"},{"name":"虚引用","slug":"虚引用","permalink":"https://blog.unclezs.com/tags/%E8%99%9A%E5%BC%95%E7%94%A8/"},{"name":"弱引用","slug":"弱引用","permalink":"https://blog.unclezs.com/tags/%E5%BC%B1%E5%BC%95%E7%94%A8/"},{"name":"并发编程","slug":"并发编程","permalink":"https://blog.unclezs.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"threadLocal","slug":"threadLocal","permalink":"https://blog.unclezs.com/tags/threadLocal/"},{"name":"插件","slug":"插件","permalink":"https://blog.unclezs.com/tags/%E6%8F%92%E4%BB%B6/"},{"name":"高效工具","slug":"高效工具","permalink":"https://blog.unclezs.com/tags/%E9%AB%98%E6%95%88%E5%B7%A5%E5%85%B7/"},{"name":"mapper","slug":"mapper","permalink":"https://blog.unclezs.com/tags/mapper/"},{"name":"mapstruct","slug":"mapstruct","permalink":"https://blog.unclezs.com/tags/mapstruct/"},{"name":"属性转换","slug":"属性转换","permalink":"https://blog.unclezs.com/tags/%E5%B1%9E%E6%80%A7%E8%BD%AC%E6%8D%A2/"},{"name":"logback","slug":"logback","permalink":"https://blog.unclezs.com/tags/logback/"},{"name":"log","slug":"log","permalink":"https://blog.unclezs.com/tags/log/"},{"name":"Jmeter","slug":"Jmeter","permalink":"https://blog.unclezs.com/tags/Jmeter/"},{"name":"Java","slug":"Java","permalink":"https://blog.unclezs.com/tags/Java/"},{"name":"Jcommander","slug":"Jcommander","permalink":"https://blog.unclezs.com/tags/Jcommander/"},{"name":"maven","slug":"maven","permalink":"https://blog.unclezs.com/tags/maven/"},{"name":"Facade","slug":"Facade","permalink":"https://blog.unclezs.com/tags/Facade/"},{"name":"外观模式","slug":"外观模式","permalink":"https://blog.unclezs.com/tags/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/"},{"name":"arthas","slug":"arthas","permalink":"https://blog.unclezs.com/tags/arthas/"},{"name":"grpc","slug":"grpc","permalink":"https://blog.unclezs.com/tags/grpc/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://blog.unclezs.com/tags/zookeeper/"},{"name":"nginx","slug":"nginx","permalink":"https://blog.unclezs.com/tags/nginx/"},{"name":"SQL","slug":"SQL","permalink":"https://blog.unclezs.com/tags/SQL/"},{"name":"单点登陆","slug":"单点登陆","permalink":"https://blog.unclezs.com/tags/%E5%8D%95%E7%82%B9%E7%99%BB%E9%99%86/"},{"name":"隔离级别","slug":"隔离级别","permalink":"https://blog.unclezs.com/tags/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"},{"name":"锁","slug":"锁","permalink":"https://blog.unclezs.com/tags/%E9%94%81/"},{"name":"JUC","slug":"JUC","permalink":"https://blog.unclezs.com/tags/JUC/"},{"name":"NIO","slug":"NIO","permalink":"https://blog.unclezs.com/tags/NIO/"},{"name":"并发","slug":"并发","permalink":"https://blog.unclezs.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"AQS","slug":"AQS","permalink":"https://blog.unclezs.com/tags/AQS/"},{"name":"HTTP","slug":"HTTP","permalink":"https://blog.unclezs.com/tags/HTTP/"},{"name":"哈希","slug":"哈希","permalink":"https://blog.unclezs.com/tags/%E5%93%88%E5%B8%8C/"},{"name":"面试","slug":"面试","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E8%AF%95/"},{"name":"ISP","slug":"ISP","permalink":"https://blog.unclezs.com/tags/ISP/"},{"name":"DNS","slug":"DNS","permalink":"https://blog.unclezs.com/tags/DNS/"},{"name":"IO模型","slug":"IO模型","permalink":"https://blog.unclezs.com/tags/IO%E6%A8%A1%E5%9E%8B/"},{"name":"哨兵","slug":"哨兵","permalink":"https://blog.unclezs.com/tags/%E5%93%A8%E5%85%B5/"},{"name":"高可用","slug":"高可用","permalink":"https://blog.unclezs.com/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"数据类型","slug":"数据类型","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"Redis","slug":"Redis","permalink":"https://blog.unclezs.com/tags/Redis/"},{"name":"面经","slug":"面经","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E7%BB%8F/"},{"name":"java","slug":"java","permalink":"https://blog.unclezs.com/tags/java/"},{"name":"责任链","slug":"责任链","permalink":"https://blog.unclezs.com/tags/%E8%B4%A3%E4%BB%BB%E9%93%BE/"},{"name":"死锁","slug":"死锁","permalink":"https://blog.unclezs.com/tags/%E6%AD%BB%E9%94%81/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.unclezs.com/tags/MySQL/"},{"name":"字节码","slug":"字节码","permalink":"https://blog.unclezs.com/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"跳跃表","slug":"跳跃表","permalink":"https://blog.unclezs.com/tags/%E8%B7%B3%E8%B7%83%E8%A1%A8/"},{"name":"JMM","slug":"JMM","permalink":"https://blog.unclezs.com/tags/JMM/"},{"name":"内存模型","slug":"内存模型","permalink":"https://blog.unclezs.com/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"数据持久化","slug":"数据持久化","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"redis","slug":"redis","permalink":"https://blog.unclezs.com/tags/redis/"},{"name":"代理","slug":"代理","permalink":"https://blog.unclezs.com/tags/%E4%BB%A3%E7%90%86/"},{"name":"装饰器","slug":"装饰器","permalink":"https://blog.unclezs.com/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"name":"适配器","slug":"适配器","permalink":"https://blog.unclezs.com/tags/%E9%80%82%E9%85%8D%E5%99%A8/"},{"name":"观察者","slug":"观察者","permalink":"https://blog.unclezs.com/tags/%E8%A7%82%E5%AF%9F%E8%80%85/"},{"name":"迭代器","slug":"迭代器","permalink":"https://blog.unclezs.com/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"},{"name":"模板方法","slug":"模板方法","permalink":"https://blog.unclezs.com/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/"},{"name":"原型","slug":"原型","permalink":"https://blog.unclezs.com/tags/%E5%8E%9F%E5%9E%8B/"},{"name":"生成器","slug":"生成器","permalink":"https://blog.unclezs.com/tags/%E7%94%9F%E6%88%90%E5%99%A8/"},{"name":"Builder","slug":"Builder","permalink":"https://blog.unclezs.com/tags/Builder/"},{"name":"工厂","slug":"工厂","permalink":"https://blog.unclezs.com/tags/%E5%B7%A5%E5%8E%82/"},{"name":"算法","slug":"算法","permalink":"https://blog.unclezs.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"缓存","slug":"缓存","permalink":"https://blog.unclezs.com/tags/%E7%BC%93%E5%AD%98/"},{"name":"Next-Key","slug":"Next-Key","permalink":"https://blog.unclezs.com/tags/Next-Key/"},{"name":"间隙锁","slug":"间隙锁","permalink":"https://blog.unclezs.com/tags/%E9%97%B4%E9%9A%99%E9%94%81/"},{"name":"幻读","slug":"幻读","permalink":"https://blog.unclezs.com/tags/%E5%B9%BB%E8%AF%BB/"},{"name":"ACID","slug":"ACID","permalink":"https://blog.unclezs.com/tags/ACID/"},{"name":"MVCC","slug":"MVCC","permalink":"https://blog.unclezs.com/tags/MVCC/"},{"name":"事务","slug":"事务","permalink":"https://blog.unclezs.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"字符集","slug":"字符集","permalink":"https://blog.unclezs.com/tags/%E5%AD%97%E7%AC%A6%E9%9B%86/"},{"name":"索引","slug":"索引","permalink":"https://blog.unclezs.com/tags/%E7%B4%A2%E5%BC%95/"},{"name":"存储引擎","slug":"存储引擎","permalink":"https://blog.unclezs.com/tags/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"https://blog.unclezs.com/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/"},{"name":"内存管理","slug":"内存管理","permalink":"https://blog.unclezs.com/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"Dijkstra","slug":"Dijkstra","permalink":"https://blog.unclezs.com/tags/Dijkstra/"},{"name":"查找算法","slug":"查找算法","permalink":"https://blog.unclezs.com/tags/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"},{"name":"排序算法","slug":"排序算法","permalink":"https://blog.unclezs.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"进程调度","slug":"进程调度","permalink":"https://blog.unclezs.com/tags/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"},{"name":"进程通讯","slug":"进程通讯","permalink":"https://blog.unclezs.com/tags/%E8%BF%9B%E7%A8%8B%E9%80%9A%E8%AE%AF/"},{"name":"IPC","slug":"IPC","permalink":"https://blog.unclezs.com/tags/IPC/"},{"name":"DFS","slug":"DFS","permalink":"https://blog.unclezs.com/tags/DFS/"},{"name":"BFS","slug":"BFS","permalink":"https://blog.unclezs.com/tags/BFS/"},{"name":"图","slug":"图","permalink":"https://blog.unclezs.com/tags/%E5%9B%BE/"},{"name":"邻接矩阵","slug":"邻接矩阵","permalink":"https://blog.unclezs.com/tags/%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5/"},{"name":"十字链表","slug":"十字链表","permalink":"https://blog.unclezs.com/tags/%E5%8D%81%E5%AD%97%E9%93%BE%E8%A1%A8/"},{"name":"邻接表和逆邻接表","slug":"邻接表和逆邻接表","permalink":"https://blog.unclezs.com/tags/%E9%82%BB%E6%8E%A5%E8%A1%A8%E5%92%8C%E9%80%86%E9%82%BB%E6%8E%A5%E8%A1%A8/"},{"name":"heap","slug":"heap","permalink":"https://blog.unclezs.com/tags/heap/"},{"name":"堆","slug":"堆","permalink":"https://blog.unclezs.com/tags/%E5%A0%86/"},{"name":"二叉树","slug":"二叉树","permalink":"https://blog.unclezs.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"tree","slug":"tree","permalink":"https://blog.unclezs.com/tags/tree/"},{"name":"树","slug":"树","permalink":"https://blog.unclezs.com/tags/%E6%A0%91/"},{"name":"数据结构","slug":"数据结构","permalink":"https://blog.unclezs.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"map","slug":"map","permalink":"https://blog.unclezs.com/tags/map/"},{"name":"哈希表","slug":"哈希表","permalink":"https://blog.unclezs.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"hash","slug":"hash","permalink":"https://blog.unclezs.com/tags/hash/"},{"name":"开放地址法","slug":"开放地址法","permalink":"https://blog.unclezs.com/tags/%E5%BC%80%E6%94%BE%E5%9C%B0%E5%9D%80%E6%B3%95/"},{"name":"拉链法","slug":"拉链法","permalink":"https://blog.unclezs.com/tags/%E6%8B%89%E9%93%BE%E6%B3%95/"},{"name":"栈","slug":"栈","permalink":"https://blog.unclezs.com/tags/%E6%A0%88/"},{"name":"stack","slug":"stack","permalink":"https://blog.unclezs.com/tags/stack/"},{"name":"list","slug":"list","permalink":"https://blog.unclezs.com/tags/list/"},{"name":"列表","slug":"列表","permalink":"https://blog.unclezs.com/tags/%E5%88%97%E8%A1%A8/"},{"name":"set","slug":"set","permalink":"https://blog.unclezs.com/tags/set/"},{"name":"queue","slug":"queue","permalink":"https://blog.unclezs.com/tags/queue/"},{"name":"队列","slug":"队列","permalink":"https://blog.unclezs.com/tags/%E9%98%9F%E5%88%97/"},{"name":"tcp","slug":"tcp","permalink":"https://blog.unclezs.com/tags/tcp/"},{"name":"拥塞控制","slug":"拥塞控制","permalink":"https://blog.unclezs.com/tags/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"},{"name":"网络","slug":"网络","permalink":"https://blog.unclezs.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"三次握手","slug":"三次握手","permalink":"https://blog.unclezs.com/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"},{"name":"osi","slug":"osi","permalink":"https://blog.unclezs.com/tags/osi/"},{"name":"endorsed","slug":"endorsed","permalink":"https://blog.unclezs.com/tags/endorsed/"},{"name":"单例","slug":"单例","permalink":"https://blog.unclezs.com/tags/%E5%8D%95%E4%BE%8B/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.unclezs.com/tags/hexo/"},{"name":"valine","slug":"valine","permalink":"https://blog.unclezs.com/tags/valine/"},{"name":"jvm","slug":"jvm","permalink":"https://blog.unclezs.com/tags/jvm/"},{"name":"servlet","slug":"servlet","permalink":"https://blog.unclezs.com/tags/servlet/"},{"name":"javaee","slug":"javaee","permalink":"https://blog.unclezs.com/tags/javaee/"},{"name":"springmvc","slug":"springmvc","permalink":"https://blog.unclezs.com/tags/springmvc/"},{"name":"aop","slug":"aop","permalink":"https://blog.unclezs.com/tags/aop/"},{"name":"spring","slug":"spring","permalink":"https://blog.unclezs.com/tags/spring/"},{"name":"profile","slug":"profile","permalink":"https://blog.unclezs.com/tags/profile/"},{"name":"耦合","slug":"耦合","permalink":"https://blog.unclezs.com/tags/%E8%80%A6%E5%90%88/"},{"name":"源码解析","slug":"源码解析","permalink":"https://blog.unclezs.com/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"name":"作用域","slug":"作用域","permalink":"https://blog.unclezs.com/tags/%E4%BD%9C%E7%94%A8%E5%9F%9F/"},{"name":"前后端分离","slug":"前后端分离","permalink":"https://blog.unclezs.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/"},{"name":"Web前端","slug":"Web前端","permalink":"https://blog.unclezs.com/tags/Web%E5%89%8D%E7%AB%AF/"},{"name":"Duration","slug":"Duration","permalink":"https://blog.unclezs.com/tags/Duration/"},{"name":"后台管理","slug":"后台管理","permalink":"https://blog.unclezs.com/tags/%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86/"},{"name":"动态路由","slug":"动态路由","permalink":"https://blog.unclezs.com/tags/%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1/"},{"name":"vue","slug":"vue","permalink":"https://blog.unclezs.com/tags/vue/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.unclezs.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabitMQ","slug":"RabitMQ","permalink":"https://blog.unclezs.com/tags/RabitMQ/"},{"name":"JavaFX","slug":"JavaFX","permalink":"https://blog.unclezs.com/tags/JavaFX/"},{"name":"exe4j","slug":"exe4j","permalink":"https://blog.unclezs.com/tags/exe4j/"},{"name":"打包","slug":"打包","permalink":"https://blog.unclezs.com/tags/%E6%89%93%E5%8C%85/"},{"name":"弹窗","slug":"弹窗","permalink":"https://blog.unclezs.com/tags/%E5%BC%B9%E7%AA%97/"},{"name":"源码分析","slug":"源码分析","permalink":"https://blog.unclezs.com/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"红黑树","slug":"红黑树","permalink":"https://blog.unclezs.com/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"name":"TreeMap","slug":"TreeMap","permalink":"https://blog.unclezs.com/tags/TreeMap/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.unclezs.com/tags/Spring/"},{"name":"docker","slug":"docker","permalink":"https://blog.unclezs.com/tags/docker/"},{"name":"搜索","slug":"搜索","permalink":"https://blog.unclezs.com/tags/%E6%90%9C%E7%B4%A2/"},{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://blog.unclezs.com/tags/ElasticSearch/"},{"name":"Lucen","slug":"Lucen","permalink":"https://blog.unclezs.com/tags/Lucen/"},{"name":"PageHelper","slug":"PageHelper","permalink":"https://blog.unclezs.com/tags/PageHelper/"},{"name":"Oracle","slug":"Oracle","permalink":"https://blog.unclezs.com/tags/Oracle/"},{"name":"PLSQL","slug":"PLSQL","permalink":"https://blog.unclezs.com/tags/PLSQL/"},{"name":"oracle","slug":"oracle","permalink":"https://blog.unclezs.com/tags/oracle/"},{"name":"问题解决","slug":"问题解决","permalink":"https://blog.unclezs.com/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"name":"破解","slug":"破解","permalink":"https://blog.unclezs.com/tags/%E7%A0%B4%E8%A7%A3/"},{"name":"步道乐跑","slug":"步道乐跑","permalink":"https://blog.unclezs.com/tags/%E6%AD%A5%E9%81%93%E4%B9%90%E8%B7%91/"},{"name":"c语言","slug":"c语言","permalink":"https://blog.unclezs.com/tags/c%E8%AF%AD%E8%A8%80/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.unclezs.com/tags/Linux/"},{"name":"小工具","slug":"小工具","permalink":"https://blog.unclezs.com/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"name":"指令集","slug":"指令集","permalink":"https://blog.unclezs.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"},{"name":"一些娱乐代码","slug":"一些娱乐代码","permalink":"https://blog.unclezs.com/tags/%E4%B8%80%E4%BA%9B%E5%A8%B1%E4%B9%90%E4%BB%A3%E7%A0%81/"},{"name":"GridPane","slug":"GridPane","permalink":"https://blog.unclezs.com/tags/GridPane/"},{"name":"自适应","slug":"自适应","permalink":"https://blog.unclezs.com/tags/%E8%87%AA%E9%80%82%E5%BA%94/"},{"name":"集合","slug":"集合","permalink":"https://blog.unclezs.com/tags/%E9%9B%86%E5%90%88/"},{"name":"HashMap","slug":"HashMap","permalink":"https://blog.unclezs.com/tags/HashMap/"},{"name":"lamda","slug":"lamda","permalink":"https://blog.unclezs.com/tags/lamda/"},{"name":"注解","slug":"注解","permalink":"https://blog.unclezs.com/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"反射","slug":"反射","permalink":"https://blog.unclezs.com/tags/%E5%8F%8D%E5%B0%84/"},{"name":"OOP","slug":"OOP","permalink":"https://blog.unclezs.com/tags/OOP/"},{"name":"面向对象","slug":"面向对象","permalink":"https://blog.unclezs.com/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"}]}